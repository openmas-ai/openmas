{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to OpenMAS","text":"<p>OpenMAS streamlines asynchronous Multi-Agent System (MAS) development in Python. By providing a lightweight framework, standardized structure, and helpful CLI tools, it handles the foundational setup, freeing you to concentrate on what matters most: designing and implementing sophisticated agent behaviors.</p> <p>Inspired by modern development ecosystems and driven by real-world use cases like coding and gaming agents, OpenMAS aims to streamline the entire MAS lifecycle, with particular attention to integrating communication protocols like the Model Context Protocol (MCP) alongside standard web protocols.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Simplified Agent Development: Build agents inheriting from <code>BaseAgent</code> with a clear asynchronous lifecycle (<code>setup</code>, <code>run</code>, <code>shutdown</code>).</li> <li>Flexible Communication: Pluggable communicators for HTTP, Model Context Protocol (SSE &amp; Stdio), gRPC, MQTT, with lazy loading to keep dependencies minimal. Easily extend with custom communicators. See Communication.</li> <li>Structured Projects: Standardized directory layout (<code>agents/</code>, <code>shared/</code>, <code>extensions/</code>, <code>packages/</code>) generated by <code>openmas init</code> promotes modularity and maintainability. See Project Structure.</li> <li>Layered Configuration: Robust system loading configuration from files (<code>openmas_project.yml</code>, <code>config/*.yml</code>), <code>.env</code>, and environment variables. See Configuration Guide.</li> <li>Agent Reasoning Agnosticism: While <code>BaseAgent</code> inherently supports heuristic-based logic, OpenMAS facilitates integrating diverse reasoning mechanisms. Follow guides for LLM Integration (using official LLM client libraries like OpenAI, Anthropic, Google Gemini) or explore built-in support for BDI Patterns (including <code>BdiAgent</code> and SPADE-BDI integration examples).</li> <li>Workflow Implementation: Implement various agent interaction patterns (see Building Effective Agents). While specific helpers exist for the Orchestrator-Worker pattern, the core framework enables building custom workflows like prompt chaining, routing, and parallel execution, with more helpers planned for future releases. See Agent Patterns.</li> <li>Developer Workflow Tools: Use the <code>openmas</code> CLI tool for initializing projects (<code>openmas init</code>), validating configuration (<code>openmas validate</code>), running agents locally (<code>openmas run</code>), managing dependencies (<code>openmas deps</code>), and generating deployment artifacts (<code>openmas generate-dockerfile</code>, <code>openmas generate-compose</code>). See CLI Docs.</li> <li>Extensibility: Design encourages local project extensions (<code>extensions/</code>) and shareable external packages (<code>packages/</code>).</li> <li>Testing Utilities: Includes <code>MockCommunicator</code> and <code>AgentTestHarness</code> to facilitate unit and integration testing. See Testing Your Agents.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to build your first agent?</p> <ol> <li>Installation: Get OpenMAS installed in your environment.     Go to Installation Guide</li> <li>Quick Start: Walk through a simple example to create and run a basic agent.     Go to Getting Started Guide</li> </ol>"},{"location":"#explore-further","title":"Explore Further","text":"<p>Dive deeper into specific aspects of OpenMAS:</p> <ul> <li>Core Concepts: Understand the fundamental ideas.<ul> <li>Design Philosophy</li> <li>Architecture Overview</li> <li>Project Structure</li> <li>Configuration System</li> <li>Communication Layer</li> </ul> </li> <li>Guides: Learn how to use specific features and patterns.<ul> <li>Integrating with LLMs</li> <li>Using MCP Integration</li> <li>Agent Patterns &amp; Workflows</li> <li>Reasoning Integration (BDI)</li> <li>Testing Your Agents</li> <li>Deploying OpenMAS Systems</li> <li>Development Workflow (Contributing)</li> </ul> </li> <li>Examples: See practical, runnable code examples.<ul> <li>Examples Overview</li> <li>Use Case: Chesspal.ai Refactoring</li> </ul> </li> <li>Command Line Interface: Detailed reference for the <code>openmas</code> CLI tool.     Go to CLI Docs</li> <li>API Reference: Detailed documentation for all framework modules and classes.     Go to API Reference</li> </ul> <p>We hope OpenMAS helps you build powerful and well-structured Multi-Agent Systems!</p>"},{"location":"api_reference/","title":"OpenMAS API Reference","text":"<p>This document provides a reference for the key classes and methods in the OpenMAS SDK.</p>"},{"location":"api_reference/#agent-module","title":"Agent Module","text":""},{"location":"api_reference/#baseagent","title":"BaseAgent","text":"<pre><code>from openmas.agent import BaseAgent\n\nclass MyAgent(BaseAgent):\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the agent.\"\"\"\n        pass\n\n    async def run(self) -&gt; None:\n        \"\"\"Run the agent.\"\"\"\n        pass\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Shut down the agent.\"\"\"\n        pass\n</code></pre> <p>Key methods: - <code>__init__(name=None, config=None, communicator_class=None, **kwargs)</code>: Initialize the agent - <code>setup()</code>: Set up the agent (called by <code>start()</code>) - <code>run()</code>: Run the agent (called by <code>start()</code>) - <code>shutdown()</code>: Shut down the agent (called by <code>stop()</code>) - <code>start()</code>: Start the agent (calls <code>setup()</code> then <code>run()</code>) - <code>stop()</code>: Stop the agent (calls <code>shutdown()</code>) - <code>set_communicator(communicator)</code>: Set the agent's communicator - <code>get_handler(method)</code>: Get a handler for the specified method - <code>register_handler(method, handler)</code>: Register a handler for the specified method</p>"},{"location":"api_reference/#mcp-agents","title":"MCP Agents","text":"<pre><code>from openmas.agent import McpAgent, McpServerAgent, McpClientAgent\n\n# Base MCP agent\nclass MyMcpAgent(McpAgent):\n    pass\n\n# MCP server agent\nclass MyServerAgent(McpServerAgent):\n    pass\n\n# MCP client agent\nclass MyClientAgent(McpClientAgent):\n    pass\n</code></pre>"},{"location":"api_reference/#mcpagent","title":"McpAgent","text":"<p>Key methods inherited from BaseAgent, plus: - <code>_discover_mcp_methods()</code>: Discover methods decorated with MCP decorators - <code>register_with_server(server)</code>: Register the agent's MCP methods with an MCP server</p>"},{"location":"api_reference/#mcpserveragent","title":"McpServerAgent","text":"<p>Key methods: - <code>setup_communicator()</code>: Set up the MCP communicator (SSE or stdio) - <code>start_server()</code>: Start the MCP server - <code>stop_server()</code>: Stop the MCP server</p>"},{"location":"api_reference/#mcpclientagent","title":"McpClientAgent","text":"<p>Key methods: - <code>connect_to_service(service_name, host, port)</code>: Connect to an MCP service - <code>disconnect_from_service(service_name)</code>: Disconnect from an MCP service - <code>list_tools(service_name)</code>: List tools available on a service - <code>call_tool(service_name, tool_name, params)</code>: Call a tool on a service</p>"},{"location":"api_reference/#mcp-decorators","title":"MCP Decorators","text":"<p> <pre><code>from openmas.agent import mcp_tool, mcp_prompt, mcp_resource\n\nclass MyAgent(McpAgent):\n    @mcp_tool(name=\"my_tool\", description=\"My tool\")\n    async def my_tool(self, param1: str) -&gt; dict:\n        \"\"\"Tool documentation.\"\"\"\n        return {\"result\": param1}\n\n    @mcp_prompt(name=\"my_prompt\", description=\"My prompt\")\n    async def my_prompt(self, context: str) -&gt; str:\n        \"\"\"Prompt documentation.\"\"\"\n        return f\"Context: {context}\\n\\nResponse:\"\n\n    @mcp_resource(uri=\"/resource\", name=\"my_resource\", mime_type=\"application/json\")\n    async def my_resource(self) -&gt; bytes:\n        \"\"\"Resource documentation.\"\"\"\n        return b'{\"key\": \"value\"}'\n</code></pre></p>"},{"location":"api_reference/#communication-module","title":"Communication Module","text":""},{"location":"api_reference/#base-communicator","title":"Base Communicator","text":"<pre><code>from openmas.communication import BaseCommunicator\n\n# Abstract base class, not used directly\n</code></pre>"},{"location":"api_reference/#http-communicator","title":"HTTP Communicator","text":"<pre><code>from openmas.communication import HttpCommunicator\n\ncommunicator = HttpCommunicator(\n    agent_name=\"my-agent\",\n    service_urls={\"other-service\": \"http://localhost:8000\"},\n    http_port=8001\n)\n</code></pre> <p>Key methods: - <code>start()</code>: Start the communicator - <code>stop()</code>: Stop the communicator - <code>register_handler(method, handler)</code>: Register a handler for the specified method - <code>send_request(target_service, method, params)</code>: Send a request to a service - <code>send_notification(target_service, method, params)</code>: Send a notification to a service</p>"},{"location":"api_reference/#mcp-communicators","title":"MCP Communicators","text":"<pre><code>from openmas.communication.mcp import McpSseCommunicator, McpStdioCommunicator\n\n# SSE-based MCP communicator (HTTP/SSE)\nsse_communicator = McpSseCommunicator(\n    agent_name=\"my-agent\",\n    service_urls={\"mcp-service\": \"http://localhost:8000\"},\n    server_mode=False,\n    http_port=8001\n)\n\n# Stdio-based MCP communicator (stdin/stdout)\nstdio_communicator = McpStdioCommunicator(\n    agent_name=\"my-agent\",\n    service_urls={},\n    server_mode=True\n)\n</code></pre> <p>Key methods (both communicators): - <code>start()</code>: Start the communicator - <code>stop()</code>: Stop the communicator - <code>register_handler(method, handler)</code>: Register a handler for the specified method - <code>register_mcp_methods(agent)</code>: Register the agent's MCP methods with the server</p>"},{"location":"api_reference/#grpc-communicator","title":"gRPC Communicator","text":"<pre><code>from openmas.communication.grpc import GrpcCommunicator\n\ngrpc_communicator = GrpcCommunicator(\n    agent_name=\"my-agent\",\n    service_urls={\"grpc-service\": \"localhost:50051\"},\n    grpc_port=50052\n)\n</code></pre>"},{"location":"api_reference/#mqtt-communicator","title":"MQTT Communicator","text":"<pre><code>from openmas.communication.mqtt import MqttCommunicator\n\nmqtt_communicator = MqttCommunicator(\n    agent_name=\"my-agent\",\n    service_urls={},\n    broker_host=\"localhost\",\n    broker_port=1883\n)\n</code></pre>"},{"location":"api_reference/#configuration-module","title":"Configuration Module","text":"<pre><code>from openmas.config import load_config, AgentConfig\nfrom pydantic import Field\n\n# Load standard configuration\nconfig = load_config(AgentConfig)\n\n# Define custom configuration\nclass MyAgentConfig(AgentConfig):\n    api_key: str = Field(..., description=\"API key for external service\")\n    model_name: str = Field(\"gpt-4\", description=\"Model name to use\")\n\n# Load custom configuration\nmy_config = load_config(MyAgentConfig)\n</code></pre> <p>Key functions: - <code>load_config(config_class)</code>: Load configuration from environment, files, etc. - <code>find_project_root()</code>: Find the root directory of the OpenMAS project</p>"},{"location":"api_reference/#agentconfig","title":"AgentConfig","text":"<p>Key fields: - <code>name</code>: Agent name (default: \"agent\") - <code>log_level</code>: Logging level (default: \"INFO\") - <code>communicator_type</code>: Type of communicator (default: \"http\") - <code>service_urls</code>: Dictionary of service URLs (default: {}) - <code>communicator_options</code>: Dictionary of options for the communicator (default: {})</p>"},{"location":"api_reference/#testing-module","title":"Testing Module","text":"<pre><code>import pytest\nfrom openmas.testing import MockCommunicator, AgentTestHarness\nfrom openmas.agent import BaseAgent\n\n# Create a mock communicator\nmock_communicator = MockCommunicator(agent_name=\"test-agent\")\n\n# Create a test harness\ntest_harness = AgentTestHarness(\n    agent_class=BaseAgent,\n    default_config={\"name\": \"test-agent\"}\n)\n</code></pre>"},{"location":"api_reference/#mockcommunicator","title":"MockCommunicator","text":"<p>Key methods: - <code>expect_request(target_service, method, params, response)</code>: Expect a request and return a response - <code>expect_request_exception(target_service, method, params, exception)</code>: Expect a request and raise an exception - <code>expect_notification(target_service, method, params)</code>: Expect a notification - <code>verify()</code>: Verify that all expectations were met - <code>trigger_handler(method, params)</code>: Trigger a handler for testing</p>"},{"location":"api_reference/#agenttestharness","title":"AgentTestHarness","text":"<p>Key methods: - <code>create_agent(**kwargs)</code>: Create an agent instance - <code>running_agent(agent)</code>: Context manager for running an agent during tests - <code>running_agents(*agents)</code>: Context manager for running multiple agents - <code>link_agents(*agents)</code>: Link agents for in-memory communication - <code>trigger_handler(agent, method, params)</code>: Trigger a handler on an agent - <code>wait_for(condition, timeout, check_interval)</code>: Wait for a condition to be true - <code>verify_all_communicators()</code>: Verify all communicators' expectations</p>"},{"location":"api_reference/#logging-module","title":"Logging Module","text":"<pre><code>from openmas.logging import get_logger, configure_logging\n\n# Configure logging\nconfigure_logging(log_level=\"DEBUG\")\n\n# Get a logger\nlogger = get_logger(__name__)\n\n# Use the logger\nlogger.debug(\"Debug message\")\nlogger.info(\"Info message\")\nlogger.warning(\"Warning message\")\nlogger.error(\"Error message\")\n</code></pre> <p>Key functions: - <code>get_logger(name)</code>: Get a logger with the specified name - <code>configure_logging(log_level, json_format)</code>: Configure logging for the application</p>"},{"location":"api_reference/#agent-patterns","title":"Agent Patterns","text":"<p>Orchestrator-Worker pattern helpers for OpenMAS.</p> <p>This module provides helper classes for implementing the Orchestrator-Worker pattern in a multi-agent system. The pattern consists of:</p> <ol> <li>An orchestrator agent that coordinates a workflow by delegating tasks to worker agents</li> <li>Worker agents that specialize in specific tasks and report results back to the orchestrator</li> <li>A communication mechanism for task delegation and result aggregation</li> </ol> <p>This pattern is useful for decomposing complex workflows into modular components that can be executed by specialized agents, potentially in parallel.</p> <p>Chaining pattern helpers for OpenMAS.</p> <p>This module provides helper classes and functions for implementing the Chaining pattern in a multi-agent system. The pattern consists of:</p> <ol> <li>A sequence of service calls that are executed in order</li> <li>Results from earlier calls can be passed to later calls</li> <li>Error handling and optional retry mechanisms</li> </ol> <p>This pattern is useful when a workflow needs to execute a series of steps in a defined order, where each step may depend on the result of previous steps.</p>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseOrchestratorAgent","title":"<code>BaseOrchestratorAgent</code>","text":"<p>               Bases: <code>BaseAgent</code></p> <p>Base orchestrator agent for coordinating tasks among worker agents.</p> <p>The orchestrator is responsible for: 1. Managing the workflow of complex tasks 2. Discovering and tracking available worker agents 3. Delegating subtasks to appropriate worker agents 4. Aggregating results from workers 5. Handling failures and retries</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>class BaseOrchestratorAgent(BaseAgent):\n    \"\"\"Base orchestrator agent for coordinating tasks among worker agents.\n\n    The orchestrator is responsible for:\n    1. Managing the workflow of complex tasks\n    2. Discovering and tracking available worker agents\n    3. Delegating subtasks to appropriate worker agents\n    4. Aggregating results from workers\n    5. Handling failures and retries\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize the orchestrator agent.\"\"\"\n        super().__init__(*args, **kwargs)\n\n        # Dictionary mapping worker names to their capabilities\n        self._workers: Dict[str, WorkerInfo] = {}\n\n        # Dictionary mapping task IDs to their status and metadata\n        self._tasks: Dict[str, Dict[str, Any]] = {}\n\n        # Default timeout for worker responses\n        self.default_timeout = 60.0\n\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the orchestrator agent.\n\n        Registers handlers for worker registration and task results.\n        \"\"\"\n        await self.communicator.register_handler(\"register_worker\", self._handle_worker_registration)\n        await self.communicator.register_handler(\"task_result\", self._handle_task_result)\n\n    async def _handle_worker_registration(self, worker_info: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle worker registration requests.\n\n        Args:\n            worker_info: Information about the worker, including name and capabilities\n\n        Returns:\n            Registration confirmation\n        \"\"\"\n        worker = WorkerInfo(**worker_info)\n        self._workers[worker.name] = worker\n\n        self.logger.info(\"Worker registered\", worker_name=worker.name, capabilities=list(worker.capabilities))\n\n        return {\"status\": \"registered\", \"orchestrator\": self.name}\n\n    async def _handle_task_result(self, result_data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle task results from workers.\n\n        Args:\n            result_data: The task result data from a worker\n\n        Returns:\n            Result acknowledgment\n        \"\"\"\n        result = TaskResult(**result_data)\n\n        if result.task_id not in self._tasks:\n            self.logger.warning(\"Received result for unknown task\", task_id=result.task_id)\n            return {\"status\": \"unknown_task\"}\n\n        task_info = self._tasks[result.task_id]\n        task_info[\"status\"] = result.status\n        task_info[\"result\"] = result.result\n        task_info[\"completed_at\"] = asyncio.get_event_loop().time()\n\n        # Call the result callback if one was registered\n        if \"callback\" in task_info and callable(task_info[\"callback\"]):\n            await task_info[\"callback\"](result)\n\n        self.logger.debug(\"Task result received\", task_id=result.task_id, status=result.status)\n\n        return {\"status\": \"acknowledged\"}\n\n    async def discover_workers(self) -&gt; List[WorkerInfo]:\n        \"\"\"Discover available worker agents.\n\n        This method broadcasts a discovery message to find workers.\n\n        Returns:\n            List of discovered worker information\n        \"\"\"\n        # Broadcast discovery message\n        try:\n            response = await self.communicator.send_request(\n                target_service=\"broadcast\",\n                method=\"discover_workers\",\n                params={\"orchestrator\": self.name},\n                timeout=5.0,\n            )\n\n            # Process responses\n            for worker_data in response.get(\"workers\", []):\n                if isinstance(worker_data, dict) and \"name\" in worker_data:\n                    worker = WorkerInfo(**worker_data)\n                    self._workers[worker.name] = worker\n\n            self.logger.info(\"Workers discovered\", worker_count=len(self._workers), workers=list(self._workers.keys()))\n\n        except Exception as e:\n            self.logger.error(\"Error discovering workers\", error=str(e))\n\n        return list(self._workers.values())\n\n    def find_worker_for_task(self, task_type: str) -&gt; Optional[str]:\n        \"\"\"Find a suitable worker for a given task type.\n\n        Args:\n            task_type: The type of task to find a worker for\n\n        Returns:\n            The name of a suitable worker, or None if no worker is found\n        \"\"\"\n        for name, info in self._workers.items():\n            if task_type in info.capabilities:\n                return name\n        return None\n\n    async def delegate_task(\n        self,\n        worker_name: str,\n        task_type: str,\n        parameters: Optional[Dict[str, Any]] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        timeout: Optional[float] = None,\n        callback: Optional[Callable[[TaskResult], Any]] = None,\n    ) -&gt; str:\n        \"\"\"Delegate a task to a worker agent.\n\n        Args:\n            worker_name: The name of the worker to delegate to\n            task_type: The type of task to delegate\n            parameters: Parameters for the task\n            metadata: Additional metadata for the task\n            timeout: Timeout for the task in seconds\n            callback: Callback function to call when the task completes\n\n        Returns:\n            The ID of the delegated task\n\n        Raises:\n            ValueError: If the worker is not registered\n        \"\"\"\n        if worker_name not in self._workers:\n            raise ValueError(f\"Worker '{worker_name}' is not registered\")\n\n        # Create the task request\n        task_request = TaskRequest(task_type=task_type, parameters=parameters or {}, metadata=metadata or {})\n\n        # Store task information\n        self._tasks[task_request.task_id] = {\n            \"worker\": worker_name,\n            \"task_type\": task_type,\n            \"status\": \"pending\",\n            \"created_at\": asyncio.get_event_loop().time(),\n            \"timeout\": timeout or self.default_timeout,\n            \"callback\": callback,\n        }\n\n        # Send the task to the worker\n        await self.communicator.send_notification(\n            target_service=worker_name, method=\"execute_task\", params=task_request.model_dump()\n        )\n\n        self.logger.debug(\"Task delegated\", task_id=task_request.task_id, worker=worker_name, task_type=task_type)\n\n        return task_request.task_id\n\n    async def get_task_result(self, task_id: str, timeout: Optional[float] = None) -&gt; Optional[TaskResult]:\n        \"\"\"Get the result of a task.\n\n        Args:\n            task_id: The ID of the task\n            timeout: How long to wait for the result in seconds\n\n        Returns:\n            The task result, or None if the task is not found or times out\n        \"\"\"\n        if task_id not in self._tasks:\n            return None\n\n        task_info = self._tasks[task_id]\n\n        # If the task is already completed, return the result\n        if task_info[\"status\"] in (\"success\", \"failure\"):\n            return TaskResult(\n                task_id=task_id,\n                status=task_info[\"status\"],\n                result=task_info.get(\"result\"),\n                error=task_info.get(\"error\"),\n            )\n\n        # Wait for the result with timeout\n        timeout_value = timeout or task_info[\"timeout\"]\n        start_time = asyncio.get_event_loop().time()\n\n        while (asyncio.get_event_loop().time() - start_time) &lt; timeout_value:\n            # Check if the task has completed\n            if task_info[\"status\"] in (\"success\", \"failure\"):\n                return TaskResult(\n                    task_id=task_id,\n                    status=task_info[\"status\"],\n                    result=task_info.get(\"result\"),\n                    error=task_info.get(\"error\"),\n                )\n\n            # Wait a bit before checking again\n            await asyncio.sleep(0.1)\n\n        # Timeout occurred\n        return TaskResult(task_id=task_id, status=\"timeout\", error=\"Task timed out\")\n\n    async def orchestrate_workflow(\n        self, tasks: List[Dict[str, Any]], parallel: bool = False\n    ) -&gt; Dict[int, Dict[str, Any]]:\n        \"\"\"Orchestrate a workflow of multiple tasks.\n\n        Args:\n            tasks: List of task definitions, each containing:\n                - task_type: The type of task\n                - parameters: Parameters for the task (optional)\n                - worker: Specific worker to use (optional)\n            parallel: Whether to execute tasks in parallel\n\n        Returns:\n            Dictionary mapping task positions or IDs to results\n        \"\"\"\n        results: Dict[int, Dict[str, Any]] = {}\n\n        if parallel:\n            # Execute tasks in parallel\n            task_futures = []\n            for i, task_def in enumerate(tasks):\n                worker = task_def.get(\"worker\") or self.find_worker_for_task(task_def[\"task_type\"])\n                if not worker:\n                    results[i] = {\n                        \"status\": \"failure\",\n                        \"error\": f\"No worker found for task type: {task_def['task_type']}\",\n                    }\n                    continue\n\n                task_id = await self.delegate_task(\n                    worker_name=worker, task_type=task_def[\"task_type\"], parameters=task_def.get(\"parameters\", {})\n                )\n\n                # Create a future for this task result\n                task_futures.append((i, task_id))\n\n            # Wait for all task results\n            for i, task_id in task_futures:\n                result = await self.get_task_result(task_id)\n                results[i] = (\n                    result.model_dump() if result else {\"status\": \"failure\", \"error\": \"Failed to get task result\"}\n                )\n        else:\n            # Execute tasks sequentially\n            for i, task_def in enumerate(tasks):\n                worker = task_def.get(\"worker\") or self.find_worker_for_task(task_def[\"task_type\"])\n                if not worker:\n                    results[i] = {\n                        \"status\": \"failure\",\n                        \"error\": f\"No worker found for task type: {task_def['task_type']}\",\n                    }\n                    continue\n\n                # Add results from previous tasks if requested\n                parameters = task_def.get(\"parameters\", {}).copy()\n                if task_def.get(\"include_previous_results\", False):\n                    parameters[\"previous_results\"] = results\n\n                task_id = await self.delegate_task(\n                    worker_name=worker, task_type=task_def[\"task_type\"], parameters=parameters\n                )\n\n                result = await self.get_task_result(task_id)\n                results[i] = (\n                    result.model_dump() if result else {\"status\": \"failure\", \"error\": \"Failed to get task result\"}\n                )\n\n                # Stop the workflow if a task fails and abort_on_failure is set\n                if (result is None or result.status != \"success\") and task_def.get(\"abort_on_failure\", False):\n                    break\n\n        return results\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseOrchestratorAgent.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initialize the orchestrator agent.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the orchestrator agent.\"\"\"\n    super().__init__(*args, **kwargs)\n\n    # Dictionary mapping worker names to their capabilities\n    self._workers: Dict[str, WorkerInfo] = {}\n\n    # Dictionary mapping task IDs to their status and metadata\n    self._tasks: Dict[str, Dict[str, Any]] = {}\n\n    # Default timeout for worker responses\n    self.default_timeout = 60.0\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseOrchestratorAgent.delegate_task","title":"<code>delegate_task(worker_name, task_type, parameters=None, metadata=None, timeout=None, callback=None)</code>  <code>async</code>","text":"<p>Delegate a task to a worker agent.</p> <p>Parameters:</p> Name Type Description Default <code>worker_name</code> <code>str</code> <p>The name of the worker to delegate to</p> required <code>task_type</code> <code>str</code> <p>The type of task to delegate</p> required <code>parameters</code> <code>Optional[Dict[str, Any]]</code> <p>Parameters for the task</p> <code>None</code> <code>metadata</code> <code>Optional[Dict[str, Any]]</code> <p>Additional metadata for the task</p> <code>None</code> <code>timeout</code> <code>Optional[float]</code> <p>Timeout for the task in seconds</p> <code>None</code> <code>callback</code> <code>Optional[Callable[[TaskResult], Any]]</code> <p>Callback function to call when the task completes</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The ID of the delegated task</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the worker is not registered</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>async def delegate_task(\n    self,\n    worker_name: str,\n    task_type: str,\n    parameters: Optional[Dict[str, Any]] = None,\n    metadata: Optional[Dict[str, Any]] = None,\n    timeout: Optional[float] = None,\n    callback: Optional[Callable[[TaskResult], Any]] = None,\n) -&gt; str:\n    \"\"\"Delegate a task to a worker agent.\n\n    Args:\n        worker_name: The name of the worker to delegate to\n        task_type: The type of task to delegate\n        parameters: Parameters for the task\n        metadata: Additional metadata for the task\n        timeout: Timeout for the task in seconds\n        callback: Callback function to call when the task completes\n\n    Returns:\n        The ID of the delegated task\n\n    Raises:\n        ValueError: If the worker is not registered\n    \"\"\"\n    if worker_name not in self._workers:\n        raise ValueError(f\"Worker '{worker_name}' is not registered\")\n\n    # Create the task request\n    task_request = TaskRequest(task_type=task_type, parameters=parameters or {}, metadata=metadata or {})\n\n    # Store task information\n    self._tasks[task_request.task_id] = {\n        \"worker\": worker_name,\n        \"task_type\": task_type,\n        \"status\": \"pending\",\n        \"created_at\": asyncio.get_event_loop().time(),\n        \"timeout\": timeout or self.default_timeout,\n        \"callback\": callback,\n    }\n\n    # Send the task to the worker\n    await self.communicator.send_notification(\n        target_service=worker_name, method=\"execute_task\", params=task_request.model_dump()\n    )\n\n    self.logger.debug(\"Task delegated\", task_id=task_request.task_id, worker=worker_name, task_type=task_type)\n\n    return task_request.task_id\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseOrchestratorAgent.discover_workers","title":"<code>discover_workers()</code>  <code>async</code>","text":"<p>Discover available worker agents.</p> <p>This method broadcasts a discovery message to find workers.</p> <p>Returns:</p> Type Description <code>List[WorkerInfo]</code> <p>List of discovered worker information</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>async def discover_workers(self) -&gt; List[WorkerInfo]:\n    \"\"\"Discover available worker agents.\n\n    This method broadcasts a discovery message to find workers.\n\n    Returns:\n        List of discovered worker information\n    \"\"\"\n    # Broadcast discovery message\n    try:\n        response = await self.communicator.send_request(\n            target_service=\"broadcast\",\n            method=\"discover_workers\",\n            params={\"orchestrator\": self.name},\n            timeout=5.0,\n        )\n\n        # Process responses\n        for worker_data in response.get(\"workers\", []):\n            if isinstance(worker_data, dict) and \"name\" in worker_data:\n                worker = WorkerInfo(**worker_data)\n                self._workers[worker.name] = worker\n\n        self.logger.info(\"Workers discovered\", worker_count=len(self._workers), workers=list(self._workers.keys()))\n\n    except Exception as e:\n        self.logger.error(\"Error discovering workers\", error=str(e))\n\n    return list(self._workers.values())\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseOrchestratorAgent.find_worker_for_task","title":"<code>find_worker_for_task(task_type)</code>","text":"<p>Find a suitable worker for a given task type.</p> <p>Parameters:</p> Name Type Description Default <code>task_type</code> <code>str</code> <p>The type of task to find a worker for</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The name of a suitable worker, or None if no worker is found</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>def find_worker_for_task(self, task_type: str) -&gt; Optional[str]:\n    \"\"\"Find a suitable worker for a given task type.\n\n    Args:\n        task_type: The type of task to find a worker for\n\n    Returns:\n        The name of a suitable worker, or None if no worker is found\n    \"\"\"\n    for name, info in self._workers.items():\n        if task_type in info.capabilities:\n            return name\n    return None\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseOrchestratorAgent.get_task_result","title":"<code>get_task_result(task_id, timeout=None)</code>  <code>async</code>","text":"<p>Get the result of a task.</p> <p>Parameters:</p> Name Type Description Default <code>task_id</code> <code>str</code> <p>The ID of the task</p> required <code>timeout</code> <code>Optional[float]</code> <p>How long to wait for the result in seconds</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[TaskResult]</code> <p>The task result, or None if the task is not found or times out</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>async def get_task_result(self, task_id: str, timeout: Optional[float] = None) -&gt; Optional[TaskResult]:\n    \"\"\"Get the result of a task.\n\n    Args:\n        task_id: The ID of the task\n        timeout: How long to wait for the result in seconds\n\n    Returns:\n        The task result, or None if the task is not found or times out\n    \"\"\"\n    if task_id not in self._tasks:\n        return None\n\n    task_info = self._tasks[task_id]\n\n    # If the task is already completed, return the result\n    if task_info[\"status\"] in (\"success\", \"failure\"):\n        return TaskResult(\n            task_id=task_id,\n            status=task_info[\"status\"],\n            result=task_info.get(\"result\"),\n            error=task_info.get(\"error\"),\n        )\n\n    # Wait for the result with timeout\n    timeout_value = timeout or task_info[\"timeout\"]\n    start_time = asyncio.get_event_loop().time()\n\n    while (asyncio.get_event_loop().time() - start_time) &lt; timeout_value:\n        # Check if the task has completed\n        if task_info[\"status\"] in (\"success\", \"failure\"):\n            return TaskResult(\n                task_id=task_id,\n                status=task_info[\"status\"],\n                result=task_info.get(\"result\"),\n                error=task_info.get(\"error\"),\n            )\n\n        # Wait a bit before checking again\n        await asyncio.sleep(0.1)\n\n    # Timeout occurred\n    return TaskResult(task_id=task_id, status=\"timeout\", error=\"Task timed out\")\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseOrchestratorAgent.orchestrate_workflow","title":"<code>orchestrate_workflow(tasks, parallel=False)</code>  <code>async</code>","text":"<p>Orchestrate a workflow of multiple tasks.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[Dict[str, Any]]</code> <p>List of task definitions, each containing: - task_type: The type of task - parameters: Parameters for the task (optional) - worker: Specific worker to use (optional)</p> required <code>parallel</code> <code>bool</code> <p>Whether to execute tasks in parallel</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[int, Dict[str, Any]]</code> <p>Dictionary mapping task positions or IDs to results</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>async def orchestrate_workflow(\n    self, tasks: List[Dict[str, Any]], parallel: bool = False\n) -&gt; Dict[int, Dict[str, Any]]:\n    \"\"\"Orchestrate a workflow of multiple tasks.\n\n    Args:\n        tasks: List of task definitions, each containing:\n            - task_type: The type of task\n            - parameters: Parameters for the task (optional)\n            - worker: Specific worker to use (optional)\n        parallel: Whether to execute tasks in parallel\n\n    Returns:\n        Dictionary mapping task positions or IDs to results\n    \"\"\"\n    results: Dict[int, Dict[str, Any]] = {}\n\n    if parallel:\n        # Execute tasks in parallel\n        task_futures = []\n        for i, task_def in enumerate(tasks):\n            worker = task_def.get(\"worker\") or self.find_worker_for_task(task_def[\"task_type\"])\n            if not worker:\n                results[i] = {\n                    \"status\": \"failure\",\n                    \"error\": f\"No worker found for task type: {task_def['task_type']}\",\n                }\n                continue\n\n            task_id = await self.delegate_task(\n                worker_name=worker, task_type=task_def[\"task_type\"], parameters=task_def.get(\"parameters\", {})\n            )\n\n            # Create a future for this task result\n            task_futures.append((i, task_id))\n\n        # Wait for all task results\n        for i, task_id in task_futures:\n            result = await self.get_task_result(task_id)\n            results[i] = (\n                result.model_dump() if result else {\"status\": \"failure\", \"error\": \"Failed to get task result\"}\n            )\n    else:\n        # Execute tasks sequentially\n        for i, task_def in enumerate(tasks):\n            worker = task_def.get(\"worker\") or self.find_worker_for_task(task_def[\"task_type\"])\n            if not worker:\n                results[i] = {\n                    \"status\": \"failure\",\n                    \"error\": f\"No worker found for task type: {task_def['task_type']}\",\n                }\n                continue\n\n            # Add results from previous tasks if requested\n            parameters = task_def.get(\"parameters\", {}).copy()\n            if task_def.get(\"include_previous_results\", False):\n                parameters[\"previous_results\"] = results\n\n            task_id = await self.delegate_task(\n                worker_name=worker, task_type=task_def[\"task_type\"], parameters=parameters\n            )\n\n            result = await self.get_task_result(task_id)\n            results[i] = (\n                result.model_dump() if result else {\"status\": \"failure\", \"error\": \"Failed to get task result\"}\n            )\n\n            # Stop the workflow if a task fails and abort_on_failure is set\n            if (result is None or result.status != \"success\") and task_def.get(\"abort_on_failure\", False):\n                break\n\n    return results\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseOrchestratorAgent.setup","title":"<code>setup()</code>  <code>async</code>","text":"<p>Set up the orchestrator agent.</p> <p>Registers handlers for worker registration and task results.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>async def setup(self) -&gt; None:\n    \"\"\"Set up the orchestrator agent.\n\n    Registers handlers for worker registration and task results.\n    \"\"\"\n    await self.communicator.register_handler(\"register_worker\", self._handle_worker_registration)\n    await self.communicator.register_handler(\"task_result\", self._handle_task_result)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseWorkerAgent","title":"<code>BaseWorkerAgent</code>","text":"<p>               Bases: <code>BaseAgent</code></p> <p>Base worker agent for processing specialized tasks.</p> <p>Workers register with orchestrators, receive task assignments, process them according to their capabilities, and return results.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>class BaseWorkerAgent(BaseAgent):\n    \"\"\"Base worker agent for processing specialized tasks.\n\n    Workers register with orchestrators, receive task assignments,\n    process them according to their capabilities, and return results.\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize the worker agent.\"\"\"\n        super().__init__(*args, **kwargs)\n\n        # Dictionary mapping task types to handler methods\n        self._task_handlers: Dict[str, Callable] = {}\n\n        # Set of orchestrators this worker is registered with\n        self._orchestrators: Set[str] = set()\n\n        # Dict of active tasks being processed\n        self._active_tasks: Dict[str, Dict[str, Any]] = {}\n\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the worker agent.\n\n        Discovers and registers task handlers, registers with orchestrators,\n        and sets up communication handlers.\n        \"\"\"\n        # Discover task handlers from class methods\n        self._discover_task_handlers()\n\n        # Register handler for executing tasks\n        await self.communicator.register_handler(\"execute_task\", self._handle_execute_task)\n\n        # Register handler for discovery requests\n        await self.communicator.register_handler(\"discover_workers\", self._handle_discovery)\n\n    def _discover_task_handlers(self) -&gt; None:\n        \"\"\"Discover task handlers from class methods.\"\"\"\n        for attr_name in dir(self):\n            attr = getattr(self, attr_name)\n            if callable(attr) and hasattr(attr, \"_task_handler\"):\n                task_info = getattr(attr, \"_task_handler\")\n                if isinstance(task_info, dict) and \"task_type\" in task_info:\n                    self._task_handlers[task_info[\"task_type\"]] = attr\n                    self.logger.debug(\"Registered task handler\", task_type=task_info[\"task_type\"], handler=attr_name)\n\n    async def register_with_orchestrator(self, orchestrator_name: str) -&gt; bool:\n        \"\"\"Register this worker with an orchestrator.\n\n        Args:\n            orchestrator_name: The name of the orchestrator to register with\n\n        Returns:\n            True if registration was successful, False otherwise\n        \"\"\"\n        try:\n            response = await self.communicator.send_request(\n                target_service=orchestrator_name,\n                method=\"register_worker\",\n                params={\n                    \"name\": self.name,\n                    \"capabilities\": list(self._task_handlers.keys()),\n                    \"metadata\": {\"agent_type\": self.__class__.__name__},\n                },\n            )\n\n            if response.get(\"status\") == \"registered\":\n                self._orchestrators.add(orchestrator_name)\n                self.logger.info(\"Registered with orchestrator\", orchestrator=orchestrator_name)\n                return True\n\n            self.logger.warning(\n                \"Failed to register with orchestrator\", orchestrator=orchestrator_name, response=response\n            )\n            return False\n\n        except Exception as e:\n            self.logger.error(\"Error registering with orchestrator\", orchestrator=orchestrator_name, error=str(e))\n            return False\n\n    async def _handle_discovery(self, discovery_request: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle worker discovery requests from orchestrators.\n\n        Args:\n            discovery_request: The discovery request\n\n        Returns:\n            Worker information\n        \"\"\"\n        orchestrator = discovery_request.get(\"orchestrator\")\n        if orchestrator and orchestrator not in self._orchestrators:\n            self._orchestrators.add(orchestrator)\n            self.logger.info(\"Added orchestrator from discovery\", orchestrator=orchestrator)\n\n        return {\n            \"name\": self.name,\n            \"capabilities\": list(self._task_handlers.keys()),\n            \"metadata\": {\"agent_type\": self.__class__.__name__},\n        }\n\n    async def _handle_execute_task(self, task_request_data: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle a task execution request from an orchestrator.\n\n        Args:\n            task_request_data: The task request data\n\n        Returns:\n            Acknowledgment of the task request\n        \"\"\"\n        task_request = TaskRequest(**task_request_data)\n\n        # Check if we have a handler for this task type\n        if task_request.task_type not in self._task_handlers:\n            self.logger.warning(\n                \"Received task with no handler\", task_id=task_request.task_id, task_type=task_request.task_type\n            )\n\n            # Send failure result back to the orchestrator\n            await self._send_task_result(\n                task_id=task_request.task_id,\n                status=\"failure\",\n                error=f\"No handler for task type: {task_request.task_type}\",\n            )\n            return {\"status\": \"rejected\", \"reason\": \"no_handler\"}\n\n        # Store the task in active tasks\n        self._active_tasks[task_request.task_id] = {\n            \"task_type\": task_request.task_type,\n            \"parameters\": task_request.parameters,\n            \"metadata\": task_request.metadata,\n            \"status\": \"in_progress\",\n            \"started_at\": asyncio.get_event_loop().time(),\n        }\n\n        # Execute the task in the background\n        asyncio.create_task(self._execute_task(task_request))\n\n        return {\"status\": \"accepted\"}\n\n    async def _execute_task(self, task_request: TaskRequest) -&gt; None:\n        \"\"\"Execute a task in the background.\n\n        Args:\n            task_request: The task request to execute\n        \"\"\"\n        handler = self._task_handlers[task_request.task_type]\n\n        try:\n            # Execute the handler\n            result = await handler(**task_request.parameters)\n\n            # Send success result\n            await self._send_task_result(task_id=task_request.task_id, status=\"success\", result=result)\n\n        except Exception as e:\n            self.logger.exception(\n                \"Error executing task\", task_id=task_request.task_id, task_type=task_request.task_type, error=str(e)\n            )\n\n            # Send failure result\n            await self._send_task_result(task_id=task_request.task_id, status=\"failure\", error=str(e))\n\n        # Remove from active tasks\n        if task_request.task_id in self._active_tasks:\n            del self._active_tasks[task_request.task_id]\n\n    async def _send_task_result(\n        self, task_id: str, status: str, result: Any = None, error: Optional[str] = None\n    ) -&gt; None:\n        \"\"\"Send a task result back to the orchestrator.\n\n        Args:\n            task_id: The ID of the task\n            status: The status of the task (\"success\", \"failure\")\n            result: The result of the task\n            error: Error message if the task failed\n        \"\"\"\n        task_info = self._active_tasks.get(task_id, {})\n        orchestrator = task_info.get(\"metadata\", {}).get(\"orchestrator\")\n\n        # If we don't know which orchestrator to send to, send to all\n        if not orchestrator:\n            for orch in self._orchestrators:\n                await self._send_result_to_orchestrator(\n                    orchestrator=orch, task_id=task_id, status=status, result=result, error=error\n                )\n        else:\n            await self._send_result_to_orchestrator(\n                orchestrator=orchestrator, task_id=task_id, status=status, result=result, error=error\n            )\n\n    async def _send_result_to_orchestrator(\n        self, orchestrator: str, task_id: str, status: str, result: Any = None, error: Optional[str] = None\n    ) -&gt; None:\n        \"\"\"Send a task result to a specific orchestrator.\n\n        Args:\n            orchestrator: The name of the orchestrator\n            task_id: The ID of the task\n            status: The status of the task\n            result: The result of the task\n            error: Error message if the task failed\n        \"\"\"\n        task_result = TaskResult(\n            task_id=task_id, status=status, result=result, error=error, metadata={\"worker\": self.name}\n        )\n\n        try:\n            await self.communicator.send_notification(\n                target_service=orchestrator, method=\"task_result\", params=task_result.model_dump()\n            )\n\n            self.logger.debug(\"Sent task result\", task_id=task_id, orchestrator=orchestrator, status=status)\n\n        except Exception as e:\n            self.logger.error(\"Error sending task result\", task_id=task_id, orchestrator=orchestrator, error=str(e))\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseWorkerAgent.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initialize the worker agent.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the worker agent.\"\"\"\n    super().__init__(*args, **kwargs)\n\n    # Dictionary mapping task types to handler methods\n    self._task_handlers: Dict[str, Callable] = {}\n\n    # Set of orchestrators this worker is registered with\n    self._orchestrators: Set[str] = set()\n\n    # Dict of active tasks being processed\n    self._active_tasks: Dict[str, Dict[str, Any]] = {}\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseWorkerAgent.register_with_orchestrator","title":"<code>register_with_orchestrator(orchestrator_name)</code>  <code>async</code>","text":"<p>Register this worker with an orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>orchestrator_name</code> <code>str</code> <p>The name of the orchestrator to register with</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if registration was successful, False otherwise</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>async def register_with_orchestrator(self, orchestrator_name: str) -&gt; bool:\n    \"\"\"Register this worker with an orchestrator.\n\n    Args:\n        orchestrator_name: The name of the orchestrator to register with\n\n    Returns:\n        True if registration was successful, False otherwise\n    \"\"\"\n    try:\n        response = await self.communicator.send_request(\n            target_service=orchestrator_name,\n            method=\"register_worker\",\n            params={\n                \"name\": self.name,\n                \"capabilities\": list(self._task_handlers.keys()),\n                \"metadata\": {\"agent_type\": self.__class__.__name__},\n            },\n        )\n\n        if response.get(\"status\") == \"registered\":\n            self._orchestrators.add(orchestrator_name)\n            self.logger.info(\"Registered with orchestrator\", orchestrator=orchestrator_name)\n            return True\n\n        self.logger.warning(\n            \"Failed to register with orchestrator\", orchestrator=orchestrator_name, response=response\n        )\n        return False\n\n    except Exception as e:\n        self.logger.error(\"Error registering with orchestrator\", orchestrator=orchestrator_name, error=str(e))\n        return False\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.BaseWorkerAgent.setup","title":"<code>setup()</code>  <code>async</code>","text":"<p>Set up the worker agent.</p> <p>Discovers and registers task handlers, registers with orchestrators, and sets up communication handlers.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>async def setup(self) -&gt; None:\n    \"\"\"Set up the worker agent.\n\n    Discovers and registers task handlers, registers with orchestrators,\n    and sets up communication handlers.\n    \"\"\"\n    # Discover task handlers from class methods\n    self._discover_task_handlers()\n\n    # Register handler for executing tasks\n    await self.communicator.register_handler(\"execute_task\", self._handle_execute_task)\n\n    # Register handler for discovery requests\n    await self.communicator.register_handler(\"discover_workers\", self._handle_discovery)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.TaskHandler","title":"<code>TaskHandler</code>","text":"<p>A decorator for registering task handlers in worker agents.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>class TaskHandler:\n    \"\"\"A decorator for registering task handlers in worker agents.\"\"\"\n\n    def __init__(self, task_type: str, description: str = \"\"):\n        \"\"\"Initialize the task handler decorator.\n\n        Args:\n            task_type: The type of task this handler can process\n            description: A description of the task handler\n        \"\"\"\n        self.task_type = task_type\n        self.description = description\n\n    def __call__(self, func: Callable) -&gt; Callable:\n        \"\"\"Decorate a method as a task handler.\n\n        Args:\n            func: The method to decorate\n\n        Returns:\n            The decorated method\n        \"\"\"\n        setattr(func, \"_task_handler\", {\"task_type\": self.task_type, \"description\": self.description})\n        return func\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.TaskHandler.__call__","title":"<code>__call__(func)</code>","text":"<p>Decorate a method as a task handler.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>The method to decorate</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>The decorated method</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>def __call__(self, func: Callable) -&gt; Callable:\n    \"\"\"Decorate a method as a task handler.\n\n    Args:\n        func: The method to decorate\n\n    Returns:\n        The decorated method\n    \"\"\"\n    setattr(func, \"_task_handler\", {\"task_type\": self.task_type, \"description\": self.description})\n    return func\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.TaskHandler.__init__","title":"<code>__init__(task_type, description='')</code>","text":"<p>Initialize the task handler decorator.</p> <p>Parameters:</p> Name Type Description Default <code>task_type</code> <code>str</code> <p>The type of task this handler can process</p> required <code>description</code> <code>str</code> <p>A description of the task handler</p> <code>''</code> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>def __init__(self, task_type: str, description: str = \"\"):\n    \"\"\"Initialize the task handler decorator.\n\n    Args:\n        task_type: The type of task this handler can process\n        description: A description of the task handler\n    \"\"\"\n    self.task_type = task_type\n    self.description = description\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.TaskRequest","title":"<code>TaskRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A task request sent from an orchestrator to a worker.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>class TaskRequest(BaseModel):\n    \"\"\"A task request sent from an orchestrator to a worker.\"\"\"\n\n    task_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    task_type: str\n    parameters: Dict[str, Any] = Field(default_factory=dict)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.TaskResult","title":"<code>TaskResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A task result sent from a worker to an orchestrator.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>class TaskResult(BaseModel):\n    \"\"\"A task result sent from a worker to an orchestrator.\"\"\"\n\n    task_id: str\n    status: str  # \"success\", \"failure\", \"in_progress\"\n    result: Optional[Any] = None\n    error: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.orchestrator.WorkerInfo","title":"<code>WorkerInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a worker agent.</p> Source code in <code>src/openmas/patterns/orchestrator.py</code> <pre><code>class WorkerInfo(BaseModel):\n    \"\"\"Information about a worker agent.\"\"\"\n\n    name: str\n    capabilities: Set[str] = Field(default_factory=set)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ServiceChain","title":"<code>ServiceChain</code>","text":"<p>A chain of service calls that can be executed sequentially.</p> <p>The ServiceChain allows defining a sequence of API calls to different services, with the ability to pass data between steps, transform inputs/outputs, apply conditions, retry logic, and error handling.</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>class ServiceChain:\n    \"\"\"A chain of service calls that can be executed sequentially.\n\n    The ServiceChain allows defining a sequence of API calls to different services,\n    with the ability to pass data between steps, transform inputs/outputs, apply\n    conditions, retry logic, and error handling.\n    \"\"\"\n\n    def __init__(self, communicator: Any, name: str = \"service_chain\"):\n        \"\"\"Initialize the ServiceChain.\n\n        Args:\n            communicator: The communicator to use for service calls\n            name: Name of this chain for logging purposes\n        \"\"\"\n        self.communicator = communicator\n        self.name = name\n        self.steps: List[ChainStep] = []\n        self.logger = logger.bind(chain_name=name)\n\n    def add_step(\n        self,\n        target_service: str,\n        method: str,\n        parameters: Optional[Dict[str, Any]] = None,\n        name: Optional[str] = None,\n        retry_count: int = 0,\n        retry_delay: float = 1.0,\n        timeout: Optional[float] = None,\n        condition: Optional[Callable[[Dict[str, Any]], bool]] = None,\n        transform_input: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None,\n        transform_output: Optional[Callable[[Any], Any]] = None,\n        error_handler: Optional[Callable[[Exception, Dict[str, Any]], Any]] = None,\n    ) -&gt; \"ServiceChain\":\n        \"\"\"Add a step to the chain.\n\n        Args:\n            target_service: The target service for this step\n            method: The method to call on the service\n            parameters: Parameters to pass to the method\n            name: Optional name for this step\n            retry_count: Number of times to retry on failure\n            retry_delay: Delay between retries in seconds\n            timeout: Timeout for this step in seconds\n            condition: Optional condition function to determine if this step should execute\n            transform_input: Optional function to transform input parameters\n            transform_output: Optional function to transform the output\n            error_handler: Optional function to handle errors\n\n        Returns:\n            The chain instance for method chaining\n        \"\"\"\n        step = ChainStep(\n            target_service=target_service,\n            method=method,\n            parameters=parameters or {},\n            name=name or f\"{target_service}.{method}\",\n            retry_count=retry_count,\n            retry_delay=retry_delay,\n            timeout=timeout,\n            condition=condition,\n            transform_input=transform_input,\n            transform_output=transform_output,\n            error_handler=error_handler,\n        )\n        self.steps.append(step)\n        return self\n\n    async def execute(self, initial_context: Optional[Dict[str, Any]] = None) -&gt; ChainResult:\n        \"\"\"Execute the chain of service calls.\n\n        Args:\n            initial_context: Optional initial context data\n\n        Returns:\n            Result of the chain execution\n        \"\"\"\n        context = initial_context or {}\n        chain_result = ChainResult()\n\n        # Track execution time\n        start_time = asyncio.get_event_loop().time()\n\n        # Execute steps sequentially\n        for step in self.steps:\n            step_result = await self._execute_step(step, context)\n            chain_result.results.append(step_result)\n\n            # Add result to context for next steps\n            if step.name is not None:\n                context[step.name] = step_result.result\n\n            # Exit early if a step failed and no error handler recovered\n            if step_result.status == ChainStepStatus.FAILURE:\n                chain_result.successful = False\n                break\n\n        # Calculate total execution time\n        chain_result.execution_time = asyncio.get_event_loop().time() - start_time\n\n        # Set the final result to the result of the last successful step\n        for step_result in reversed(chain_result.results):\n            if step_result.status == ChainStepStatus.SUCCESS:\n                chain_result.final_result = step_result.result\n                break\n\n        return chain_result\n\n    async def _execute_step(self, step: ChainStep, context: Dict[str, Any]) -&gt; ChainStepResult:\n        \"\"\"Execute a single step in the chain.\n\n        Args:\n            step: The step to execute\n            context: The current context with results from previous steps\n\n        Returns:\n            Result of the step execution\n        \"\"\"\n        result = ChainStepResult(step=step, status=ChainStepStatus.PENDING)\n\n        # Check condition\n        if step.condition is not None and not step.condition(context):\n            result.status = ChainStepStatus.SKIPPED\n            self.logger.info(f\"Step {step.name} skipped due to condition\", step=step.name)\n            return result\n\n        # Track execution time\n        start_time = asyncio.get_event_loop().time()\n        result.status = ChainStepStatus.IN_PROGRESS\n\n        # Prepare parameters with context\n        parameters = self._prepare_parameters(step, context)\n\n        # Execute with retry logic\n        attempt = 0\n        while True:\n            attempt += 1\n            result.attempt_count = attempt\n\n            try:\n                response = await self.communicator.send_request(\n                    target_service=step.target_service,\n                    method=step.method,\n                    params=parameters,\n                    timeout=step.timeout,\n                )\n\n                # Process successful response\n                if step.transform_output:\n                    response = step.transform_output(response)\n\n                result.result = response\n                result.status = ChainStepStatus.SUCCESS\n                result.execution_time = asyncio.get_event_loop().time() - start_time\n\n                self.logger.debug(\n                    f\"Step {step.name} executed successfully\",\n                    step=step.name,\n                    attempt=attempt,\n                    execution_time=result.execution_time,\n                )\n                break\n\n            except Exception as e:\n                # Handle error\n                if step.error_handler:\n                    try:\n                        # Try to recover with the error handler\n                        recovery_result = step.error_handler(e, context)\n                        result.result = recovery_result\n                        result.status = ChainStepStatus.SUCCESS\n                        result.execution_time = asyncio.get_event_loop().time() - start_time\n\n                        self.logger.info(\n                            f\"Step {step.name} recovered from error with handler\",\n                            step=step.name,\n                            error=str(e),\n                            attempt=attempt,\n                        )\n                        break\n                    except Exception as recovery_error:\n                        # Error handler failed\n                        self.logger.warning(\n                            f\"Error handler for step {step.name} failed\",\n                            step=step.name,\n                            error=str(recovery_error),\n                        )\n\n                # Check if we should retry\n                if attempt &lt;= step.retry_count:\n                    self.logger.info(\n                        f\"Retrying step {step.name} after error (attempt {attempt}/{step.retry_count})\",\n                        step=step.name,\n                        error=str(e),\n                        attempt=attempt,\n                        retry_delay=step.retry_delay,\n                    )\n                    await asyncio.sleep(step.retry_delay)\n                    continue\n\n                # No more retries, mark as failed\n                result.status = ChainStepStatus.FAILURE\n                result.error = str(e)\n                result.execution_time = asyncio.get_event_loop().time() - start_time\n\n                self.logger.error(\n                    f\"Step {step.name} failed after {attempt} attempts\",\n                    step=step.name,\n                    error=str(e),\n                    attempt=attempt,\n                )\n                break\n\n        return result\n\n    def _prepare_parameters(self, step: ChainStep, context: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Prepare parameters for a step, incorporating context data.\n\n        Args:\n            step: The step being executed\n            context: The current context with results from previous steps\n\n        Returns:\n            The prepared parameters\n        \"\"\"\n        # Start with the step's defined parameters\n        parameters = step.parameters.copy()\n\n        # Look for placeholders in the parameters to substitute with context values\n        for key, value in parameters.items():\n            if isinstance(value, str) and value.startswith(\"$\"):\n                context_key = value[1:]\n                if context_key in context:\n                    parameters[key] = context[context_key]\n\n        # Apply transform_input if defined\n        if step.transform_input:\n            parameters = step.transform_input(context)\n\n        return parameters\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ServiceChain.__init__","title":"<code>__init__(communicator, name='service_chain')</code>","text":"<p>Initialize the ServiceChain.</p> <p>Parameters:</p> Name Type Description Default <code>communicator</code> <code>Any</code> <p>The communicator to use for service calls</p> required <code>name</code> <code>str</code> <p>Name of this chain for logging purposes</p> <code>'service_chain'</code> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>def __init__(self, communicator: Any, name: str = \"service_chain\"):\n    \"\"\"Initialize the ServiceChain.\n\n    Args:\n        communicator: The communicator to use for service calls\n        name: Name of this chain for logging purposes\n    \"\"\"\n    self.communicator = communicator\n    self.name = name\n    self.steps: List[ChainStep] = []\n    self.logger = logger.bind(chain_name=name)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ServiceChain.add_step","title":"<code>add_step(target_service, method, parameters=None, name=None, retry_count=0, retry_delay=1.0, timeout=None, condition=None, transform_input=None, transform_output=None, error_handler=None)</code>","text":"<p>Add a step to the chain.</p> <p>Parameters:</p> Name Type Description Default <code>target_service</code> <code>str</code> <p>The target service for this step</p> required <code>method</code> <code>str</code> <p>The method to call on the service</p> required <code>parameters</code> <code>Optional[Dict[str, Any]]</code> <p>Parameters to pass to the method</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Optional name for this step</p> <code>None</code> <code>retry_count</code> <code>int</code> <p>Number of times to retry on failure</p> <code>0</code> <code>retry_delay</code> <code>float</code> <p>Delay between retries in seconds</p> <code>1.0</code> <code>timeout</code> <code>Optional[float]</code> <p>Timeout for this step in seconds</p> <code>None</code> <code>condition</code> <code>Optional[Callable[[Dict[str, Any]], bool]]</code> <p>Optional condition function to determine if this step should execute</p> <code>None</code> <code>transform_input</code> <code>Optional[Callable[[Dict[str, Any]], Dict[str, Any]]]</code> <p>Optional function to transform input parameters</p> <code>None</code> <code>transform_output</code> <code>Optional[Callable[[Any], Any]]</code> <p>Optional function to transform the output</p> <code>None</code> <code>error_handler</code> <code>Optional[Callable[[Exception, Dict[str, Any]], Any]]</code> <p>Optional function to handle errors</p> <code>None</code> <p>Returns:</p> Type Description <code>ServiceChain</code> <p>The chain instance for method chaining</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>def add_step(\n    self,\n    target_service: str,\n    method: str,\n    parameters: Optional[Dict[str, Any]] = None,\n    name: Optional[str] = None,\n    retry_count: int = 0,\n    retry_delay: float = 1.0,\n    timeout: Optional[float] = None,\n    condition: Optional[Callable[[Dict[str, Any]], bool]] = None,\n    transform_input: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None,\n    transform_output: Optional[Callable[[Any], Any]] = None,\n    error_handler: Optional[Callable[[Exception, Dict[str, Any]], Any]] = None,\n) -&gt; \"ServiceChain\":\n    \"\"\"Add a step to the chain.\n\n    Args:\n        target_service: The target service for this step\n        method: The method to call on the service\n        parameters: Parameters to pass to the method\n        name: Optional name for this step\n        retry_count: Number of times to retry on failure\n        retry_delay: Delay between retries in seconds\n        timeout: Timeout for this step in seconds\n        condition: Optional condition function to determine if this step should execute\n        transform_input: Optional function to transform input parameters\n        transform_output: Optional function to transform the output\n        error_handler: Optional function to handle errors\n\n    Returns:\n        The chain instance for method chaining\n    \"\"\"\n    step = ChainStep(\n        target_service=target_service,\n        method=method,\n        parameters=parameters or {},\n        name=name or f\"{target_service}.{method}\",\n        retry_count=retry_count,\n        retry_delay=retry_delay,\n        timeout=timeout,\n        condition=condition,\n        transform_input=transform_input,\n        transform_output=transform_output,\n        error_handler=error_handler,\n    )\n    self.steps.append(step)\n    return self\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ServiceChain.execute","title":"<code>execute(initial_context=None)</code>  <code>async</code>","text":"<p>Execute the chain of service calls.</p> <p>Parameters:</p> Name Type Description Default <code>initial_context</code> <code>Optional[Dict[str, Any]]</code> <p>Optional initial context data</p> <code>None</code> <p>Returns:</p> Type Description <code>ChainResult</code> <p>Result of the chain execution</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>async def execute(self, initial_context: Optional[Dict[str, Any]] = None) -&gt; ChainResult:\n    \"\"\"Execute the chain of service calls.\n\n    Args:\n        initial_context: Optional initial context data\n\n    Returns:\n        Result of the chain execution\n    \"\"\"\n    context = initial_context or {}\n    chain_result = ChainResult()\n\n    # Track execution time\n    start_time = asyncio.get_event_loop().time()\n\n    # Execute steps sequentially\n    for step in self.steps:\n        step_result = await self._execute_step(step, context)\n        chain_result.results.append(step_result)\n\n        # Add result to context for next steps\n        if step.name is not None:\n            context[step.name] = step_result.result\n\n        # Exit early if a step failed and no error handler recovered\n        if step_result.status == ChainStepStatus.FAILURE:\n            chain_result.successful = False\n            break\n\n    # Calculate total execution time\n    chain_result.execution_time = asyncio.get_event_loop().time() - start_time\n\n    # Set the final result to the result of the last successful step\n    for step_result in reversed(chain_result.results):\n        if step_result.status == ChainStepStatus.SUCCESS:\n            chain_result.final_result = step_result.result\n            break\n\n    return chain_result\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ChainBuilder","title":"<code>ChainBuilder</code>","text":"<p>A builder for creating and executing service chains.</p> <p>This builder provides a fluent interface for constructing service chains.</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>class ChainBuilder:\n    \"\"\"A builder for creating and executing service chains.\n\n    This builder provides a fluent interface for constructing service chains.\n    \"\"\"\n\n    def __init__(self, communicator: Any, name: str = \"service_chain\"):\n        \"\"\"Initialize the ChainBuilder.\n\n        Args:\n            communicator: The communicator to use for service calls\n            name: Name of this chain for logging purposes\n        \"\"\"\n        self.chain = ServiceChain(communicator, name)\n\n    def add_step(\n        self,\n        target_service: str,\n        method: str,\n        parameters: Optional[Dict[str, Any]] = None,\n        name: Optional[str] = None,\n        retry_count: int = 0,\n        retry_delay: float = 1.0,\n        timeout: Optional[float] = None,\n        condition: Optional[Callable[[Dict[str, Any]], bool]] = None,\n        transform_input: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None,\n        transform_output: Optional[Callable[[Any], Any]] = None,\n        error_handler: Optional[Callable[[Exception, Dict[str, Any]], Any]] = None,\n    ) -&gt; \"ChainBuilder\":\n        \"\"\"Add a step to the chain.\n\n        Args:\n            target_service: The target service for this step\n            method: The method to call on the service\n            parameters: Parameters to pass to the method\n            name: Optional name for this step\n            retry_count: Number of times to retry on failure\n            retry_delay: Delay between retries in seconds\n            timeout: Timeout for this step in seconds\n            condition: Optional condition function to determine if this step should execute\n            transform_input: Optional function to transform input parameters\n            transform_output: Optional function to transform the output\n            error_handler: Optional function to handle errors\n\n        Returns:\n            The builder instance for method chaining\n        \"\"\"\n        self.chain.add_step(\n            target_service=target_service,\n            method=method,\n            parameters=parameters,\n            name=name,\n            retry_count=retry_count,\n            retry_delay=retry_delay,\n            timeout=timeout,\n            condition=condition,\n            transform_input=transform_input,\n            transform_output=transform_output,\n            error_handler=error_handler,\n        )\n        return self\n\n    def build(self) -&gt; ServiceChain:\n        \"\"\"Build and return the service chain.\n\n        Returns:\n            The constructed service chain\n        \"\"\"\n        return self.chain\n\n    async def execute(self, initial_context: Optional[Dict[str, Any]] = None) -&gt; ChainResult:\n        \"\"\"Build and execute the service chain.\n\n        Args:\n            initial_context: Optional initial context data\n\n        Returns:\n            Result of the chain execution\n        \"\"\"\n        return await self.chain.execute(initial_context)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ChainBuilder.__init__","title":"<code>__init__(communicator, name='service_chain')</code>","text":"<p>Initialize the ChainBuilder.</p> <p>Parameters:</p> Name Type Description Default <code>communicator</code> <code>Any</code> <p>The communicator to use for service calls</p> required <code>name</code> <code>str</code> <p>Name of this chain for logging purposes</p> <code>'service_chain'</code> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>def __init__(self, communicator: Any, name: str = \"service_chain\"):\n    \"\"\"Initialize the ChainBuilder.\n\n    Args:\n        communicator: The communicator to use for service calls\n        name: Name of this chain for logging purposes\n    \"\"\"\n    self.chain = ServiceChain(communicator, name)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ChainBuilder.add_step","title":"<code>add_step(target_service, method, parameters=None, name=None, retry_count=0, retry_delay=1.0, timeout=None, condition=None, transform_input=None, transform_output=None, error_handler=None)</code>","text":"<p>Add a step to the chain.</p> <p>Parameters:</p> Name Type Description Default <code>target_service</code> <code>str</code> <p>The target service for this step</p> required <code>method</code> <code>str</code> <p>The method to call on the service</p> required <code>parameters</code> <code>Optional[Dict[str, Any]]</code> <p>Parameters to pass to the method</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>Optional name for this step</p> <code>None</code> <code>retry_count</code> <code>int</code> <p>Number of times to retry on failure</p> <code>0</code> <code>retry_delay</code> <code>float</code> <p>Delay between retries in seconds</p> <code>1.0</code> <code>timeout</code> <code>Optional[float]</code> <p>Timeout for this step in seconds</p> <code>None</code> <code>condition</code> <code>Optional[Callable[[Dict[str, Any]], bool]]</code> <p>Optional condition function to determine if this step should execute</p> <code>None</code> <code>transform_input</code> <code>Optional[Callable[[Dict[str, Any]], Dict[str, Any]]]</code> <p>Optional function to transform input parameters</p> <code>None</code> <code>transform_output</code> <code>Optional[Callable[[Any], Any]]</code> <p>Optional function to transform the output</p> <code>None</code> <code>error_handler</code> <code>Optional[Callable[[Exception, Dict[str, Any]], Any]]</code> <p>Optional function to handle errors</p> <code>None</code> <p>Returns:</p> Type Description <code>ChainBuilder</code> <p>The builder instance for method chaining</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>def add_step(\n    self,\n    target_service: str,\n    method: str,\n    parameters: Optional[Dict[str, Any]] = None,\n    name: Optional[str] = None,\n    retry_count: int = 0,\n    retry_delay: float = 1.0,\n    timeout: Optional[float] = None,\n    condition: Optional[Callable[[Dict[str, Any]], bool]] = None,\n    transform_input: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None,\n    transform_output: Optional[Callable[[Any], Any]] = None,\n    error_handler: Optional[Callable[[Exception, Dict[str, Any]], Any]] = None,\n) -&gt; \"ChainBuilder\":\n    \"\"\"Add a step to the chain.\n\n    Args:\n        target_service: The target service for this step\n        method: The method to call on the service\n        parameters: Parameters to pass to the method\n        name: Optional name for this step\n        retry_count: Number of times to retry on failure\n        retry_delay: Delay between retries in seconds\n        timeout: Timeout for this step in seconds\n        condition: Optional condition function to determine if this step should execute\n        transform_input: Optional function to transform input parameters\n        transform_output: Optional function to transform the output\n        error_handler: Optional function to handle errors\n\n    Returns:\n        The builder instance for method chaining\n    \"\"\"\n    self.chain.add_step(\n        target_service=target_service,\n        method=method,\n        parameters=parameters,\n        name=name,\n        retry_count=retry_count,\n        retry_delay=retry_delay,\n        timeout=timeout,\n        condition=condition,\n        transform_input=transform_input,\n        transform_output=transform_output,\n        error_handler=error_handler,\n    )\n    return self\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ChainBuilder.build","title":"<code>build()</code>","text":"<p>Build and return the service chain.</p> <p>Returns:</p> Type Description <code>ServiceChain</code> <p>The constructed service chain</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>def build(self) -&gt; ServiceChain:\n    \"\"\"Build and return the service chain.\n\n    Returns:\n        The constructed service chain\n    \"\"\"\n    return self.chain\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.ChainBuilder.execute","title":"<code>execute(initial_context=None)</code>  <code>async</code>","text":"<p>Build and execute the service chain.</p> <p>Parameters:</p> Name Type Description Default <code>initial_context</code> <code>Optional[Dict[str, Any]]</code> <p>Optional initial context data</p> <code>None</code> <p>Returns:</p> Type Description <code>ChainResult</code> <p>Result of the chain execution</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>async def execute(self, initial_context: Optional[Dict[str, Any]] = None) -&gt; ChainResult:\n    \"\"\"Build and execute the service chain.\n\n    Args:\n        initial_context: Optional initial context data\n\n    Returns:\n        Result of the chain execution\n    \"\"\"\n    return await self.chain.execute(initial_context)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.create_chain","title":"<code>create_chain(communicator, name='service_chain')</code>","text":"<p>Create a new service chain builder.</p> <p>Parameters:</p> Name Type Description Default <code>communicator</code> <code>Any</code> <p>The communicator to use for service calls</p> required <code>name</code> <code>str</code> <p>Name of this chain for logging purposes</p> <code>'service_chain'</code> <p>Returns:</p> Type Description <code>ChainBuilder</code> <p>A new chain builder</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>def create_chain(communicator: Any, name: str = \"service_chain\") -&gt; ChainBuilder:\n    \"\"\"Create a new service chain builder.\n\n    Args:\n        communicator: The communicator to use for service calls\n        name: Name of this chain for logging purposes\n\n    Returns:\n        A new chain builder\n    \"\"\"\n    return ChainBuilder(communicator, name)\n</code></pre>"},{"location":"api_reference/#openmas.patterns.chaining.execute_chain","title":"<code>execute_chain(communicator, steps, initial_context=None, name='service_chain')</code>  <code>async</code>","text":"<p>Execute a chain of service calls defined by steps.</p> <p>This is a convenience function for creating and executing a chain in a single call.</p> <p>Parameters:</p> Name Type Description Default <code>communicator</code> <code>Any</code> <p>The communicator to use for service calls</p> required <code>steps</code> <code>List[Dict[str, Any]]</code> <p>List of step definitions, each a dict with parameters for add_step</p> required <code>initial_context</code> <code>Optional[Dict[str, Any]]</code> <p>Optional initial context data</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of this chain for logging purposes</p> <code>'service_chain'</code> <p>Returns:</p> Type Description <code>ChainResult</code> <p>Result of the chain execution</p> Source code in <code>src/openmas/patterns/chaining.py</code> <pre><code>async def execute_chain(\n    communicator: Any,\n    steps: List[Dict[str, Any]],\n    initial_context: Optional[Dict[str, Any]] = None,\n    name: str = \"service_chain\",\n) -&gt; ChainResult:\n    \"\"\"Execute a chain of service calls defined by steps.\n\n    This is a convenience function for creating and executing a chain in a single call.\n\n    Args:\n        communicator: The communicator to use for service calls\n        steps: List of step definitions, each a dict with parameters for add_step\n        initial_context: Optional initial context data\n        name: Name of this chain for logging purposes\n\n    Returns:\n        Result of the chain execution\n    \"\"\"\n    builder = ChainBuilder(communicator, name)\n\n    for step_def in steps:\n        builder.add_step(**step_def)\n\n    return await builder.execute(initial_context)\n</code></pre>"},{"location":"api_reference/#deployment","title":"Deployment","text":"<p>Generators for deployment configurations from OpenMAS metadata.</p>"},{"location":"communicator_extensions/","title":"Communicator Extension System","text":"<p>OpenMAS provides a robust system for discovering and using communicator extensions. This allows for extending the framework with custom communication methods, both as installable packages (via entry points) and as local project extensions.</p>"},{"location":"communicator_extensions/#types-of-extensions","title":"Types of Extensions","text":"<p>The communicator extension system supports three types of extension sources:</p> <ol> <li>Built-in Communicators: These are included with the OpenMAS package (<code>HttpCommunicator</code>, etc.)</li> <li>Entry Point Extensions: These are installed packages that register communicators via the <code>openmas.communicators</code> entry point</li> <li>Local Extensions: These are project-local communicator implementations found in directories specified in <code>extension_paths</code></li> </ol>"},{"location":"communicator_extensions/#using-communicator-extensions","title":"Using Communicator Extensions","text":"<p>To use a specific communicator in your agent, you can:</p> <ol> <li>Set it in the configuration:</li> </ol> <pre><code>config = {\n    \"name\": \"my_agent\",\n    \"communicator_type\": \"my_custom_communicator\",\n    \"extension_paths\": [\"./my_extensions\"]  # Optional: For local extensions\n}\nagent = MyAgent(config=config)\n</code></pre> <ol> <li>Pass it directly to the constructor:</li> </ol> <pre><code>from my_package import MyCustomCommunicator\n\nagent = MyAgent(\n    name=\"my_agent\",\n    communicator_class=MyCustomCommunicator\n)\n</code></pre>"},{"location":"communicator_extensions/#creating-communicator-extensions","title":"Creating Communicator Extensions","text":"<p>There are two ways to create and distribute communicator extensions:</p>"},{"location":"communicator_extensions/#1-as-an-installable-package-entry-points","title":"1. As an Installable Package (Entry Points)","text":"<p>To create a communicator extension as an installable package:</p> <ol> <li>Create a subclass of <code>BaseCommunicator</code>:</li> </ol> <pre><code>from openmas.communication import BaseCommunicator\n\nclass MyCustomCommunicator(BaseCommunicator):\n    async def send_request(self, target_service, method, params=None, response_model=None, timeout=None):\n        # Your implementation here\n        ...\n\n    async def send_notification(self, target_service, method, params=None):\n        # Your implementation here\n        ...\n\n    async def register_handler(self, method, handler):\n        # Your implementation here\n        ...\n\n    async def start(self):\n        # Your implementation here\n        ...\n\n    async def stop(self):\n        # Your implementation here\n        ...\n</code></pre> <ol> <li>Register it as an entry point in your package's <code>pyproject.toml</code>:</li> </ol> <pre><code>[project.entry-points.\"openmas.communicators\"]\nmy_communicator = \"my_package.module:MyCustomCommunicator\"\n</code></pre> <p>Or in <code>setup.py</code>:</p> <pre><code>setup(\n    # ...\n    entry_points={\n        'openmas.communicators': [\n            'my_communicator = my_package.module:MyCustomCommunicator',\n        ],\n    },\n    # ...\n)\n</code></pre>"},{"location":"communicator_extensions/#2-as-a-local-extension","title":"2. As a Local Extension","text":"<p>To create a communicator as a local extension:</p> <ol> <li>Create a Python file in your project directory (e.g., <code>./extensions/my_communicator.py</code>):</li> </ol> <pre><code>from openmas.communication import BaseCommunicator\n\nclass MyLocalCommunicator(BaseCommunicator):\n    # Implementation as above\n    ...\n</code></pre> <ol> <li>Specify the extension path in your agent configuration:</li> </ol> <pre><code>config = {\n    \"name\": \"my_agent\",\n    \"communicator_type\": \"my_communicator\",  # Uses the filename without .py\n    \"extension_paths\": [\"./extensions\"]\n}\nagent = MyAgent(config=config)\n</code></pre>"},{"location":"communicator_extensions/#discovery-order","title":"Discovery Order","text":"<p>When resolving a communicator type, OpenMAS uses the following order:</p> <ol> <li>Check if a communicator class is directly provided to the agent constructor</li> <li>Look for the type in the registry (built-ins and entry points)</li> <li>Search local extension paths for matching communicator implementations</li> </ol>"},{"location":"communicator_extensions/#environment-configuration","title":"Environment Configuration","text":"<p>You can also configure the communicator type and extension paths through environment variables:</p> <pre><code>export COMMUNICATOR_TYPE=my_communicator\nexport EXTENSION_PATHS='[\"./extensions\"]'  # JSON array\n</code></pre> <p>For agent-specific configuration with a prefix:</p> <pre><code>export MYAGENT_COMMUNICATOR_TYPE=my_communicator\nexport MYAGENT_EXTENSION_PATHS='[\"./extensions\"]'\n</code></pre> <p>Then initialize the agent with:</p> <pre><code>agent = MyAgent(env_prefix=\"MYAGENT\")\n</code></pre>"},{"location":"examples/","title":"OpenMAS Examples","text":"<p>The <code>examples/</code> directory within the OpenMAS source code repository plays a crucial role in the development and usability of the framework.</p>"},{"location":"examples/#purpose-of-examples","title":"Purpose of Examples","text":"<p>The examples serve multiple key purposes:</p> <ol> <li> <p>Contributor Testing &amp; Dogfooding:</p> <ul> <li>Examples provide concrete, runnable scenarios used in the framework's internal testing pipeline (<code>tox</code>).</li> <li>Running tests against these examples ensures that core framework features, SDK components, and CLI commands work as expected across different use cases (e.g., various communicators, agent patterns).</li> <li>The process of creating and maintaining these examples acts as a primary \"dogfooding\" mechanism, forcing developers contributing to OpenMAS to use the framework's own tools and abstractions, thereby identifying usability issues or bugs.</li> </ul> </li> <li> <p>User Learning &amp; Guidance:</p> <ul> <li>While not installed via <code>pip</code>, users can browse the examples directly in the OpenMAS GitHub repository.</li> <li>They serve as practical, self-contained illustrations of how to implement specific features (like using a particular communicator), patterns (like request-response), or integrations.</li> <li>The documentation often references these examples or includes snippets from them to provide concrete context.</li> <li>(Future Consideration: A command like <code>openmas examples download &lt;example_name&gt;</code> might be added to easily fetch example code locally.)</li> </ul> </li> <li> <p>Best Practice Demonstration:</p> <ul> <li>Examples showcase recommended ways to structure simple OpenMAS projects, define agents, configure communication, handle basic lifecycle events, and use the <code>openmas</code> CLI for local execution.</li> </ul> </li> </ol>"},{"location":"examples/#example-structure","title":"Example Structure","text":"<p>The <code>examples/</code> directory is organized as follows.  This documentation presents a categorized structure for improved user understanding.</p>"},{"location":"examples/#conceptual-category-view","title":"Conceptual Category View","text":"<p>The examples are organized into the following categories:</p> <pre><code>examples/\n\u251c\u2500\u2500 example_00_hello_agent/                          # Basic agent run\n\u2502   \u251c\u2500\u2500 00_single/                                   # Leaf example: Single basic agent\n\u2502   \u2502   \u251c\u2500\u2500 agents/hello_agent_single/agent.py       # The agent code\n\u2502   \u2502   \u251c\u2500\u2500 openmas_project.yml                      # Minimal project config\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt                         # Example-specific Python deps\n\u2502   \u2502   \u251c\u2500\u2500 test_example.py                          # Internal test script (pytest)\n\u2502   \u2502   \u2514\u2500\u2500 README.md                                # How to run THIS example\n\u2502   \u2514\u2500\u2500 01_multi_mock/                               # Leaf example: Two agents communicating\n\u2502       \u2514\u2500\u2500 ... (similar files: agents/, openmas_project.yml, etc.)\n\u251c\u2500\u2500 example_01_communication_basics/                 # Communication Basics\n\u2502   \u251c\u2500\u2500 http_client_server/                          # HTTP Communication\n\u2502   \u251c\u2500\u2500 mcp_stdio_external/                          # MCP stdio Communication\n\u2502   \u251c\u2500\u2500 mcp_sse_internal/                            # MCP SSE Communication\n\u2502   \u251c\u2500\u2500 grpc_request_reply/                          # gRPC Communication\n\u2502   \u251c\u2500\u2500 mq_publish_subscribe/                        # MQ Communication (RabbitMQ/Redis)\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n\u251c\u2500\u2500 example_02_configuration/                        # Configuration\n\u2502   \u2514\u2500\u2500 layered_loading/                             # Layered Configuration\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n\u251c\u2500\u2500 example_03_patterns/                             # Core Patterns\n\u2502   \u251c\u2500\u2500 orchestrator_worker/                         # Orchestrator Pattern\n\u2502   \u251c\u2500\u2500 chaining_sequence/                           # Chaining Pattern\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n\u251c\u2500\u2500 example_04_agent_features/                       # Agent Features\n\u2502   \u251c\u2500\u2500 mcp_tool_decorator/                          # MCP Tool Decorator\n\u2502   \u251c\u2500\u2500 bdi_hooks/                                   # BDI Agent Usage\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n\u251c\u2500\u2500 example_05_integrations/                         # Integrations\n\u2502   \u251c\u2500\u2500 basic_llm/                                   # LLM Integration (OpenAI/Anthropic)\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n\u251c\u2500\u2500 example_06_project_structure/                    # Project Structure\n\u2502   \u251c\u2500\u2500 local_plugin/                                # Local Plugin\n\u2502   \u251c\u2500\u2500 shared_code_usage/                           # Shared Code Usage\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n\u251c\u2500\u2500 example_07_deployment_preview/                   # Deployment Preview\n\u2502   \u2514\u2500\u2500 simple_compose_setup/                        # Docker Compose Setup\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n\u251c\u2500\u2500 example_08_mcp/                                  # MCP examples\n\u2502   \u2514\u2500\u2500 01_mcp_sse_tool_call/                        # MCP SSE tool call\n\u2502   \u2514\u2500\u2500 02_mcp_stdio_tool_call/                      # MCP stdio tool call\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n\u251c\u2500\u2500 example_09_prompt_sampling/                      # Prompt and sampling examples\n\u2502   \u2514\u2500\u2500 00_minimal/                                  # Minimal prompt &amp; sampling usage\n\u2502   \u2514\u2500\u2500 README.md                                    # Category README\n</code></pre> <p>Each leaf example directory typically contains:</p> <ul> <li>An <code>agents/</code> subdirectory with the agent code (<code>agent.py</code>).</li> <li>A minimal <code>openmas_project.yml</code> defining the agent(s) for that example.</li> <li>A <code>requirements.txt</code> for any dependencies specific to that example (beyond the core <code>openmas</code> framework).</li> <li>A <code>README.md</code> explaining the purpose of the example and how to run it manually (usually involving <code>openmas run</code>).</li> <li>A <code>test_example.py</code> file used *internally* by the framework's <code>tox</code> setup to validate the example's correctness.  This test file is for framework testing, not a template for end-user application testing.</li> </ul>"},{"location":"examples/#using-the-examples","title":"Using the Examples","text":"<ol> <li>Browse: Explore the <code>examples/</code> directory on GitHub to find scenarios relevant to your needs.</li> <li>Understand: Read the <code>README.md</code> within a specific example directory.</li> <li>Adapt: Copy relevant code snippets (agent structure, communicator configuration, handler registration) into your own OpenMAS project.</li> <li>Run Manually (Optional): To run an example locally, you would typically:<ul> <li>Clone the OpenMAS repository (<code>git clone https://github.com/dylangames/openmas.git</code>).</li> <li>Navigate into a specific example directory (e.g., <code>cd openmas/examples/example_00_hello_agent/00_single</code>).</li> <li>Set up a virtual environment and install dependencies (<code>python -m venv .venv</code>, <code>source .venv/bin/activate</code>, <code>pip install -e ../../..</code>, <code>pip install -r requirements.txt</code>).  Note the <code>-e ../../..</code> installs the main OpenMAS package from the repo root in editable mode.</li> <li>Run the agent using the <code>openmas</code> CLI (<code>openmas run hello_agent</code>).  Refer to the example's <code>README.md</code> for specific instructions.</li> </ul> </li> </ol>"},{"location":"examples/#testing-strategy-tox-pytest","title":"Testing Strategy (<code>tox</code> + <code>pytest</code>)","text":"<p>The OpenMAS project uses <code>tox</code> and <code>pytest</code> to automatically test the examples as part of its Continuous Integration (CI) process.</p> <ul> <li><code>tox.ini</code> in the repository root defines test environments for each example.</li> <li>Each environment installs <code>openmas</code> and the example's specific dependencies.</li> <li><code>tox</code> runs the <code>pytest</code> command targeting the <code>test_example.py</code> file within the example directory.</li> <li>The <code>test_example.py</code> scripts use <code>pytest</code> fixtures and assertions to instantiate the example agent(s), trigger their logic (e.g., by calling handlers or simulating communication via <code>MockCommunicator</code> or <code>AgentTestHarness</code>), and verify the expected outcomes. This ensures the framework behaves correctly for that example scenario.</li> </ul>"},{"location":"why_openmas/","title":"Why OpenMAS?","text":"<p>The landscape of Artificial Intelligence is rapidly evolving, with agentic systems \u2013 AI entities capable of autonomous reasoning, planning, and tool use \u2013 moving from research concepts to powerful real-world applications. However, building these sophisticated systems often involves significant engineering overhead, repetitive boilerplate code, and challenges in coordinating diverse capabilities.</p> <p>OpenMAS was created to address these challenges and democratize the development of sophisticated Multi-Agent Systems (MAS).</p>"},{"location":"why_openmas/#the-problem-complexity-hinders-progress","title":"The Problem: Complexity Hinders Progress","text":"<p>Developing robust agentic solutions involves more than just connecting to an LLM. Key challenges include:</p> <ul> <li>Structuring Agent Logic: How do you organize the code for agents with different responsibilities (e.g., perception, reasoning, action, communication)?</li> <li>Managing Communication: How do agents reliably exchange information and coordinate tasks, potentially using different protocols?</li> <li>Integrating Capabilities: How can agents seamlessly access diverse tools and data sources (files, databases, APIs, specialized models)?</li> <li>Lifecycle &amp; Configuration: How do you manage the startup, shutdown, and configuration of multiple interacting agents consistently?</li> <li>Developer Experience: How can we reduce the boilerplate and provide conventions to make MAS development faster, more maintainable, and less error-prone?</li> </ul>"},{"location":"why_openmas/#the-vision-empowering-developers-with-a-pragmatic-framework","title":"The Vision: Empowering Developers with a Pragmatic Framework","text":"<p>OpenMAS aims to provide a cohesive, Pythonic environment that simplifies the end-to-end lifecycle of MAS development. We believe that by providing the right abstractions, conventions, and tooling, developers can focus on the unique intelligence and capabilities of their agents, rather than reinventing the underlying infrastructure.</p>"},{"location":"why_openmas/#inspiration-learning-from-experience-and-opportunity","title":"Inspiration: Learning from Experience and Opportunity","text":"<p>The motivation for OpenMAS stems from several key insights:</p> <ol> <li>The Power of Agentic Tools: Tools like Cursor IDE demonstrate the immense potential of LLM-powered agents performing complex tasks (coding, editing, command execution). OpenMAS seeks to provide the foundation for building such specialized, capable agents more easily.</li> <li>Practical Development Hurdles: Our own experience building systems like <code>Chesspal.ai</code> (a sophisticated chess-playing agent) highlighted the repetitive challenges in managing agent lifecycles, communication, and state. This underscored the need for a reusable framework.</li> <li>The MCP Ecosystem Opportunity: The emergence of the Model Context Protocol (MCP) as an open standard for tool use presents a massive opportunity. OpenMAS embraces MCP, envisioning a future where developers can easily integrate a vast ecosystem of community-built MCP servers, granting agents diverse capabilities out-of-the-box.</li> <li>Proven Developer Tooling: Frameworks like <code>dbt</code> show how structure, configuration, and CLI tools enhance productivity in other domains. OpenMAS adopts similar principles for MAS development.</li> </ol>"},{"location":"why_openmas/#what-openmas-provides-the-agents-body-and-connective-tissue","title":"What OpenMAS Provides: The Agent's \"Body\" and \"Connective Tissue\"","text":"<p>OpenMAS doesn't dictate how an agent thinks (its \"brain\"), but it provides the essential structure and mechanisms for it to operate and interact:</p> <ul> <li>Agent Scaffolding (<code>BaseAgent</code>): A clear structure for agent code, managing lifecycle (<code>setup</code>, <code>run</code>, <code>shutdown</code>) and configuration.</li> <li>Communication Abstraction (<code>BaseCommunicator</code>): Decouples agent logic from specific protocols (HTTP, gRPC, MQTT, and crucially, MCP via SSE/stdio), allowing agents to talk to each other and external services consistently.</li> <li>Configuration Management: A layered system for managing settings.</li> <li>Developer Tooling (<code>openmas</code> CLI): Commands to initialize projects, run agents locally, manage dependencies, and generate deployment artifacts (Dockerfiles, Compose files).</li> <li>MCP Integration: First-class support for building MCP clients and integrating with MCP servers, enabling standardized tool use.</li> </ul>"},{"location":"why_openmas/#positioning-how-openmas-fits-in","title":"Positioning: How OpenMAS Fits In","text":"<ul> <li>vs. Low-Level Distributed Frameworks (e.g., Ray): Ray excels at general-purpose distributed computing and scaling Python/ML tasks. OpenMAS is a higher-level application framework specifically designed and opinionated for the structure and development workflow of Multi-Agent Systems. It focuses on agent abstractions, communication patterns (like MCP), and MAS-specific tooling, rather than the underlying distributed execution engine (though they could potentially be complementary).</li> <li>vs. \"Agentic OS\" Concepts: OpenMAS embodies the spirit of an Agentic OS at the application layer by providing core services for agents. However, it's a framework running on a traditional OS, focused on structuring agent applications, not replacing the underlying operating system.</li> <li>vs. Other Agent Frameworks (e.g., Langchain, CrewAI, AutoGen): Many frameworks focus on specific interaction patterns (chains, crews, conversations) or LLM orchestration. OpenMAS aims to be a more general-purpose MAS framework, emphasizing architectural structure, protocol flexibility (especially MCP), and integrated developer tooling from initialization to deployment.</li> </ul>"},{"location":"why_openmas/#is-the-vision-achievable","title":"Is the Vision Achievable?","text":"<p>We believe so. The technical foundation of OpenMAS is designed to be modular, extensible, and pragmatic. It directly tackles common pain points in MAS development. The integration with the growing MCP standard provides a unique pathway for building rich, interconnected agent ecosystems.</p> <p>While challenges like community building and adoption exist for any new framework, OpenMAS offers a focused solution to the real and growing need for better tools to build the next generation of sophisticated agentic AI systems. It provides the essential scaffolding, allowing developers to build higher.</p>"},{"location":"cli/","title":"OpenMAS CLI","text":"<p>OpenMAS includes a command-line interface (CLI) to help you manage your multi-agent system projects. The CLI provides tools for project initialization, validation, agent listing, dependency management, prompt management, and running agents locally.</p>"},{"location":"cli/#available-commands","title":"Available Commands","text":"<ul> <li>openmas init: Initialize a new OpenMAS project with standard directory structure</li> <li>openmas validate: Validate the OpenMAS project configuration</li> <li>openmas list agents: List agents defined in the project</li> <li>openmas prompts list: List prompts defined in the project</li> <li>openmas run: Run an agent from the OpenMAS project</li> <li>openmas deps: Manage project dependencies</li> <li>openmas generate-dockerfile: Generate a Dockerfile for an agent</li> </ul>"},{"location":"cli/#installation","title":"Installation","text":"<p>The CLI is automatically installed when you install the OpenMAS package:</p> <pre><code>pip install openmas\n</code></pre>"},{"location":"cli/#usage","title":"Usage","text":"<pre><code># Show help\nopenmas --help\n\n# Show help for a specific command\nopenmas run --help\n</code></pre>"},{"location":"cli/#environmental-requirements","title":"Environmental Requirements","text":"<p>Running agents using the CLI requires:</p> <ol> <li>A properly structured OpenMAS project (created with <code>openmas init</code> or following the same conventions)</li> <li>A <code>openmas_project.yml</code> file in the project root</li> <li>Agent directories containing <code>agent.py</code> files with <code>BaseAgent</code> subclasses</li> </ol> <p>For more details on project structure and conventions, see the Getting Started guide.</p>"},{"location":"cli/assets/","title":"Assets CLI Commands","text":"<p>OpenMAS provides a set of CLI commands to manage assets defined in your project.</p>"},{"location":"cli/assets/#overview","title":"Overview","text":"<p>The <code>openmas assets</code> command group helps you:</p> <ul> <li>List all assets defined in your project and their current status</li> <li>Download assets on-demand, with options to force re-download</li> <li>Verify the integrity of downloaded assets</li> <li>Clear the asset cache when needed</li> </ul>"},{"location":"cli/assets/#commands","title":"Commands","text":""},{"location":"cli/assets/#list-assets","title":"List Assets","text":"<pre><code>openmas assets list\n</code></pre> <p>Lists all assets defined in your project configuration (<code>openmas_project.yml</code>) along with their current status.</p> <p>Output example:</p> <pre><code>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name            \u2503 Version \u2503 Type       \u2503 Source               \u2503 Status                               \u2503 Cache Path                  \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 llama3-8b       \u2502 1.0     \u2502 model      \u2502 hf:meta-llama/...    \u2502 \u2705 Downloaded and verified           \u2502 ~/.openmas/assets/model/... \u2502\n\u2502 prompt-templates\u2502 latest  \u2502 template   \u2502 http://example.com/..\u2502 \u274c Not found                         \u2502 -                           \u2502\n\u2502 knowledge-index \u2502 2023-06 \u2502 index      \u2502 local:/opt/shared/.. \u2502 \u26a0\ufe0f Downloaded but checksum mismatch \u2502 ~/.openmas/assets/index/... \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The status column shows: - \u2705 Downloaded and verified: Asset is downloaded and checksum verified (if provided) - \u26a0\ufe0f Downloaded but checksum mismatch: Asset is downloaded but checksum doesn't match - \u274c Not found: Asset is not in cache</p>"},{"location":"cli/assets/#download-asset","title":"Download Asset","text":"<pre><code>openmas assets download &lt;asset_name&gt; [--force]\n</code></pre> <p>Downloads a specific asset to the cache.</p> <p>Arguments and Options:</p> Argument/Option Description <code>asset_name</code> Name of the asset to download <code>--force</code>, <code>-f</code> Force re-download even if the asset exists in cache <p>Examples:</p> <p>Download an asset if not already cached: <pre><code>openmas assets download llama3-8b\n</code></pre></p> <p>Force re-download even if cached: <pre><code>openmas assets download llama3-8b --force\n</code></pre></p> <p>Output: <pre><code>Downloading asset \"llama3-8b\" (version 1.0)...\nSource: Hugging Face Hub (meta-llama/Llama-3-8B)\nProgress: \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 100%\nVerifying checksum... OK\nAsset downloaded to: /home/user/.openmas/assets/model/llama3-8b/1.0/model.safetensors\n</code></pre></p> <p>The command will: 1. Check if the asset exists in the project configuration 2. Determine the appropriate downloader based on the source type 3. Download the asset to the cache (or skip if already cached and <code>--force</code> is not used) 4. Verify the checksum (if provided) 5. Unpack the asset (if configured)</p>"},{"location":"cli/assets/#verify-asset","title":"Verify Asset","text":"<pre><code>openmas assets verify [asset_name]\n</code></pre> <p>Verifies the integrity of one or all cached assets.</p> <p>Arguments:</p> Argument Description <code>asset_name</code> (Optional) Name of the asset to verify. If omitted, all cached assets are verified. <p>Examples:</p> <p>Verify a specific asset: <pre><code>openmas assets verify llama3-8b\n</code></pre></p> <p>Output: <pre><code>Verifying asset \"llama3-8b\" (version 1.0)...\nExpected checksum: sha256:a1b2c3d4e5f6...\nCalculated checksum: sha256:a1b2c3d4e5f6...\nResult: \u2705 Verification successful\n</code></pre></p> <p>Verify all assets: <pre><code>openmas assets verify\n</code></pre></p> <p>Output: <pre><code>Verifying all cached assets...\n\nllama3-8b (version 1.0):\n  Expected checksum: sha256:a1b2c3d4e5f6...\n  Calculated checksum: sha256:a1b2c3d4e5f6...\n  Result: \u2705 Verification successful\n\nknowledge-index (version 2023-06):\n  Expected checksum: sha256:1a2b3c4d5e6f...\n  Calculated checksum: sha256:9z8y7x6w5v4...\n  Result: \u274c Verification failed\n\nSummary:\n  Total assets: 2\n  Passed: 1\n  Failed: 1\n</code></pre></p>"},{"location":"cli/assets/#clear-cache","title":"Clear Cache","text":"<pre><code>openmas assets clear-cache [--asset ASSET_NAME] [--all]\n</code></pre> <p>Clears the asset cache, either for a specific asset or the entire cache.</p> <p>Options:</p> Option Description <code>--asset</code>, <code>-a</code> Name of the asset to clear from cache <code>--all</code> Clear the entire asset cache (will prompt for confirmation) <p>Examples:</p> <p>Clear a specific asset: <pre><code>openmas assets clear-cache --asset llama3-8b\n</code></pre></p> <p>Output: <pre><code>Clearing asset \"llama3-8b\" (version 1.0) from cache...\nCache location: /home/user/.openmas/assets/model/llama3-8b/1.0\nAre you sure you want to clear the cache for asset 'llama3-8b'? [y/N]: y\nAsset cache successfully cleared.\n</code></pre></p> <p>Clear all assets: <pre><code>openmas assets clear-cache --all\n</code></pre></p> <p>Output: <pre><code>This will clear the entire asset cache at:\n/home/user/.openmas/assets/\n\nAre you sure you want to clear the entire asset cache? [y/N]: y\nSuccessfully cleared entire assets cache.\n</code></pre></p>"},{"location":"cli/assets/#environment-variables","title":"Environment Variables","text":"<p>The asset CLI commands respect the same environment variables as the core asset management system:</p> Environment Variable Description Default <code>OPENMAS_ASSETS_DIR</code> Override the default asset cache directory <code>~/.openmas/assets/</code> <code>OPENMAS_ENV</code> Environment name for loading configuration <code>local</code> <p>In addition, asset authentication can use environment variables like:</p> Environment Variable Description <code>HUGGING_FACE_HUB_TOKEN</code> Default token for Hugging Face Hub authentication Custom variables Any custom variable referenced in <code>authentication.*.token_env_var</code>"},{"location":"cli/assets/#using-env-for-authentication","title":"Using .env for Authentication","text":"<p>When using the asset commands, OpenMAS automatically loads environment variables from a <code>.env</code> file in your project root. This is especially useful for storing authentication tokens for gated assets:</p> <pre><code># .env file\nHUGGING_FACE_HUB_TOKEN=hf_abcdefghijklmnopqrstuvwxyz\nMY_CUSTOM_API_KEY=api_123456789abcdef\n</code></pre> <p>Make sure to add <code>.env</code> to your <code>.gitignore</code> to prevent accidentally committing sensitive tokens.</p>"},{"location":"cli/assets/#examples","title":"Examples","text":"<p>Download all assets defined in your project:</p> <pre><code># List all assets\nopenmas assets list | grep \"Not found\" | awk '{print $1}' &gt; missing_assets.txt\n\n# Download each missing asset\nwhile read asset; do\n  openmas assets download $asset\ndone &lt; missing_assets.txt\n</code></pre> <p>Verify and re-download corrupted assets:</p> <pre><code># Verify all assets and capture results\nopenmas assets verify &gt; verification_results.txt\n\n# Extract failed assets\ngrep \"failed\" verification_results.txt | awk '{print $1}' &gt; failed_assets.txt\n\n# Re-download failed assets\nwhile read asset; do\n  openmas assets clear-cache --asset $asset\n  openmas assets download $asset --force\ndone &lt; failed_assets.txt\n</code></pre>"},{"location":"cli/deps/","title":"OpenMAS Package Management","text":"<p>OpenMAS supports external package management through the <code>openmas deps</code> command, inspired by dbt's package management system. This allows you to include external Git repositories as dependencies in your OpenMAS project.</p>"},{"location":"cli/deps/#configuration","title":"Configuration","text":"<p>Dependencies are defined in the <code>dependencies</code> section of your <code>openmas_project.yml</code> file:</p> <pre><code>dependencies:\n  - git: https://github.com/example/openmas-repo.git\n    revision: main  # Optional: branch, tag, or commit hash\n</code></pre>"},{"location":"cli/deps/#supported-dependency-types","title":"Supported Dependency Types","text":"<p>Currently, OpenMAS supports the following dependency types:</p>"},{"location":"cli/deps/#git-dependencies-implemented","title":"Git Dependencies (Implemented)","text":"<p>Git dependencies allow you to include code from Git repositories:</p> <pre><code>dependencies:\n  - git: https://github.com/example/repo.git\n    revision: main  # Optional: branch, tag, or commit\n</code></pre> <ul> <li>The <code>git</code> key specifies the Git repository URL</li> <li>The optional <code>revision</code> key specifies a branch, tag, or commit to checkout</li> </ul>"},{"location":"cli/deps/#package-dependencies-not-yet-implemented","title":"Package Dependencies (Not Yet Implemented)","text":"<p>Package dependencies will allow importing from centralized package repositories:</p> <pre><code>dependencies:\n  - package: example/package-name\n    version: 1.0.0\n</code></pre>"},{"location":"cli/deps/#local-dependencies-not-yet-implemented","title":"Local Dependencies (Not Yet Implemented)","text":"<p>Local dependencies will allow referencing code from other directories:</p> <pre><code>dependencies:\n  - local: ../path/to/local/package\n</code></pre>"},{"location":"cli/deps/#installing-dependencies","title":"Installing Dependencies","text":"<p>To install or update the dependencies defined in your project, run:</p> <pre><code>openmas deps\n</code></pre> <p>This will: 1. Create a <code>packages/</code> directory in your project (if it doesn't exist) 2. Clone Git repositories to <code>packages/&lt;repo-name&gt;</code> 3. Checkout the specified revision (branch, tag, or commit)</p>"},{"location":"cli/deps/#options","title":"Options","text":"<ul> <li><code>--project-dir PATH</code>: Specify the project directory containing <code>openmas_project.yml</code></li> <li><code>--clean</code>: Clean (remove) the packages directory before installing dependencies</li> </ul>"},{"location":"cli/deps/#usage-in-your-project","title":"Usage in Your Project","text":"<p>Code from installed packages is automatically available to your agents. When running an agent with <code>openmas run</code>, the system automatically adds:</p> <ul> <li>The package's <code>src/</code> directory to the Python path (if it exists)</li> <li>Otherwise, the package's root directory</li> </ul> <p>This means you can import modules from installed packages directly in your agent code:</p> <pre><code># If the package has a src/ directory\nfrom package_name.module import something\n\n# If the package doesn't have a src/ directory\nfrom module import something\n</code></pre>"},{"location":"cli/deps/#validating-dependencies","title":"Validating Dependencies","text":"<p>To validate the dependency configuration in your project:</p> <pre><code>openmas validate\n</code></pre> <p>This checks that: - Each dependency has a valid type (<code>git</code>, <code>package</code>, or <code>local</code>) - Git dependencies have valid URLs - Package dependencies have the required <code>version</code> field</p>"},{"location":"cli/deps/#best-practices","title":"Best Practices","text":"<ol> <li>Always specify a <code>revision</code> for Git dependencies to ensure reproducibility</li> <li>Consider using the <code>.gitignore</code> file to exclude the <code>packages/</code> directory (OpenMAS init does this by default)</li> <li>Use <code>openmas deps</code> in your CI/CD pipelines to ensure dependencies are properly installed</li> </ol>"},{"location":"cli/generate-compose/","title":"<code>openmas generate-compose</code> Command","text":"<p>The <code>openmas generate-compose</code> command helps automate the creation of a <code>docker-compose.yml</code> file for running your entire OpenMAS project locally using Docker Compose.</p>"},{"location":"cli/generate-compose/#usage","title":"Usage","text":"<p><code>openmas generate-compose [OPTIONS]</code></p>"},{"location":"cli/generate-compose/#options","title":"Options","text":"<ul> <li><code>--output-file TEXT</code>: Name of the output Docker Compose file (default: \"docker-compose.yml\")</li> <li><code>--project-dir PATH</code>: Explicit path to the project directory containing <code>openmas_project.yml</code>. If omitted, searches upwards from the current directory.</li> <li><code>--image-name TEXT</code>: Base name for the Docker image to use for agent services (default: derived from project name in <code>openmas_project.yml</code>). Assumes a single image can run any agent via <code>AGENT_NAME</code> env var.</li> <li><code>--image-tag TEXT</code>: Tag for the Docker image (default: \"latest\").</li> <li><code>--network-name TEXT</code>: Name for the Docker network (default: \"_default\"). <li><code>--env-file PATH</code>: Path to an optional .env file to include in the generated services.</li>"},{"location":"cli/generate-compose/#purpose","title":"Purpose","text":"<p>This command aims to simplify the setup for running a multi-agent system locally with Docker Compose by:</p> <ol> <li>Reading Project Configuration: Parses <code>openmas_project.yml</code> to identify all defined agents.</li> <li>Defining Services: Creates a Docker Compose service definition for each agent listed in the <code>agents:</code> section.</li> <li>Setting Agent Name: Automatically sets the crucial <code>AGENT_NAME</code> environment variable for each service, telling the container which agent code to run via <code>openmas run</code>.</li> <li>Configuring Image: Assumes a single Docker image (specified by <code>--image-name</code> and <code>--image-tag</code>) is built (e.g., using <code>openmas generate-dockerfile</code> or manually) that can run any agent based on the <code>AGENT_NAME</code> variable.</li> <li>Basic Networking: Sets up a default Docker bridge network and connects all agent services to it.</li> <li>Injecting Service URLs: Attempts to automatically inject <code>SERVICE_URLS__&lt;AGENT_NAME&gt;</code> environment variables into each service, using the Docker Compose service names and default ports (assuming HTTP on 8000/8001 etc., or reading hints from <code>openmas.deploy.yaml</code> if available). This automatic URL injection might require manual adjustment.</li> <li>Reading Deployment Hints: Optionally reads <code>agents/&lt;agent_name&gt;/openmas.deploy.yaml</code> for hints like exposed ports or specific environment variables for that agent's service.</li> </ol>"},{"location":"cli/generate-compose/#example-usage","title":"Example Usage","text":"<pre><code># In your project root directory\n# First, ensure you have a suitable Docker image built, e.g., my-mas-image:latest\n\n# Generate docker-compose.yml using default settings\nopenmas generate-compose\n\n# Generate with a specific image name and output file\nopenmas generate-compose --image-name my-company/my-mas-image --image-tag v1.1 --output-file compose.prod.yml\n</code></pre>"},{"location":"cli/generate-compose/#example-docker-composeyml-output","title":"Example <code>docker-compose.yml</code> Output","text":"<p>Given an <code>openmas_project.yml</code> defining <code>orchestrator</code> and <code>worker</code> agents, the generated output might resemble:</p> <pre><code># Indented YAML Code Block\n# Generated by openmas generate-compose\nversion: '3.8'\n\nservices:\n    orchestrator:\n    image: my_mas_project-agent:latest # Default image name derived from project\n    container_name: orchestrator\n    environment:\n        AGENT_NAME: orchestrator # Tells the container to run this agent\n        OPENMAS_ENV: local # Default, can be overridden\n        # --- Auto-injected Service URLs (Review Carefully!) ---\n        SERVICE_URLS__WORKER: http://worker:8000 # Assumes worker runs on port 8000\n        # Add other necessary env vars (LOG_LEVEL, API keys, etc.)\n    ports:\n        - \"8000:8000\" # Default exposed port, adjust if needed\n    networks:\n        - my_mas_project_default # Default network name\n\n    worker:\n    image: my_mas_project-agent:latest\n    container_name: worker\n    environment:\n        AGENT_NAME: worker\n        OPENMAS_ENV: local\n        # --- Auto-injected Service URLs (Review Carefully!) ---\n        SERVICE_URLS__ORCHESTRATOR: http://orchestrator:8000 # Assumes orchestrator runs on port 8000\n    ports:\n        - \"8001:8000\" # Example: worker internally runs on 8000, exposed as 8001 on host\n    networks:\n        - my_mas_project_default\n\nnetworks:\n    my_mas_project_default: # Default network name derived from project\n    driver: bridge\n</code></pre>"},{"location":"cli/generate-compose/#important-considerations-manual-adjustments","title":"Important Considerations &amp; Manual Adjustments","text":"<ul> <li>Review Generated File: The generated file is a starting point. Always review and adjust it to match your specific needs.</li> <li>Image Name: Ensure the <code>image:</code> specified matches the image you have built that contains your project code and the <code>openmas</code> framework.</li> <li>Service URLs: The automatic <code>SERVICE_URLS__*</code> injection makes assumptions about ports (often defaulting to 8000 or based on simple ordering). Verify these URLs and ports are correct for how your agents are configured to listen internally within their containers (e.g., via <code>COMMUNICATOR_OPTIONS__HTTP_PORT</code>). You may need to manually edit these URLs.</li> <li>Ports: Adjust the <code>ports:</code> mapping (<code>HOST:CONTAINER</code>) as needed. The <code>CONTAINER</code> port must match the port the agent's communicator listens on inside the container.</li> <li>Environment Variables: Add any other required environment variables for configuration (e.g., <code>LOG_LEVEL</code>, <code>OPENMAS_ENV</code>, API keys, database connection strings). Consider using <code>.env</code> files with Docker Compose for sensitive data.</li> <li>Dependencies: Add other services your MAS depends on (e.g., databases, message brokers) to the Compose file.</li> <li>Volumes: Mount volumes if needed for persistent data or configuration files.</li> </ul>"},{"location":"cli/generate-compose/#related-commands","title":"Related Commands","text":"<ul> <li><code>openmas run</code>: Run a single agent locally.</li> <li><code>openmas generate-dockerfile</code>: Generate a Dockerfile for containerizing agents.</li> <li><code>openmas validate</code>: Validate project configuration.</li> <li><code>openmas deps</code>: Manage external package dependencies.</li> </ul>"},{"location":"cli/generate-dockerfile/","title":"<code>openmas generate-dockerfile</code> Command","text":"<p>The <code>openmas generate-dockerfile</code> command helps you create a Dockerfile for an OpenMAS agent, making it easy to containerize your agent for deployment.</p>"},{"location":"cli/generate-dockerfile/#usage","title":"Usage","text":"<pre><code>openmas generate-dockerfile &lt;agent_name&gt; [OPTIONS]\n</code></pre> <p>Where: - <code>&lt;agent_name&gt;</code> is the name of an agent defined in your project's <code>openmas_project.yml</code> file.</p>"},{"location":"cli/generate-dockerfile/#options","title":"Options","text":"<ul> <li><code>--output-file TEXT</code>: Name of the output Dockerfile (default: \"Dockerfile\")</li> <li><code>--project-dir PATH</code>: Explicit path to the project directory containing <code>openmas_project.yml</code></li> <li><code>--python-version TEXT</code>: Python version to use (default: \"3.10\")</li> <li><code>--use-poetry</code>: Use Poetry for dependency management instead of pip requirements.txt</li> </ul>"},{"location":"cli/generate-dockerfile/#purpose","title":"Purpose","text":"<p>This command provides a standardized way to create a Dockerfile for your agent by:</p> <ol> <li>Finding your project root (location of <code>openmas_project.yml</code>)</li> <li>Identifying the agent's location and dependencies</li> <li>Creating a Dockerfile with appropriate build steps</li> <li>Configuring the container for proper runtime behavior</li> </ol>"},{"location":"cli/generate-dockerfile/#example-usage","title":"Example Usage","text":""},{"location":"cli/generate-dockerfile/#basic-usage","title":"Basic Usage","text":"<pre><code># Generate a Dockerfile for the 'orchestrator' agent in the current project\nopenmas generate-dockerfile orchestrator\n</code></pre> <p>This will create a <code>Dockerfile</code> in the current directory.</p>"},{"location":"cli/generate-dockerfile/#specifying-an-output-file","title":"Specifying an Output File","text":"<pre><code># Generate a Dockerfile with a custom name\nopenmas generate-dockerfile worker --output-file Dockerfile.worker\n</code></pre>"},{"location":"cli/generate-dockerfile/#using-poetry-for-dependencies","title":"Using Poetry for Dependencies","text":"<pre><code># Generate a Dockerfile that uses Poetry for dependency management\nopenmas generate-dockerfile orchestrator --use-poetry\n</code></pre>"},{"location":"cli/generate-dockerfile/#specifying-python-version","title":"Specifying Python Version","text":"<pre><code># Generate a Dockerfile using Python 3.11\nopenmas generate-dockerfile orchestrator --python-version 3.11\n</code></pre>"},{"location":"cli/generate-dockerfile/#example-dockerfile-output","title":"Example Dockerfile Output","text":"<p>Here's an example of a generated Dockerfile:</p> <pre><code>FROM python:3.10-slim\n\nWORKDIR /app\n\n# Copy project files\nCOPY . /app/\n\n# Install dependencies\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Set environment variables\nENV AGENT_NAME=\"orchestrator\"\nENV PYTHONPATH=\"/app\"\n\n# Expose port (if your agent uses HTTP)\nEXPOSE 8000\n\n# Run the agent\nCMD [\"openmas\", \"run\", \"orchestrator\"]\n</code></pre>"},{"location":"cli/generate-dockerfile/#best-practices","title":"Best Practices","text":"<ol> <li>Review the generated Dockerfile: While the command creates a good starting point, you might need to modify it for specific requirements.</li> <li>Add any required environment variables: Add environment variables for API keys, service URLs, etc.</li> <li>Consider multi-stage builds: For more complex applications, you might want to use multi-stage builds to reduce the final image size.</li> </ol>"},{"location":"cli/generate-dockerfile/#related-commands","title":"Related Commands","text":"<ul> <li><code>openmas run</code>: Run an agent locally</li> <li><code>openmas deps</code>: Manage project dependencies</li> </ul>"},{"location":"cli/init/","title":"<code>openmas init</code> Command","text":"<p>The <code>openmas init</code> command helps you initialize a new OpenMAS project with the standard directory structure and configuration files.</p>"},{"location":"cli/init/#usage","title":"Usage","text":"<pre><code>openmas init &lt;project_name&gt; [OPTIONS]\n</code></pre> <p>Where: - <code>&lt;project_name&gt;</code> is the name of the project to create, or \".\" to initialize in the current directory.</p>"},{"location":"cli/init/#options","title":"Options","text":"<ul> <li><code>--template, -t TEXT</code>: Template to use for project initialization (e.g., \"mcp-server\")</li> <li><code>--name TEXT</code>: Project name when initializing in current directory (required if <code>project_name</code> is \".\")</li> </ul>"},{"location":"cli/init/#purpose","title":"Purpose","text":"<p>This command creates a new OpenMAS project with a standardized directory structure, making it easy to start building multi-agent systems. It:</p> <ol> <li>Creates the project directory (unless using the current directory)</li> <li>Sets up the standard directory structure</li> <li>Creates starter configuration files</li> <li>(Optionally) Sets up a template with specific agent implementations</li> </ol>"},{"location":"cli/init/#directory-structure","title":"Directory Structure","text":"<p>The command creates the following directory structure:</p> <pre><code>project_name/\n\u251c\u2500\u2500 agents/               # Agent implementations\n\u251c\u2500\u2500 shared/               # Shared code between agents\n\u251c\u2500\u2500 extensions/           # Custom extensions\n\u251c\u2500\u2500 config/               # Configuration files\n\u251c\u2500\u2500 tests/                # Test files\n\u251c\u2500\u2500 packages/             # External dependencies\n\u251c\u2500\u2500 .gitignore            # Git ignore file\n\u251c\u2500\u2500 openmas_project.yml   # Project configuration\n\u251c\u2500\u2500 README.md             # Project README\n\u2514\u2500\u2500 requirements.txt      # Python dependencies\n</code></pre>"},{"location":"cli/init/#example-usage","title":"Example Usage","text":""},{"location":"cli/init/#create-a-new-project","title":"Create a New Project","text":"<pre><code># Create a new project named \"my_project\"\nopenmas init my_project\n</code></pre>"},{"location":"cli/init/#initialize-in-current-directory","title":"Initialize in Current Directory","text":"<pre><code># Initialize in the current directory\nopenmas init . --name my_project\n</code></pre>"},{"location":"cli/init/#use-a-template","title":"Use a Template","text":"<pre><code># Create a new project with the MCP server template\nopenmas init my_mcp_project --template mcp-server\n</code></pre>"},{"location":"cli/init/#template-options","title":"Template Options","text":"<p>The <code>--template</code> option allows you to create a project with pre-configured components. Currently supported templates include:</p>"},{"location":"cli/init/#mcp-server","title":"mcp-server","text":"<p>Creates a project with an MCP server agent preconfigured:</p> <pre><code>openmas init my_mcp_project --template mcp-server\n</code></pre> <p>This will create: - A directory structure for an MCP server agent - A sample implementation in <code>agents/mcp_server/agent.py</code> - A deployment configuration in <code>agents/mcp_server/openmas.deploy.yaml</code></p>"},{"location":"cli/init/#project-configuration","title":"Project Configuration","text":"<p>The command creates an <code>openmas_project.yml</code> file with the following structure:</p> <pre><code>name: \"my_project\"\nversion: \"0.1.0\"\nagents: {}  # Will contain agent definitions\nshared_paths: [\"shared\"]\nplugin_paths: [\"extensions\"]\ndefault_config:\n  log_level: \"INFO\"\n  communicator_type: \"http\"\ndependencies: []  # External dependencies\n</code></pre>"},{"location":"cli/init/#next-steps","title":"Next Steps","text":"<p>After initializing a project, you can:</p> <ol> <li>Create agent implementations in the <code>agents/</code> directory</li> <li>Register your agents in the <code>openmas_project.yml</code> file</li> <li>Run your agents with the <code>openmas run</code> command</li> <li>Validate your project configuration with <code>openmas validate</code></li> </ol>"},{"location":"cli/init/#related-commands","title":"Related Commands","text":"<ul> <li><code>openmas run</code>: Run an agent from the project</li> <li><code>openmas validate</code>: Validate the project configuration</li> <li><code>openmas list agents</code>: List agents defined in the project</li> </ul>"},{"location":"cli/list/","title":"<code>openmas list</code> Command","text":"<p>The <code>openmas list</code> command displays resources defined in your OpenMAS project, such as agents, making it easier to understand your project structure.</p>"},{"location":"cli/list/#usage","title":"Usage","text":"<pre><code>openmas list [RESOURCE_TYPE]\n</code></pre> <p>Where: - <code>[RESOURCE_TYPE]</code> is the type of resource to list (currently only \"agents\" is supported)</p>"},{"location":"cli/list/#purpose","title":"Purpose","text":"<p>This command helps you view resources defined in your project configuration, providing a quick overview of what's available in your multi-agent system.</p>"},{"location":"cli/list/#example-usage","title":"Example Usage","text":"<pre><code># List all agents in the project\nopenmas list agents\n</code></pre>"},{"location":"cli/list/#available-resource-types","title":"Available Resource Types","text":""},{"location":"cli/list/#agents","title":"agents","text":"<p>Lists all agents defined in your project's <code>openmas_project.yml</code> file.</p> <p>Example output:</p> <pre><code>\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 Agent Name     \u2502 Path                  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 orchestrator   \u2502 agents/orchestrator   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 worker1        \u2502 agents/worker1        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 worker2        \u2502 agents/worker2        \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</code></pre>"},{"location":"cli/list/#related-commands","title":"Related Commands","text":"<ul> <li><code>openmas init</code>: Initialize a new OpenMAS project</li> <li><code>openmas validate</code>: Validate the project configuration</li> <li><code>openmas run</code>: Run an agent from the project</li> </ul>"},{"location":"cli/prompts/","title":"Prompt Management Commands","text":"<p>The <code>openmas prompts</code> command group provides tools for working with prompt templates defined in your OpenMAS project.</p>"},{"location":"cli/prompts/#list-prompts","title":"List Prompts","text":"<p>The <code>openmas prompts list</code> command displays all prompts defined in your project, showing their structure, source, and input variables.</p> <pre><code>openmas prompts list [--agent &lt;agent_name&gt;] [--project-dir &lt;project_dir&gt;]\n</code></pre>"},{"location":"cli/prompts/#options","title":"Options","text":"<ul> <li><code>--agent &lt;agent_name&gt;</code>: Filter prompts by agent name</li> <li><code>--project-dir &lt;project_dir&gt;</code>: Explicit path to the project directory containing openmas_project.yml</li> </ul>"},{"location":"cli/prompts/#examples","title":"Examples","text":"<p>List all prompts across all agents:</p> <pre><code>openmas prompts list\n</code></pre> <p>List prompts for a specific agent:</p> <pre><code>openmas prompts list --agent my_agent\n</code></pre>"},{"location":"cli/prompts/#output","title":"Output","text":"<p>The command displays detailed information about each prompt:</p> <pre><code>\ud83e\udd16 Agent: my_agent\n\n  \ud83d\udcdd Prompt: greeting\n    Template (inline): Hello, {{name}}!\n    Input variables: name\n\n  \ud83d\udcdd Prompt: farewell\n    Template file: farewell.txt\n    Input variables: name\n</code></pre> <p>For each prompt, the output includes: - The prompt name - Template content (truncated if too long) or template file path - Input variables expected by the template</p>"},{"location":"cli/prompts/#prompt-configuration","title":"Prompt Configuration","text":"<p>Prompts in OpenMAS are defined in the <code>openmas_project.yml</code> file under each agent's configuration. Here's an example:</p> <pre><code>agents:\n  my_agent:\n    module: \"agents.my_agent\"\n    class: \"MyAgent\"\n    prompts_dir: \"prompts\"  # Directory for template files (relative to project root)\n    prompts:\n      - name: \"greeting\"\n        template: \"Hello, {{name}}!\"  # Inline template\n        input_variables: [\"name\"]\n      - name: \"farewell\"\n        template_file: \"farewell.txt\"  # File-based template\n        input_variables: [\"name\"]\n</code></pre> <p>Each prompt can have either: - An inline template using the <code>template</code> field, or - A reference to a template file using the <code>template_file</code> field</p> <p>Template files are looked up in the directory specified by <code>prompts_dir</code> (defaults to \"prompts\" if not specified).</p>"},{"location":"cli/prompts/#render-prompt","title":"Render Prompt","text":"<p>The <code>openmas prompts render</code> command renders a specific prompt for a given agent with provided variables. This is useful for testing how prompt templates will look when rendered with actual values.</p> <pre><code>openmas prompts render &lt;agent_name&gt; &lt;prompt_name&gt; [--var key=value] [--project-dir &lt;project_dir&gt;]\n</code></pre>"},{"location":"cli/prompts/#arguments","title":"Arguments","text":"<ul> <li><code>agent_name</code>: The name of the agent containing the prompt</li> <li><code>prompt_name</code>: The name of the prompt to render</li> </ul>"},{"location":"cli/prompts/#options_1","title":"Options","text":"<ul> <li><code>--var key=value</code>: Variables to use when rendering the prompt (can be specified multiple times)</li> <li><code>--project-dir &lt;project_dir&gt;</code>: Explicit path to the project directory containing openmas_project.yml</li> </ul>"},{"location":"cli/prompts/#examples_1","title":"Examples","text":"<p>Render a prompt with a single variable:</p> <pre><code>openmas prompts render my_agent greeting --var name=\"John Smith\"\n</code></pre> <p>Render a prompt with multiple variables:</p> <pre><code>openmas prompts render my_agent analyze --var text=\"This is a sample text\" --var depth=3\n</code></pre> <p>List the required variables for a prompt without rendering it:</p> <pre><code>openmas prompts render my_agent greeting\n</code></pre>"},{"location":"cli/prompts/#output_1","title":"Output","text":"<p>The command displays the rendered prompt:</p> <pre><code>=== Rendered Prompt ===\n\nHello, John Smith!\n\n======================\n</code></pre> <p>If no variables are provided, the command will display the required variables for the prompt:</p> <pre><code>Required variables for prompt 'greeting':\n  name\n\nUse --var key=value to provide values for variables\n</code></pre>"},{"location":"cli/run/","title":"<code>openmas run</code> Command","text":"<p>The <code>openmas run</code> command is a cornerstone of the OpenMAS developer experience, designed for local execution and debugging of a single agent within a multi-agent system. It functions similarly to <code>dbt run</code> in its role within the development loop.</p>"},{"location":"cli/run/#usage","title":"Usage","text":"<pre><code>openmas run &lt;agent_name&gt; [--project-dir PATH]\n</code></pre> <p>Where: - <code>&lt;agent_name&gt;</code> is the name of an agent defined in your project's <code>openmas_project.yml</code> file. - <code>--project-dir PATH</code> (optional) is an explicit path to the project directory containing the <code>openmas_project.yml</code> file.</p>"},{"location":"cli/run/#purpose","title":"Purpose","text":"<p>This command provides a standardized, framework-aware way to run and test individual agents locally. It:</p> <ol> <li>Finds your project root (location of <code>openmas_project.yml</code>)</li> <li>Loads the complete, layered configuration stack</li> <li>Sets up Python paths for imports from <code>shared/</code> and <code>extensions/</code> directories</li> <li>Dynamically loads and instantiates the specified agent</li> <li>Executes the agent's lifecycle methods (<code>setup()</code>, <code>run()</code>, and <code>shutdown()</code>) via <code>asyncio</code></li> <li>Blocks the terminal while the agent's <code>run()</code> method executes</li> <li>Provides guidance for running other agents in separate terminals</li> <li>Gracefully handles signals (Ctrl+C) to ensure proper shutdown</li> </ol>"},{"location":"cli/run/#configuration-loading","title":"Configuration Loading","text":"<p>When running an agent, configuration is loaded in the following order (lowest to highest precedence):</p> <ol> <li>OpenMAS SDK internal defaults (defined in Pydantic models)</li> <li><code>default_config</code> section in <code>openmas_project.yml</code></li> <li><code>config/default.yml</code> file</li> <li><code>config/&lt;OPENMAS_ENV&gt;.yml</code> file (defaults to <code>local.yml</code> if <code>OPENMAS_ENV</code> is not set)</li> <li><code>.env</code> file at project root</li> <li>Environment variables (highest precedence)</li> </ol> <p>This layered approach allows for flexible configuration management across different environments.</p>"},{"location":"cli/run/#running-multiple-agents","title":"Running Multiple Agents","text":"<p>To run a full multi-agent system locally, you need to:</p> <ol> <li>Open a separate terminal window for each agent</li> <li>Run each agent with <code>openmas run &lt;agent_name&gt;</code></li> </ol> <p>After successfully starting an agent, if your project contains multiple agents, the command will display a helpful guidance message suggesting how to run the other agents in your project.</p>"},{"location":"cli/run/#example","title":"Example","text":"<pre><code># In terminal 1\n$ openmas run orchestrator\n\nStarting agent 'orchestrator' (OrchestratorAgent)\nSetting up agent...\n\n[OpenMAS CLI] Agent start success.\n[OpenMAS CLI] To run other agents in this project, open new terminal windows and use:\n[OpenMAS CLI]     openmas run worker1\n[OpenMAS CLI]     openmas run worker2\n[OpenMAS CLI] Project agents: orchestrator, worker1, worker2\n\n# In terminal 2\n$ openmas run worker1\n...\n\n# In terminal 3\n$ openmas run worker2\n...\n</code></pre>"},{"location":"cli/run/#example-with-project-directory-specified","title":"Example with project directory specified","text":"<pre><code># Running from outside the project directory\n$ openmas run orchestrator --project-dir /path/to/my/project\n\nStarting agent 'orchestrator' (OrchestratorAgent)\nSetting up agent...\n</code></pre>"},{"location":"cli/run/#graceful-shutdown","title":"Graceful Shutdown","text":"<p>The command handles <code>SIGINT</code> (Ctrl+C) and <code>SIGTERM</code> signals gracefully, ensuring that:</p> <ol> <li>The agent's <code>run()</code> method is cancelled or completes</li> <li>The agent's <code>shutdown()</code> method is called to perform cleanup</li> <li>The process exits cleanly</li> </ol>"},{"location":"cli/run/#python-path-management","title":"Python Path Management","text":"<p>When running an agent, the command automatically sets up the Python path to include:</p> <ol> <li>The project root directory</li> <li>The agent's parent directory</li> <li>All directories listed in <code>shared_paths</code> in your project configuration</li> <li>All directories listed in <code>extension_paths</code> in your project configuration</li> </ol> <p>This enables imports from shared modules and extensions without requiring manual <code>PYTHONPATH</code> manipulation.</p>"},{"location":"cli/run/#error-handling","title":"Error Handling","text":"<p>The command provides specific and informative error messages for common issues:</p> <ul> <li>Missing project configuration</li> <li>Agent not found in configuration</li> <li>Missing agent module file</li> <li>Import errors</li> <li>No BaseAgent subclass found</li> <li>Exceptions during agent setup, run, or shutdown</li> </ul>"},{"location":"cli/run/#related-commands","title":"Related Commands","text":"<ul> <li><code>openmas init</code>: Initialize a new OpenMAS project</li> <li><code>openmas validate</code>: Validate project configuration</li> <li><code>openmas list agents</code>: List agents defined in the project</li> </ul>"},{"location":"cli/validate/","title":"<code>openmas validate</code> Command","text":"<p>The <code>openmas validate</code> command checks your OpenMAS project configuration for correctness and consistency, helping you catch issues before running your agents.</p>"},{"location":"cli/validate/#usage","title":"Usage","text":"<pre><code>openmas validate [OPTIONS]\n</code></pre>"},{"location":"cli/validate/#purpose","title":"Purpose","text":"<p>This command performs a series of validation checks on your OpenMAS project to ensure that:</p> <ol> <li>The <code>openmas_project.yml</code> file has the required structure</li> <li>All referenced agent paths exist</li> <li>All referenced shared and plugin paths exist</li> <li>Dependencies are correctly specified</li> <li>The configuration format is valid</li> <li>Prompt configurations are valid and reference existing files</li> <li>Sampling configurations are compatible with the agent's communicator</li> </ol> <p>It helps identify issues early, such as missing files or invalid references, before you try to run your agents.</p>"},{"location":"cli/validate/#example-usage","title":"Example Usage","text":"<pre><code># Validate project in the current directory\nopenmas validate\n</code></pre>"},{"location":"cli/validate/#validation-checks","title":"Validation Checks","text":"<p>The command performs the following validation checks:</p>"},{"location":"cli/validate/#project-configuration","title":"Project Configuration","text":"<ul> <li>Validates that <code>openmas_project.yml</code> exists</li> <li>Checks that required fields (<code>name</code>, <code>version</code>) are present</li> <li>Validates the format of optional fields (<code>agents</code>, <code>shared_paths</code>, <code>plugin_paths</code>, <code>default_config</code>, <code>dependencies</code>)</li> </ul>"},{"location":"cli/validate/#agent-paths","title":"Agent Paths","text":"<p>For each agent defined in the <code>agents</code> section: - Validates that the agent directory exists - Checks that the agent directory contains an <code>agent.py</code> file - Verifies that <code>agent.py</code> contains a <code>BaseAgent</code> subclass</p>"},{"location":"cli/validate/#prompt-configuration","title":"Prompt Configuration","text":"<p>For each agent with prompt configurations: - Validates that each prompt has a unique name within the agent - Checks that template files referenced by <code>template_file</code> exist in the <code>prompts_dir</code> - Verifies that variables listed in <code>input_variables</code> appear in the template with the expected <code>{{variable}}</code> syntax - Confirms that either <code>template</code> or <code>template_file</code> is provided for each prompt</p>"},{"location":"cli/validate/#sampling-configuration","title":"Sampling Configuration","text":"<p>For each agent with sampling configurations: - Validates the sampling provider (if specified) - Checks that the provider is compatible with the communicator type (e.g., \"mcp\" provider with \"mcp_sse\" communicator) - Verifies that required parameters for the provider are present</p>"},{"location":"cli/validate/#shared-and-plugin-paths","title":"Shared and Plugin Paths","text":"<ul> <li>Validates that all paths in <code>shared_paths</code> exist</li> <li>Validates that all paths in <code>plugin_paths</code> exist</li> </ul>"},{"location":"cli/validate/#dependencies","title":"Dependencies","text":"<p>For each dependency in the <code>dependencies</code> section: - Validates the dependency type (<code>git</code>, <code>package</code>, or <code>local</code>) - For <code>git</code> dependencies, checks that the URL is valid - For <code>package</code> dependencies, checks that the version is specified - For <code>local</code> dependencies, checks that the path exists</p>"},{"location":"cli/validate/#exit-codes","title":"Exit Codes","text":"<ul> <li><code>0</code>: Validation successful</li> <li><code>1</code>: Validation failed (with error messages)</li> </ul>"},{"location":"cli/validate/#example-feedback","title":"Example Feedback","text":"<p>Here are examples of the feedback provided:</p>"},{"location":"cli/validate/#successful-validation","title":"Successful Validation","text":"<pre><code>\u2705 Project configuration found and validated\n\u2705 Agent 'orchestrator' found at 'agents/orchestrator'\n\u2705 Agent 'worker' found at 'agents/worker'\n\u2705 All shared paths exist\n\u2705 All plugin paths exist\n\u2705 Dependencies validated\n</code></pre>"},{"location":"cli/validate/#failed-validation","title":"Failed Validation","text":"<pre><code>\u2705 Project configuration found\n\u274c Agent 'orchestrator': Directory 'agents/orchestrator' does not exist\n\u2705 Agent 'worker' found at 'agents/worker'\n\u274c Shared path 'shared/missing' does not exist\n\u2705 All plugin paths exist\n\u274c Git dependency 'https://example.com/invalid.git': Invalid URL format\n</code></pre>"},{"location":"cli/validate/#related-commands","title":"Related Commands","text":"<ul> <li><code>openmas init</code>: Initialize a new OpenMAS project</li> <li><code>openmas list agents</code>: List agents defined in the project</li> <li><code>openmas run</code>: Run an agent from the project</li> </ul>"},{"location":"contributing/contributing/","title":"Contributing to OpenMAS","text":"<p>We welcome contributions to OpenMAS! Whether you're fixing a bug, improving documentation, or proposing a new feature, your help is appreciated.</p> <p>Please follow standard GitHub practices:</p> <ol> <li>Fork the repository.</li> <li>Create a new branch for your changes (<code>git checkout -b feature/my-new-feature</code> or <code>bugfix/issue-number</code>).</li> <li>Make your changes. Ensure you follow the project's coding style and conventions.</li> <li>Add tests for any new features or bug fixes.</li> <li>Ensure all tests pass by running <code>poetry run tox</code>.</li> <li>Update documentation if necessary.</li> <li>Submit a Pull Request against the <code>main</code> branch.</li> </ol>"},{"location":"contributing/contributing/#development-setup","title":"Development Setup","text":"<p>Please refer to the main README for instructions on setting up your development environment using Poetry and pre-commit hooks.</p> <p>For more detailed information about our development workflow, tools, and best practices, see the Development Workflow guide.</p>"},{"location":"contributing/contributing/#code-style-and-quality","title":"Code Style and Quality","text":"<p>We use <code>black</code> for formatting, <code>isort</code> for import sorting, <code>flake8</code> for linting, and <code>mypy</code> for type checking. These are enforced via pre-commit hooks.</p> <p>Run quality checks using <code>poetry run tox -e lint</code>.</p> <p>Alternatively, you can use the convenience script to run all quality checks at once:</p> <pre><code>./scripts/check_quality.sh\n</code></pre> <p>See the Development Workflow guide for more details.</p>"},{"location":"contributing/contributing/#docstrings","title":"Docstrings","text":"<p>Clear and consistent docstrings are important. Please adhere to the guidelines outlined in our Docstring Policy.</p>"},{"location":"contributing/contributing/#testing","title":"Testing","text":"<p>All contributions must include relevant tests. Please follow the testing strategy outlined in the Testing README.</p> <p>Run tests using tox environments:</p> <pre><code># Run unit tests\npoetry run tox -e unit\n\n# Run integration tests with mocks (no real dependencies needed)\npoetry run tox -e integration-mock\n\n# Run all tests with coverage report\npoetry run tox -e coverage\n</code></pre> <p>For more testing commands and environments, see the Development Workflow guide.</p>"},{"location":"contributing/development_workflow/","title":"Development Workflow","text":"<p>This document provides an overview of the OpenMAS development workflow, tools, and commands for contributors.</p>"},{"location":"contributing/development_workflow/#development-environment","title":"Development Environment","text":"<p>OpenMAS uses Poetry for dependency management and tox for testing across environments.</p>"},{"location":"contributing/development_workflow/#setup","title":"Setup","text":"<ol> <li> <p>Install Poetry (if not already installed):    <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n</code></pre></p> </li> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/dylangames/openmas.git\ncd openmas\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>poetry install\n</code></pre></p> </li> <li> <p>Install pre-commit hooks:    <pre><code>poetry run pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"contributing/development_workflow/#dependency-management","title":"Dependency Management","text":"<p>OpenMAS uses a DRY (Don't Repeat Yourself) approach to dependency management by leveraging Poetry for all dependency definitions in <code>pyproject.toml</code>, while tox environments use Poetry to install dependencies as needed.</p>"},{"location":"contributing/development_workflow/#how-it-works","title":"How it works","text":"<ol> <li>All dependencies are defined in <code>pyproject.toml</code>:</li> <li>Core dependencies in <code>[tool.poetry.dependencies]</code></li> <li>Dev dependencies in <code>[tool.poetry.group.dev.dependencies]</code></li> <li> <p>Optional dependencies in <code>[tool.poetry.extras]</code></p> </li> <li> <p>The tox environments use Poetry to install dependencies with the correct extras:    <pre><code>[testenv]\ncommands_pre =\n    poetry install --with dev {env:TOX_EXTRAS:}\n</code></pre></p> </li> <li> <p>Specific environments that need additional extras (like MCP integration) set environment variables:    <pre><code>[testenv:integration-mock]\nsetenv =\n    TOX_EXTRAS = --extras mcp\n</code></pre></p> </li> </ol> <p>This approach ensures that the tox environments always use the same versions of dependencies as defined in <code>pyproject.toml</code>, eliminating duplication and potential version conflicts.</p>"},{"location":"contributing/development_workflow/#convenience-scripts","title":"Convenience Scripts","text":""},{"location":"contributing/development_workflow/#check_qualitysh","title":"check_quality.sh","text":"<p>For convenience, OpenMAS provides a script that runs all the quality checks in one command:</p> <pre><code># Run all checks (linting and tests)\n./scripts/check_quality.sh\n\n# Run only linting checks\n./scripts/check_quality.sh lint\n\n# Run only tests\n./scripts/check_quality.sh test\n</code></pre> <p>This script provides color-coded output and helpful troubleshooting tips if any checks fail. It uses the tox environments under the hood to ensure consistency with CI checks.</p>"},{"location":"contributing/development_workflow/#common-commands","title":"Common Commands","text":""},{"location":"contributing/development_workflow/#linting-and-formatting","title":"Linting and Formatting","text":"<pre><code># Run all linting checks\npoetry run tox -e lint\n\n# Format code directly\npoetry run black .\npoetry run isort .\n\n# Run flake8 linting\npoetry run flake8 src tests examples\n\n# Run type checking with mypy\npoetry run mypy --config-file=mypy.ini src tests examples\n</code></pre>"},{"location":"contributing/development_workflow/#unit-tests","title":"Unit Tests","text":"<pre><code># Run all unit tests\npoetry run tox -e unit\n\n# Run specific unit tests\npoetry run tox -e unit -- tests/unit/agent/test_specific.py\n\n# Run with pytest directly (faster during development)\npoetry run pytest tests/unit/\n</code></pre>"},{"location":"contributing/development_workflow/#integration-tests","title":"Integration Tests","text":"<pre><code># Run integration tests with mocks (no real dependencies needed)\npoetry run tox -e integration-mock\n\n# Run integration tests with MCP (requires MCP setup)\npoetry run tox -e integration-real-mcp\n\n# Run integration tests with gRPC\npoetry run tox -e integration-real-grpc\n\n# Run integration tests with MQTT\npoetry run tox -e integration-real-mqtt\n</code></pre>"},{"location":"contributing/development_workflow/#coverage-report","title":"Coverage Report","text":"<pre><code># Run tests with coverage report\npoetry run tox -e coverage\n</code></pre>"},{"location":"contributing/development_workflow/#documentation","title":"Documentation","text":"<pre><code># Build documentation\npoetry run tox -e docs\n\n# Serve documentation locally (after building)\npoetry run mkdocs serve\n</code></pre>"},{"location":"contributing/development_workflow/#examples","title":"Examples","text":"<pre><code># Run the hello agent example\npoetry run tox -e example-00a-hello-single\n</code></pre>"},{"location":"contributing/development_workflow/#available-tox-environments","title":"Available Tox Environments","text":"<p>OpenMAS defines the following tox environments:</p> Environment Description <code>lint</code> Run linting, formatting checks, and type checking <code>unit</code> Run all unit tests (fast, no external deps) <code>integration-mock</code> Run integration tests using mocks (no real services) <code>integration-real-mcp</code> Run real integration tests requiring MCP services <code>integration-real-grpc</code> Run real integration tests requiring gRPC services <code>integration-real-mqtt</code> Run real integration tests requiring MQTT broker <code>coverage</code> Run tests with coverage report <code>docs</code> Build documentation <code>example-00a-hello-single</code> Run the single hello world agent example"},{"location":"contributing/development_workflow/#continuous-integration","title":"Continuous Integration","text":"<p>The CI/CD pipeline automatically runs the following checks on pull requests:</p> <ol> <li>Linting and static type checking with <code>tox -e lint</code></li> <li>Unit tests with <code>tox -e unit</code></li> <li>Mock integration tests with <code>tox -e integration-mock</code></li> <li>Coverage reporting with <code>tox -e coverage</code></li> </ol>"},{"location":"contributing/development_workflow/#troubleshooting","title":"Troubleshooting","text":""},{"location":"contributing/development_workflow/#dependency-issues","title":"Dependency Issues","text":"<p>If you encounter dependency-related errors when running tox, try the following steps:</p> <ol> <li> <p>Update Poetry and tox to the latest versions:    <pre><code>pip install --upgrade poetry tox\n</code></pre></p> </li> <li> <p>Update your Poetry lock file:    <pre><code>poetry update\n</code></pre></p> </li> <li> <p>Clean the tox environments and try again:    <pre><code>rm -rf .tox\npoetry run tox -e lint\n</code></pre></p> </li> </ol>"},{"location":"contributing/development_workflow/#version-pinning","title":"Version Pinning","text":"<p>Since the tox.ini environment dependencies now rely on Poetry's dependency resolution, ensure that version constraints in <code>pyproject.toml</code> are appropriately specified to avoid CI/local inconsistencies:</p> <ul> <li>For development tools (like black, flake8, mypy), use exact pins (<code>black = \"==25.1.0\"</code>) to ensure consistent behavior</li> <li>For libraries, use appropriate version constraints (<code>\"&gt;=x.y.z,&lt;a.b.c\"</code>) as needed</li> </ul>"},{"location":"contributing/docstring_policy/","title":"OpenMAS Docstring Policy","text":"<p>This document defines the standard format for docstrings in the OpenMAS codebase.</p>"},{"location":"contributing/docstring_policy/#docstring-style","title":"Docstring Style","text":"<p>OpenMAS uses Google-style docstrings throughout the codebase. This style is chosen for its readability, ease of use, and compatibility with tools like Sphinx and mkdocs.</p>"},{"location":"contributing/docstring_policy/#required-elements","title":"Required Elements","text":""},{"location":"contributing/docstring_policy/#module-docstrings","title":"Module Docstrings","text":"<p>Each Python module should have a docstring at the top that describes its purpose:</p> <pre><code>\"\"\"OpenMAS communication module.\n\nThis module provides communication infrastructure for agents to exchange\nmessages using various protocols and message formats.\n\"\"\"\n</code></pre>"},{"location":"contributing/docstring_policy/#class-docstrings","title":"Class Docstrings","text":"<p>Each class should have a docstring describing its purpose, behavior, and usage:</p> <pre><code>class Agent:\n    \"\"\"The main agent class for building multi-agent systems.\n\n    Agent handles message routing, state management, and communication\n    with other agents and services. It provides a simple interface for\n    developers to focus on business logic.\n\n    Attributes:\n        name: The name of the agent.\n        communicator: The communicator instance used by this agent.\n    \"\"\"\n</code></pre>"},{"location":"contributing/docstring_policy/#method-and-function-docstrings","title":"Method and Function Docstrings","text":"<p>Each method and function should have a docstring describing its purpose, parameters, return values, and exceptions:</p> <pre><code>async def send_request(\n    self,\n    target_service: str,\n    method: str,\n    params: Optional[Dict[str, Any]] = None,\n    response_model: Optional[Type[BaseModel]] = None,\n    timeout: Optional[float] = None,\n) -&gt; Any:\n    \"\"\"Send a request to a target service and wait for a response.\n\n    Args:\n        target_service: The name of the target service.\n        method: The method name to call on the target service.\n        params: Optional parameters to pass to the method.\n        response_model: Optional Pydantic model to validate and parse the response.\n        timeout: Optional timeout in seconds. None means use default timeout.\n\n    Returns:\n        The parsed response from the target service. If response_model is provided,\n        the response will be validated and parsed into that model.\n\n    Raises:\n        ServiceNotFoundError: If the target service is not found.\n        CommunicationError: If there is a problem with communication.\n        ValidationError: If response validation fails.\n        TimeoutError: If the request times out.\n    \"\"\"\n</code></pre>"},{"location":"contributing/docstring_policy/#property-docstrings","title":"Property Docstrings","text":"<p>Properties should also have docstrings:</p> <pre><code>@property\ndef is_running(self) -&gt; bool:\n    \"\"\"Return True if the agent is currently running.\"\"\"\n    return self._is_running\n</code></pre>"},{"location":"contributing/docstring_policy/#documentation-tools","title":"Documentation Tools","text":"<p>The project uses Sphinx with the <code>napoleon</code> extension to generate documentation from Google-style docstrings. To build documentation, run:</p> <pre><code>poetry run sphinx-build -b html docs/source docs/build/html\n</code></pre>"},{"location":"contributing/docstring_policy/#style-guidelines","title":"Style Guidelines","text":"<ol> <li>Keep docstrings clear and concise: Focus on conveying meaning, not just describing the code.</li> <li>Always document parameters and return values: This helps users understand how to use functions.</li> <li>Document exceptions: List all exceptions that can be raised and the conditions under which they occur.</li> <li>Use type hints: Combine docstrings with Python type hints for better documentation.</li> <li>Document complex logic: If a method contains complex logic, explain the reason and approach.</li> <li>Example usage: For public APIs, consider including example usage.</li> </ol> <pre><code>def get_logger(name: str) -&gt; Logger:\n    \"\"\"Get a logger instance for the given name.\n\n    Args:\n        name: The name for the logger, typically __name__.\n\n    Returns:\n        A Logger instance configured with the OpenMAS logging settings.\n\n    Example:\n        ```python\n        from openmas.logging import get_logger\n\n        logger = get_logger(__name__)\n        logger.info(\"This is a log message\")\n        ```\n    \"\"\"\n</code></pre>"},{"location":"contributing/docstring_policy/#validation","title":"Validation","text":"<p>The CI pipeline includes a check for docstring coverage and compliance with this policy using the <code>pydocstyle</code> tool. Ensure all new code follows these guidelines to pass CI checks.</p>"},{"location":"contributing/example_prompts/","title":"Example Prompts for Contributors","text":"<p>This document provides sample prompts to help contributors create consistent and high-quality examples for OpenMAS.</p>"},{"location":"contributing/example_prompts/#general-notes-on-creating-examples","title":"General Notes on Creating Examples","text":"<p>When creating examples for OpenMAS, follow these key principles:</p> <ol> <li>Test-Driven Development: Begin by writing the test for the example before implementing it</li> <li>Completeness: Ensure examples include all required files: agents, configuration, READMEs, and tests</li> <li>Minimum Working Examples: Make examples focused and minimal while still demonstrating the feature</li> <li>Clear Documentation: Include clear explanations in README.md and code comments</li> <li>Consistency: Follow the established patterns in existing examples</li> </ol>"},{"location":"contributing/example_prompts/#sample-prompt-multi-agent-http-example","title":"Sample Prompt: Multi-Agent HTTP Example","text":"<p>Here's a detailed prompt for creating a multi-agent HTTP example:</p> <pre><code>Prompt: Multi-Agent \"Hello World\" with HTTP Communicator\n\nObjective: Create, configure, and test a simple two-agent system using HTTP communication. The primary goal is to demonstrate how agents can communicate using the HTTP communicator.\n\nContext: This example will feature a sender agent that sends messages to a receiver agent using HTTP communication. Both agents need to implement the required BaseAgent methods (setup, run, shutdown). The example will demonstrate basic request-response patterns over HTTP.\n\nTask:\n1. **Navigate:** Ensure you are in the `openmas/` project root directory.\n\n2. **Create Directory Structure:**\n   ```bash\n   mkdir -p examples/01_communication_basics/00_http_client_server/agents/{sender,receiver}\n   ```\n\n3. **Implement Agents:**\n   * Create `examples/01_communication_basics/00_http_client_server/agents/sender/agent.py`:\n     * Define `SenderAgent(BaseAgent)` class implementing all required methods\n     * In `async def run(self):`, send an HTTP request to the receiver using `self.communicator.send_request()`\n     * Include appropriate logging and error handling\n\n   * Create `examples/01_communication_basics/00_http_client_server/agents/receiver/agent.py`:\n     * Define `ReceiverAgent(BaseAgent)` class implementing all required methods\n     * Register a handler in `setup()` method to process incoming requests\n     * Include appropriate logging and responses\n\n4. **Create Package Initialization Files:**\n   * Create `__init__.py` files in all appropriate directories to ensure proper importing\n\n5. **Create Project Configuration:**\n   * Create `examples/01_communication_basics/00_http_client_server/openmas_project.yml`:\n     * Define both agents with their appropriate modules/classes\n     * Configure the HTTP communicator with appropriate ports\n     * Add service URLs to enable agents to find each other\n\n6. **Create Requirements File:**\n   * Create a minimal `requirements.txt` file if any additional dependencies are needed\n\n7. **Implement Tests:**\n   * Create `examples/01_communication_basics/00_http_client_server/test_example.py`:\n     * Import `AgentTestHarness` and agent classes\n     * Use expectation-based testing pattern to validate communication\n     * Set up appropriate request expectations\n     * Verify agent behavior and communication\n\n8. **Create Documentation:**\n   * Write a detailed `README.md` explaining:\n     * Purpose of the example\n     * Core concepts demonstrated (HTTP communication)\n     * How to run the example\n     * Expected results\n     * Project structure\n\n9. **Update tox.ini:**\n   * Add a new environment for running the example's tests\n   * Ensure proper environment setup and dependencies\n\n10. **Test Thoroughly:**\n    * Run the test via tox to verify it works\n    * Fix any issues that arise\n    * Test manually to ensure proper functionality\n\n**Key Implementation Details:**\n\n1. **SenderAgent:**\n   ```python\n   async def run(self) -&gt; None:\n       \"\"\"Run the agent, sending a request to the receiver.\"\"\"\n       self.logger.info(\"Sender sending HTTP request\")\n       try:\n           response = await self.communicator.send_request(\n               target_service=\"receiver\",\n               method=\"process_message\",\n               params={\"message\": \"Hello from HTTP sender!\"}\n           )\n           self.logger.info(f\"Received response: {response}\")\n       except Exception as e:\n           self.logger.error(f\"Error sending request: {e}\")\n   ```\n\n2. **ReceiverAgent:**\n   ```python\n   async def setup(self) -&gt; None:\n       \"\"\"Set up the receiver agent.\"\"\"\n       self.logger.info(\"Setting up ReceiverAgent\")\n       # Register handler for incoming requests\n       await self.communicator.register_handler(\n           \"process_message\", self.handle_message\n       )\n\n   async def handle_message(self, payload: dict) -&gt; dict:\n       \"\"\"Handle incoming messages.\"\"\"\n       self.logger.info(f\"Received message: {payload}\")\n       return {\"status\": \"success\", \"response\": \"Message received!\"}\n   ```\n\n3. **Project Configuration:**\n   ```yaml\n   name: examples/01_communication_basics/00_http_client_server\n   version: 0.1.0\n   agents:\n     sender: \"agents/sender\"\n     receiver: \"agents/receiver\"\n   default_config:\n     log_level: INFO\n   communicator_defaults:\n     type: http\n     options:\n       http_port: 8000\n   agent_configs:\n     receiver:\n       communicator_options:\n         http_port: 8001\n     sender:\n       service_urls:\n         receiver: \"http://localhost:8001\"\n   ```\n\n4. **Test Strategy:**\n   - Use `AgentTestHarness` to create and manage agent instances\n   - Set up expectations for HTTP requests/responses\n   - Verify that agents implement the expected communication pattern\n   ```python\n   # Example test snippet\n   sender_harness = AgentTestHarness(SenderAgent)\n   sender = await sender_harness.create_agent(name=\"sender\")\n\n   # Set up expected HTTP request\n   sender.communicator.expect_request(\n       target_service=\"receiver\",\n       method=\"process_message\",\n       params={\"message\": \"Hello from HTTP sender!\"},\n       response={\"status\": \"success\", \"response\": \"Message received!\"}\n   )\n\n   # Run the test\n   async with sender_harness.running_agent(sender):\n       await sender.run()\n       sender.communicator.verify()\n   ```\n</code></pre>"},{"location":"contributing/example_prompts/#sample-prompt-bdi-agent-example","title":"Sample Prompt: BDI Agent Example","text":"<pre><code>Prompt: BDI Agent Pattern Example\n\nObjective: Create a simple example demonstrating the Belief-Desire-Intention (BDI) agent pattern using OpenMAS's BdiAgent class. This example should showcase how to create and manage beliefs, desires, and intentions within an agent.\n\nContext: The BDI architecture is a popular agent design pattern where agents maintain beliefs about the world, desires (goals) they want to achieve, and intentions (current plans). This example will demonstrate how to implement a simple BDI agent in OpenMAS.\n\nTask:\n1. **Navigate:** Ensure you are in the `openmas/` project root directory.\n\n2. **Create Directory Structure:**\n   ```bash\n   mkdir -p examples/03_agent_patterns/00_bdi_agent/agents/gardener\n   ```\n\n3. **Implement Agents:**\n   * Create `examples/03_agent_patterns/00_bdi_agent/agents/gardener/agent.py`:\n     * Define `GardenerAgent(BdiAgent)` that maintains beliefs about a garden\n     * Implement intentions to water plants, remove weeds, etc. based on beliefs\n     * Use the BDI pattern to make decisions based on the agent's current state\n\n4. **Create Package Initialization Files:**\n   * Create `__init__.py` files in all appropriate directories\n\n5. **Create Project Configuration:**\n   * Create `examples/03_agent_patterns/00_bdi_agent/openmas_project.yml`:\n     * Define the gardener agent and its configuration\n     * Use a mock communicator for testing\n\n6. **Implement Tests:**\n   * Create `examples/03_agent_patterns/00_bdi_agent/test_example.py`:\n     * Test the agent's ability to update beliefs\n     * Test decision-making based on beliefs\n     * Verify that intentions are executed appropriately\n\n7. **Create Documentation:**\n   * Write a detailed `README.md` explaining the BDI pattern and how it's implemented\n\n8. **Update tox.ini:**\n   * Add a new environment for testing the BDI example\n</code></pre>"},{"location":"contributing/example_prompts/#adding-new-examples-to-the-documentation","title":"Adding New Examples to the Documentation","text":"<p>When adding new examples, ensure you:</p> <ol> <li>Update the main examples documentation in <code>docs/examples.md</code></li> <li>Add the new tox environment to the project's <code>tox.ini</code> file</li> <li>Ensure the example follows existing patterns and directory structures</li> <li>Include complete documentation in the example's README.md</li> </ol>"},{"location":"contributing/example_prompts/#testing-your-examples","title":"Testing Your Examples","text":"<p>All examples must be thoroughly tested using the following approach:</p> <ol> <li>Write Tests First: Create a <code>test_example.py</code> file that validates the example's functionality</li> <li>Use AgentTestHarness: For agent-based examples, use <code>AgentTestHarness</code> to test agent behavior</li> <li>Expectation-Based Testing: For communication tests, set up expectations and verify them</li> <li>Add to tox.ini: Create a dedicated tox environment for your example</li> <li>Run Both Automated and Manual Tests: Ensure the example works both via automated tests and when run manually</li> </ol> <p>For more detailed information on testing approaches, refer to: - Testing Utilities Guide - Testing Strategy for Contributors</p>"},{"location":"contributing/example_prompts/#testing-your-examples-advanced-testing-patterns","title":"Testing Your Examples: Advanced Testing Patterns","text":"<p>OpenMAS provides two main testing approaches, each with specific use cases:</p>"},{"location":"contributing/example_prompts/#1-streamlined-helper-functions-recommended-for-most-cases","title":"1. Streamlined Helper Functions (Recommended for Most Cases)","text":"<p>This approach uses helper functions that simplify common testing patterns:</p> <pre><code>import pytest\nfrom agents.receiver import ReceiverAgent\nfrom agents.sender import SenderAgent\nfrom openmas.testing import expect_sender_request, multi_running_agents, setup_sender_receiver_test\n\n@pytest.mark.asyncio\nasync def test_hello_pair_mock():\n    # Set up sender and receiver agents in one line\n    sender_harness, receiver_harness, sender, receiver = await setup_sender_receiver_test(\n        SenderAgent, ReceiverAgent\n    )\n\n    # Set up expectations with the simplified helper\n    expect_sender_request(\n        sender,\n        \"receiver\",\n        \"process_message\",\n        {\"message\": \"Hello from sender!\"},\n        {\"status\": \"success\", \"response\": \"Message received!\"}\n    )\n\n    # Run both agents with a single context manager\n    async with multi_running_agents(sender_harness, sender, receiver_harness, receiver):\n        await sender.run()\n        sender.communicator.verify()\n</code></pre> <p>When to use this approach: - For sender-receiver test patterns (the most common scenario) - When you want minimal boilerplate code - For examples that demonstrate typical agent interactions - When clarity and brevity are important</p>"},{"location":"contributing/example_prompts/#2-direct-harness-and-expectations-for-greater-control","title":"2. Direct Harness and Expectations (For Greater Control)","text":"<p>This approach gives you more direct control over harness creation and expectation setup:</p> <pre><code>import pytest\nfrom openmas.testing import AgentTestHarness\nfrom agents.my_agent import MySpecialAgent\n\n@pytest.mark.asyncio\nasync def test_custom_agent_behavior():\n    # Create and configure a harness with custom options\n    harness = AgentTestHarness(MySpecialAgent,\n                              default_config={\"custom_option\": True})\n\n    # Create an agent with specific configuration\n    agent = await harness.create_agent(name=\"custom-agent\",\n                                     config={\"special_mode\": \"advanced\"})\n\n    # Set up complex expectations directly\n    agent.communicator.expect_request(\n        target_service=\"external-service\",\n        method=\"complex_operation\",\n        params={\"nested\": {\"data\": {\"structure\": 123}}},\n        response={\"result\": {\"detailed\": \"response\"}}\n    )\n\n    # Run the agent and test its behavior\n    async with harness.running_agent(agent):\n        await agent.perform_special_operation()\n        agent.communicator.verify()\n\n        # Assert custom state changes\n        assert agent.operation_count == 1\n        assert agent.last_result[\"detailed\"] == \"response\"\n</code></pre> <p>When to use this approach: - For testing agents with complex configuration requirements - When you need to assert agent state changes beyond just communications - For non-standard testing scenarios (beyond simple sender-receiver) - When testing specialized agent patterns (e.g., BDI agents, orchestrators)</p>"},{"location":"contributing/prompt_and_sampling/","title":"Prompt Management and Sampling Implementation Guide","text":"<p>This document provides detailed information about the implementation of OpenMAS's prompt management and sampling systems for contributors who want to understand, extend, or modify these modules.</p>"},{"location":"contributing/prompt_and_sampling/#architecture-overview","title":"Architecture Overview","text":"<p>The prompt management and sampling systems are designed with the following principles:</p> <ul> <li>Modularity: Clear separation of concerns between different components</li> <li>Extensibility: Easy to extend with new storage backends, sampling providers, etc.</li> <li>Type Safety: Strong typing with Pydantic for all data models</li> <li>Async-First: All operations are async-compatible for integration with OpenMAS agents</li> <li>Protocol Integration: Seamless integration with MCP (Model Context Protocol)</li> </ul> <p>The architecture consists of two primary subsystems:</p> <ol> <li>Prompt Management: Defines, stores, and retrieves prompts</li> <li>Sampling: Handles interaction with language models</li> </ol>"},{"location":"contributing/prompt_and_sampling/#directory-structure","title":"Directory Structure","text":"<pre><code>src/openmas/\n\u251c\u2500\u2500 prompt/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base.py         # Core prompt management classes\n\u2502   \u2514\u2500\u2500 mcp.py          # MCP integration\n\u251c\u2500\u2500 sampling/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base.py         # Core sampling abstractions\n\u2502   \u2514\u2500\u2500 providers/      # Provider-specific implementations\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 mcp.py      # MCP-specific sampler\n\u2514\u2500\u2500 agent/\n    \u2514\u2500\u2500 mcp_prompt.py   # Enhanced MCP agent with prompt &amp; sampling\n</code></pre>"},{"location":"contributing/prompt_and_sampling/#prompt-management-system","title":"Prompt Management System","text":""},{"location":"contributing/prompt_and_sampling/#core-classes","title":"Core Classes","text":""},{"location":"contributing/prompt_and_sampling/#promptmetadata","title":"<code>PromptMetadata</code>","text":"<pre><code>class PromptMetadata(BaseModel):\n    \"\"\"Metadata for a prompt.\"\"\"\n    name: str\n    description: Optional[str] = None\n    version: str = \"1.0.0\"\n    created_at: str = Field(default_factory=lambda: datetime.datetime.now().isoformat())\n    updated_at: str = Field(default_factory=lambda: datetime.datetime.now().isoformat())\n    tags: Set[str] = Field(default_factory=set)\n    author: Optional[str] = None\n</code></pre> <p>Key design decisions: - Uses ISO format for timestamps to ensure compatibility and ease of parsing - Includes version field for tracking prompt evolution - Tags are a set to prevent duplicates and enable efficient filtering</p>"},{"location":"contributing/prompt_and_sampling/#promptcontent","title":"<code>PromptContent</code>","text":"<pre><code>class PromptContent(BaseModel):\n    \"\"\"Content for a prompt.\"\"\"\n    system: Optional[str] = None\n    template: Optional[str] = None\n    examples: List[Dict[str, Any]] = Field(default_factory=list)\n    context_keys: Set[str] = Field(default_factory=set)\n    fallback: Optional[str] = None\n</code></pre> <p>Key design decisions: - Separate system prompt and template for flexible composition - Supports examples for few-shot learning - <code>context_keys</code> tracks expected template variables (though not strictly enforced) - <code>fallback</code> provides a default response if rendering fails</p>"},{"location":"contributing/prompt_and_sampling/#prompt","title":"<code>Prompt</code>","text":"<pre><code>class Prompt(BaseModel):\n    \"\"\"A prompt definition with metadata and content.\"\"\"\n    metadata: PromptMetadata\n    content: PromptContent\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n</code></pre> <p>Key design decisions: - Auto-generated UUID for stable identification across systems - Separation of metadata and content for cleaner organization - Helper methods for common operations like retrieving system prompt</p>"},{"location":"contributing/prompt_and_sampling/#promptstorage","title":"<code>PromptStorage</code>","text":"<pre><code>class PromptStorage(BaseModel):\n    \"\"\"Base class for prompt storage backends.\"\"\"\n    async def save(self, prompt: Prompt) -&gt; None: ...\n    async def load(self, prompt_id: str) -&gt; Optional[Prompt]: ...\n    async def list(self, tag: Optional[str] = None) -&gt; List[PromptMetadata]: ...\n    async def delete(self, prompt_id: str) -&gt; bool: ...\n</code></pre> <p>Key design decisions: - Abstract base class to enable multiple storage implementations - Async methods for compatibility with OpenMAS agents - <code>list()</code> returns only metadata to reduce data transfer when listing many prompts</p>"},{"location":"contributing/prompt_and_sampling/#promptmanager","title":"<code>PromptManager</code>","text":"<pre><code>class PromptManager:\n    \"\"\"Manages prompts for an agent.\"\"\"\n    def __init__(self, storage: Optional[PromptStorage] = None) -&gt; None: ...\n    async def create_prompt(self, name: str, ...) -&gt; Prompt: ...\n    async def get_prompt(self, prompt_id: str) -&gt; Optional[Prompt]: ...\n    async def get_prompt_by_name(self, name: str) -&gt; Optional[Prompt]: ...\n    async def update_prompt(self, prompt_id: str, **kwargs: Any) -&gt; Optional[Prompt]: ...\n    async def delete_prompt(self, prompt_id: str) -&gt; bool: ...\n    async def list_prompts(self, tag: Optional[str] = None) -&gt; List[PromptMetadata]: ...\n    async def render_prompt(self, prompt_id: str, ...) -&gt; Optional[Dict[str, Any]]: ...\n</code></pre> <p>Key design decisions: - Local caching of prompts for performance - Defaults to <code>MemoryPromptStorage</code> if no storage provided - Comprehensive CRUD operations - Flexible prompt creation with optional parameters - Simple template rendering (could be extended with a template engine)</p>"},{"location":"contributing/prompt_and_sampling/#storage-implementations","title":"Storage Implementations","text":""},{"location":"contributing/prompt_and_sampling/#memorypromptstorage","title":"<code>MemoryPromptStorage</code>","text":"<p>In-memory storage suitable for testing or simple applications.</p> <pre><code>class MemoryPromptStorage(PromptStorage):\n    \"\"\"Store prompts in memory.\"\"\"\n    prompts: Dict[str, Prompt] = Field(default_factory=dict)\n</code></pre>"},{"location":"contributing/prompt_and_sampling/#filesystempromptstorage","title":"<code>FileSystemPromptStorage</code>","text":"<p>File-based storage for persistence between runs.</p> <pre><code>class FileSystemPromptStorage(PromptStorage):\n    \"\"\"Store prompts in the file system.\"\"\"\n    path: Path = Field(..., description=\"Path to store prompts\")\n</code></pre> <p>Key design decisions: - Each prompt is stored as a separate JSON file - Files are named with the prompt's UUID - Automatically creates storage directory if it doesn't exist</p>"},{"location":"contributing/prompt_and_sampling/#sampling-system","title":"Sampling System","text":""},{"location":"contributing/prompt_and_sampling/#core-classes_1","title":"Core Classes","text":""},{"location":"contributing/prompt_and_sampling/#samplingparameters","title":"<code>SamplingParameters</code>","text":"<pre><code>class SamplingParameters(BaseModel):\n    \"\"\"Parameters for sampling from a language model.\"\"\"\n    temperature: Optional[float] = Field(default=0.7, ge=0.0, le=1.0)\n    max_tokens: Optional[int] = Field(default=1024, gt=0)\n    top_p: Optional[float] = Field(default=0.9, ge=0.0, le=1.0)\n    top_k: Optional[int] = Field(default=None, gt=0)\n    stop_sequences: Optional[List[str]] = None\n    repetition_penalty: Optional[float] = Field(default=None, ge=0.0)\n    presence_penalty: Optional[float] = Field(default=None, ge=0.0)\n    frequency_penalty: Optional[float] = Field(default=None, ge=0.0)\n    seed: Optional[int] = None\n</code></pre> <p>Key design decisions: - Includes all common sampling parameters used by major LLM providers - Uses Pydantic validators (ge, le, gt) to ensure valid parameter ranges - All parameters are optional with sensible defaults - <code>to_dict()</code> method omits None values for clean API calls</p>"},{"location":"contributing/prompt_and_sampling/#messagerole-and-message","title":"<code>MessageRole</code> and <code>Message</code>","text":"<pre><code>class MessageRole(str, Enum):\n    \"\"\"Role of a message in a conversation.\"\"\"\n    SYSTEM = \"system\"\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n    TOOL = \"tool\"\n\nclass Message(BaseModel):\n    \"\"\"A message in a conversation.\"\"\"\n    role: MessageRole\n    content: str\n    metadata: Optional[Dict[str, Any]] = None\n</code></pre> <p>Key design decisions: - Uses an Enum for roles to ensure consistent values - Supports metadata for additional message information - Simple structure aligns with common LLM provider APIs</p>"},{"location":"contributing/prompt_and_sampling/#samplingcontext","title":"<code>SamplingContext</code>","text":"<pre><code>class SamplingContext(BaseModel):\n    \"\"\"Context for a sampling operation.\"\"\"\n    system_prompt: Optional[str] = None\n    messages: List[Message] = Field(default_factory=list)\n    parameters: SamplingParameters = Field(default_factory=SamplingParameters)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n</code></pre> <p>Key design decisions: - Complete context for a sampling operation - Follows common patterns used by major LLM providers - Factory method <code>from_prompt()</code> to create context from a prompt - Helper methods for common operations</p>"},{"location":"contributing/prompt_and_sampling/#samplingresult","title":"<code>SamplingResult</code>","text":"<pre><code>class SamplingResult(BaseModel):\n    \"\"\"Result of a sampling operation.\"\"\"\n    content: str\n    finish_reason: Optional[str] = None\n    usage: Optional[Dict[str, int]] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    raw_response: Optional[Any] = None\n</code></pre> <p>Key design decisions: - Stores the essential response content plus additional metadata - Captures raw response for debugging or advanced usage - Includes common fields like usage stats and finish reason - Serialization methods for consistent output</p>"},{"location":"contributing/prompt_and_sampling/#sampler-protocol-and-base-class","title":"<code>Sampler</code> Protocol and Base Class","text":"<pre><code>@runtime_checkable\nclass SamplerProtocol(Protocol):\n    \"\"\"Protocol for samplers.\"\"\"\n    async def sample(self, context: SamplingContext, model: Optional[str] = None) -&gt; SamplingResult: ...\n\nclass Sampler:\n    \"\"\"Base class for samplers.\"\"\"\n    async def sample(self, context: SamplingContext, model: Optional[str] = None) -&gt; SamplingResult: ...\n    @classmethod\n    def create_context(cls, system: Optional[str] = None, ...) -&gt; SamplingContext: ...\n    async def sample_from_prompt(self, prompt: Prompt, ...) -&gt; SamplingResult: ...\n</code></pre> <p>Key design decisions: - Uses Protocol for structural typing - Base class with shared functionality - Helper methods for creating contexts and sampling from prompts - Abstract <code>sample()</code> method to be implemented by subclasses</p>"},{"location":"contributing/prompt_and_sampling/#provider-implementations","title":"Provider Implementations","text":""},{"location":"contributing/prompt_and_sampling/#mcpsampler","title":"<code>McpSampler</code>","text":"<pre><code>class McpSampler(Sampler):\n    \"\"\"Sampler that uses MCP to sample from a language model.\"\"\"\n    def __init__(self, communicator: BaseCommunicator, target_service: str, default_model: Optional[str] = None) -&gt; None: ...\n    async def sample(self, context: SamplingContext, model: Optional[str] = None) -&gt; SamplingResult: ...\n</code></pre> <p>Key design decisions: - Uses the existing MCP communicator infrastructure - Validates that the communicator supports sampling - Converts between OpenMAS sampling context and MCP format - Handles error cases with appropriate exceptions</p>"},{"location":"contributing/prompt_and_sampling/#mcpagentsampler","title":"<code>McpAgentSampler</code>","text":"<pre><code>class McpAgentSampler(Sampler):\n    \"\"\"Sampler that uses an MCP agent to sample from a language model.\"\"\"\n    def __init__(self, agent: McpAgent, target_service: str, default_model: Optional[str] = None) -&gt; None: ...\n    async def sample(self, context: SamplingContext, model: Optional[str] = None) -&gt; SamplingResult: ...\n</code></pre> <p>Key design decisions: - Uses an MCP agent directly instead of a communicator - Otherwise similar to <code>McpSampler</code> - Allows more direct integration with agent functionality</p>"},{"location":"contributing/prompt_and_sampling/#mcp-integration","title":"MCP Integration","text":""},{"location":"contributing/prompt_and_sampling/#prompt-registration-with-mcp","title":"Prompt Registration with MCP","text":"<p>The <code>McpPromptManager</code> class handles registration of prompts with an MCP server:</p> <pre><code>class McpPromptManager:\n    \"\"\"Manages prompts for MCP integration.\"\"\"\n    def __init__(self, prompt_manager: PromptManager) -&gt; None: ...\n    async def register_prompt_with_server(self, prompt_id: str, server: Any, name: Optional[str] = None) -&gt; Optional[str]: ...\n    async def register_all_prompts_with_server(self, server: Any, tag: Optional[str] = None) -&gt; List[str]: ...\n</code></pre> <p>Key design decisions: - Wraps a <code>PromptManager</code> to provide MCP-specific functionality - Gracefully handles the case where MCP is not installed - Creates handler functions that render prompts on demand - Returns the registered names for verification</p>"},{"location":"contributing/prompt_and_sampling/#enhanced-mcp-agent","title":"Enhanced MCP Agent","text":"<p>The <code>PromptMcpAgent</code> class extends <code>McpAgent</code> with prompt management and sampling capabilities:</p> <pre><code>class PromptMcpAgent(McpAgent):\n    \"\"\"Enhanced MCP agent with prompt management and sampling capabilities.\"\"\"\n    def __init__(self, name: Optional[str] = None, config: Optional[Dict[str, Any]] = None, prompt_manager: Optional[PromptManager] = None, **kwargs: Any) -&gt; None: ...\n    async def setup(self) -&gt; None: ...\n    async def register_prompts_with_server(self) -&gt; None: ...\n    async def create_prompt(self, name: str, ...) -&gt; Prompt: ...\n    async def render_prompt(self, prompt_id: str, ...) -&gt; Optional[Dict[str, Any]]: ...\n    async def sample(self, prompt_id: str, ...) -&gt; SamplingResult: ...\n    async def sample_text(self, system: Optional[str] = None, prompt: str = \"\", ...) -&gt; str: ...\n    async def chat(self, system: Optional[str] = None, messages: Optional[List[Dict[str, str]]] = None, ...) -&gt; SamplingResult: ...\n</code></pre> <p>Key design decisions: - Integrates all components (prompt management, sampling, MCP) - Creates the sampler during setup based on provided configuration - Provides high-level methods for common operations - Automatically registers prompts with the server in server mode - Lazy initialization of the sampler to handle different usage patterns</p>"},{"location":"contributing/prompt_and_sampling/#testing-strategy","title":"Testing Strategy","text":"<p>The prompt management and sampling systems are thoroughly tested with unit tests:</p> <ol> <li>Component Tests: Each class and method is tested individually</li> <li>Integration Tests: Components are tested working together</li> <li>Edge Cases: Tests cover error conditions, edge cases, and boundary values</li> </ol> <p>Example test files: - <code>tests/unit/prompt/test_prompt_manager.py</code>: Tests for prompt management - <code>tests/unit/sampling/test_sampling.py</code>: Tests for sampling abstractions - <code>tests/unit/sampling/providers/test_mcp_sampler.py</code>: Tests for MCP samplers - <code>tests/unit/prompt/test_mcp_prompt_manager.py</code>: Tests for MCP prompt integration - <code>tests/unit/agent/test_prompt_mcp_agent.py</code>: Tests for the enhanced MCP agent</p>"},{"location":"contributing/prompt_and_sampling/#future-improvements","title":"Future Improvements","text":"<p>Potential areas for enhancement:</p> <ol> <li>Advanced Template Engine: Replace the simple template rendering with a more powerful engine like Jinja2</li> <li>Additional Storage Backends: Implement database or cloud storage options</li> <li>Provider-Specific Samplers: Add samplers for direct integration with OpenAI, Anthropic, etc.</li> <li>Streaming Support: Add streaming capabilities for incremental results</li> <li>Batch Sampling: Support for batch operations to improve throughput</li> <li>Caching: Add caching layer for sampling results</li> <li>Prompt Versioning: Enhanced versioning with history tracking</li> <li>Prompt Sharing: Mechanism for sharing prompts between agents</li> </ol>"},{"location":"contributing/prompt_and_sampling/#contributing-guidelines","title":"Contributing Guidelines","text":"<p>When contributing to these modules, please follow these guidelines:</p> <ol> <li>Testing: Add tests for all new functionality</li> <li>Type Hints: Use proper type hints throughout</li> <li>Docstrings: Update docstrings for all public methods</li> <li>Backwards Compatibility: Maintain compatibility when extending functionality</li> <li>Error Handling: Use appropriate error types and provide helpful messages</li> <li>Logging: Add appropriate logging at DEBUG, INFO, WARNING, and ERROR levels</li> <li>Performance: Consider performance implications, especially for operations that might be called frequently</li> </ol>"},{"location":"contributing/prompt_and_sampling/#common-pitfalls","title":"Common Pitfalls","text":"<ol> <li>Template Variables: The simple template engine only supports simple replacements; consider using a proper template engine for complex cases</li> <li>Concurrency: Be aware of concurrency issues when multiple agents share a PromptManager</li> <li>Large Prompts: Very large prompts might cause performance issues; consider chunking or streaming</li> <li>Error Propagation: Ensure errors from the sampling operations are properly propagated and handled</li> </ol>"},{"location":"contributing/testing_strategy/","title":"OpenMAS Testing Strategy (for Contributors)","text":"<p>This document outlines the testing strategy for the <code>openmas</code> framework itself, providing guidance for contributors on test types, locations, and execution.</p> <p>For information on how to test applications built with OpenMAS, please see the user guide: Testing Your Agents.</p>"},{"location":"contributing/testing_strategy/#goals","title":"Goals","text":"<p>The OpenMAS internal testing framework addresses several key goals:</p> <ul> <li>Ensure correctness of individual framework components (agents, communicators, config, etc.).</li> <li>Prevent regressions when implementing new features or refactoring.</li> <li>Validate framework behavior in isolation and integration scenarios.</li> <li>Properly test optional features and communicators (like MCP, gRPC, MQTT).</li> <li>Provide end-to-end validation via example applications.</li> </ul>"},{"location":"contributing/testing_strategy/#testing-philosophy","title":"Testing Philosophy","text":"<p>OpenMAS follows a Test-Driven Development (TDD) approach internally:</p> <ol> <li>Write failing tests first.</li> <li>Implement the minimum code required to make the tests pass.</li> <li>Refactor the code while keeping the tests passing.</li> </ol> <p>This ensures that features are well-tested and code quality remains high.</p>"},{"location":"contributing/testing_strategy/#tooling","title":"Tooling","text":"<p>OpenMAS uses standard Python testing tools:</p> <ul> <li><code>pytest</code>: Primary test runner.</li> <li><code>pytest-asyncio</code>: Testing async code.</li> <li><code>pytest-mock</code>: Mocking dependencies.</li> <li><code>tox</code>: Test automation and environment management via directory targeting.</li> </ul>"},{"location":"contributing/testing_strategy/#test-levels-locations","title":"Test Levels &amp; Locations","text":"<p>Tests are organized primarily by directory structure within the <code>tests/</code> directory, reflecting the type of test and its dependencies.</p>"},{"location":"contributing/testing_strategy/#unit-tests-testsunit","title":"Unit Tests (<code>tests/unit/</code>)","text":"<p>Unit tests verify isolated components with all external dependencies mocked.</p> <ul> <li>Location: <code>tests/unit/</code></li> <li>Purpose: Test individual classes and functions (e.g., <code>BaseAgent</code> methods, config loading logic) with complete isolation.</li> <li>Dependencies: External dependencies (Communicators, I/O, network calls, file system access) are always mocked using <code>pytest-mock</code> or framework utilities like <code>MockCommunicator</code>.</li> <li>Execution: Run via the <code>tox -e unit</code> environment.</li> <li>Requirement: Must never be skipped due to the unavailability of external dependencies. They should be fast and self-contained.</li> </ul>"},{"location":"contributing/testing_strategy/#integration-tests-testsintegration","title":"Integration Tests (<code>tests/integration/</code>)","text":"<p>Integration tests verify how framework components work together or interact with external protocols/libraries. They are subdivided based on dependency requirements.</p> <ul> <li>Location: <code>tests/integration/</code></li> <li>Purpose: Test interactions between components (e.g., <code>BaseAgent</code> with <code>HttpCommunicator</code>) or with external services/protocols (e.g., connecting to a real MQTT broker).</li> <li>Dependencies: May use mocks (<code>MockCommunicator</code>, <code>AgentTestHarness</code>) or actual dependencies (like specific communicator libraries or running services).</li> <li>Execution: Run via various <code>tox -e integration-*</code> environments.</li> <li>Requirement: Tests relying on actual external services (like a running MQTT broker or specific MCP server setup) must be skipped (using <code>pytest.mark.skipif</code>) if the required service/dependency is unavailable in the test environment. Any test that is executed (not skipped) must pass.</li> </ul>"},{"location":"contributing/testing_strategy/#core-integration-tests-testsintegrationcore","title":"Core Integration Tests (<code>tests/integration/core/</code>)","text":"<ul> <li>Location: <code>tests/integration/core/</code></li> <li>Purpose: Test core feature interactions without optional extras (e.g., agent lifecycle with <code>HttpCommunicator</code>).</li> <li>Execution: Included in the <code>tox -e integration-mock</code> environment.</li> <li>Dependencies: Primarily test interactions between core components, typically using mocks like <code>MockCommunicator</code> or <code>AgentTestHarness</code> for simulating communication.</li> </ul>"},{"location":"contributing/testing_strategy/#mocked-integration-tests-testsintegrationfeaturemock","title":"Mocked Integration Tests (<code>tests/integration/&lt;feature&gt;/mock/</code>)","text":"<ul> <li>Example Location: <code>tests/integration/mcp/mock/</code></li> <li>Purpose: Test integration with optional features (like MCP, gRPC) using mocks instead of real services. Allows testing the integration logic (e.g., how <code>McpAgent</code> uses <code>McpSseCommunicator</code>) without needing the actual service running.</li> <li>Execution: Included in the <code>tox -e integration-mock</code> environment.</li> <li>Dependencies: Requires the feature's libraries installed (e.g., <code>mcp</code> via <code>openmas[mcp]</code>) but mocks the actual service interaction (e.g., using <code>AgentTestHarness</code> which injects <code>MockCommunicator</code>).</li> </ul>"},{"location":"contributing/testing_strategy/#real-service-integration-tests-testsintegrationfeaturereal-or-testsintegrationfeature","title":"Real Service Integration Tests (<code>tests/integration/&lt;feature&gt;/real/</code> or <code>tests/integration/&lt;feature&gt;/</code>)","text":"<ul> <li>Example Locations: <code>tests/integration/mcp/real/</code>, <code>tests/integration/grpc/</code>, <code>tests/integration/mqtt/</code></li> <li>Purpose: Test integration with optional features (like MCP, gRPC, MQTT) against real services or libraries. These verify the actual communication protocol implementation works correctly.</li> <li>Execution: Run via dedicated <code>tox</code> environments (e.g., <code>tox -e integration-real-mcp</code>, <code>tox -e integration-real-grpc</code>, <code>tox -e integration-real-mqtt</code>).</li> <li>Dependencies: Require the feature's libraries and potentially a running instance of the service (e.g., an MQTT broker, a specific test MCP server). These tests must use <code>pytest.mark.skipif</code> to check for service availability and skip gracefully if absent.</li> </ul>"},{"location":"contributing/testing_strategy/#example-tests-examples","title":"Example Tests (<code>examples/*/</code>)","text":"<p>Example tests run the actual example applications end-to-end, primarily for framework validation.</p> <ul> <li>Location: <code>examples/*/</code> (Test logic often in <code>test_example.py</code> within each example).</li> <li>Purpose: Framework dogfooding and end-to-end feature validation in a realistic context.</li> <li>Execution: Run via dedicated <code>tox</code> environments (e.g., <code>tox -e example-00a-hello-single</code>).</li> <li>Note: These validate that the framework enables the creation of working applications for specific scenarios.</li> </ul>"},{"location":"contributing/testing_strategy/#using-the-testing-harness-and-mock-communicator","title":"Using the Testing Harness and Mock Communicator","text":"<p>OpenMAS provides powerful testing utilities that are used across all test levels:</p>"},{"location":"contributing/testing_strategy/#mockcommunicator-overview","title":"MockCommunicator Overview","text":"<p><code>MockCommunicator</code> is used to mock agent communication in isolation. Key aspects:</p> <ol> <li> <p>Expectation Based Testing: It uses an expectations pattern - you define what calls are expected and with what parameters, then verify they were made.</p> </li> <li> <p>Available Methods:</p> </li> <li><code>expect_request()</code>: Set up an expected outgoing request with a predefined response</li> <li><code>expect_notification()</code>: Set up an expected outgoing notification</li> <li><code>trigger_handler()</code>: Directly trigger an agent's registered handler for testing</li> <li> <p><code>verify()</code>: Check that all expected requests/notifications were made</p> </li> <li> <p>Common Pattern: <pre><code># Set expectation for outgoing calls\ncommunicator.expect_request(\n    target_service=\"service\",\n    method=\"operation\",\n    params={\"expected\": \"params\"},\n    response={\"mock\": \"response\"}\n)\n\n# Run agent code that should make that call\nawait agent.do_something()\n\n# Verify expectations\ncommunicator.verify()\n</code></pre></p> </li> </ol>"},{"location":"contributing/testing_strategy/#agenttestharness-overview","title":"AgentTestHarness Overview","text":"<p><code>AgentTestHarness</code> manages agent lifecycle with mocked communicators. Key aspects:</p> <ol> <li> <p>Agent Class Requirements: You must pass in an agent class (not instance) that implements all abstract methods from <code>BaseAgent</code> (<code>setup</code>, <code>run</code>, <code>shutdown</code>).</p> </li> <li> <p>Agent Creation Pattern: <pre><code># Create harness with your agent class\nharness = AgentTestHarness(MyAgent)\n\n# Create an agent instance\nagent = await harness.create_agent(name=\"test-agent\")\n\n# The harness provides a MockCommunicator\nagent.communicator.expect_request(...)\n\n# Context manager to start/stop the agent\nasync with harness.running_agent(agent):\n    # Agent is now running\n    # Test interactions here\n</code></pre></p> </li> <li> <p>Multi-Agent Testing: For multiple agents, create separate harnesses for each agent type:    <pre><code>sender_harness = AgentTestHarness(SenderAgent)\nreceiver_harness = AgentTestHarness(ReceiverAgent)\n\nsender = await sender_harness.create_agent(name=\"sender\")\nreceiver = await receiver_harness.create_agent(name=\"receiver\")\n\n# Set up expectations for what sender will send\nsender.communicator.expect_request(...)\n\n# Run both agents in context managers\nasync with sender_harness.running_agent(sender), receiver_harness.running_agent(receiver):\n    # Test interactions\n</code></pre></p> </li> </ol>"},{"location":"contributing/testing_strategy/#common-testing-patterns","title":"Common Testing Patterns","text":"<ol> <li> <p>Testing an agent's outgoing messages: <pre><code># Set up expectation\nagent.communicator.expect_request(\n    target_service=\"service\", method=\"operation\",\n    params={\"key\": \"value\"}, response={\"result\": \"success\"}\n)\n\n# Run the agent logic that should make this call\nawait agent.do_work()\n\n# Verify all expected calls were made\nagent.communicator.verify()\n</code></pre></p> </li> <li> <p>Testing an agent's handler logic: <pre><code># Register handlers (usually happens in agent.setup())\nawait agent.setup()\n\n# Trigger the handler directly\nresponse = await agent.communicator.trigger_handler(\n    method=\"handle_request\",\n    params={\"data\": \"test\"}\n)\n\n# Verify the response\nassert response == {\"status\": \"success\", \"result\": \"processed\"}\n</code></pre></p> </li> <li> <p>Testing agent state after operations: <pre><code># Run some agent logic\nawait agent.process_data(test_input)\n\n# Verify state changes\nassert agent.data_processed == True\nassert len(agent.results) == 1\n</code></pre></p> </li> </ol> <p>For detailed examples and advanced usage, refer to the unit/integration tests in the codebase.</p>"},{"location":"contributing/testing_strategy/#helper-functions-for-common-testing-patterns","title":"Helper Functions for Common Testing Patterns","text":"<p>For common testing scenarios, OpenMAS provides high-level helper functions that significantly reduce boilerplate code:</p> <ol> <li><code>setup_sender_receiver_test()</code>: Creates and configures a sender-receiver test scenario in a single call.</li> </ol> <pre><code># Instead of manually creating two harnesses and agents:\nsender_harness, receiver_harness, sender, receiver = await setup_sender_receiver_test(\n    SenderAgent, ReceiverAgent\n)\n</code></pre> <ol> <li><code>expect_sender_request()</code>: Sets up request expectations with a cleaner interface:</li> </ol> <pre><code># Instead of directly using communicator.expect_request:\nexpect_sender_request(\n    sender,\n    \"receiver\",\n    \"handle_message\",\n    {\"greeting\": \"hello\"},\n    {\"status\": \"received\", \"message\": \"Hello received!\"}\n)\n</code></pre> <ol> <li><code>expect_notification()</code>: Sets up notification expectations with a cleaner interface:</li> </ol> <pre><code>expect_notification(\n    sender,\n    \"logging-service\",\n    \"log_event\",\n    {\"level\": \"info\", \"message\": \"Test completed\"}\n)\n</code></pre> <ol> <li><code>multi_running_agents()</code>: Manages multiple agent lifecycles in a single context manager:</li> </ol> <pre><code># Instead of nested context managers:\nasync with multi_running_agents(sender_harness, sender, receiver_harness, receiver):\n    # Both agents are now running\n    await sender.run()\n</code></pre> <p>When to Use Helpers vs. Direct Approach:</p> <ul> <li>Use helpers for standard test scenarios and when readability is a priority</li> <li>Use direct harness/communicator for tests that need custom configuration, complex state assertions, or non-standard patterns</li> </ul> <p>For examples demonstrating OpenMAS functionality (like those in <code>examples/</code>), the helper functions are generally preferred for clarity and conciseness.</p>"},{"location":"contributing/testing_strategy/#running-tests-via-tox","title":"Running Tests via <code>tox</code>","text":"<p><code>tox</code> is the required way to run tests for contribution, ensuring isolated environments and correct dependencies based on targeted directories. Use <code>poetry run tox ...</code> to ensure tox uses the project's Poetry environment.</p>"},{"location":"contributing/testing_strategy/#local-development-fast-feedback","title":"Local Development (Fast Feedback):","text":"<p>These environments are fast and don't require external services.</p> <ul> <li><code>poetry run tox</code>: Runs the default set: <code>lint</code>, <code>unit</code>, <code>integration-mock</code>.</li> <li><code>poetry run tox -e lint</code>: Run linters, formatters (check mode), and type checker.</li> <li><code>poetry run tox -e unit</code>: Run only unit tests (very fast).</li> <li><code>poetry run tox -e integration-mock</code>: Run core and mocked integration tests.</li> <li><code>poetry run tox -e coverage</code>: Run unit and mock integration tests and generate a coverage report.</li> </ul>"},{"location":"contributing/testing_strategy/#local-development-specific-real-services","title":"Local Development (Specific Real Services):","text":"<p>Run these if you have the corresponding service (e.g., MQTT broker, specific MCP server) running locally and configured.</p> <ul> <li><code>poetry run tox -e integration-real-mcp</code>: Run MCP integration tests against real services/libs.</li> <li><code>poetry run tox -e integration-real-grpc</code>: Run gRPC integration tests against real services/libs.</li> <li><code>poetry run tox -e integration-real-mqtt</code>: Run MQTT integration tests against a real MQTT broker.</li> </ul>"},{"location":"contributing/testing_strategy/#ci-pull-request-checks-fast","title":"CI Pull Request Checks (Fast):","text":"<p>CI should run the fast checks on every pull request:</p> <ul> <li><code>poetry run tox -e lint</code></li> <li><code>poetry run tox -e unit</code></li> <li><code>poetry run tox -e integration-mock</code></li> </ul>"},{"location":"contributing/testing_strategy/#full-ci-runs-eg-on-mergerelease","title":"Full CI Runs (e.g., on Merge/Release):","text":"<p>Full CI runs should execute all environments, including those requiring real services. The CI environment must be configured to provide these services (e.g., start Docker containers).</p> <ul> <li><code>poetry run tox</code> (which includes <code>lint</code>, <code>unit</code>, <code>integration-mock</code>)</li> <li><code>poetry run tox -e integration-real-mcp</code></li> <li><code>poetry run tox -e integration-real-grpc</code></li> <li><code>poetry run tox -e integration-real-mqtt</code></li> <li><code>poetry run tox -e coverage</code></li> <li>All <code>example-*</code> environments.</li> </ul> <p>Important: Running <code>pytest</code> directly is discouraged for final checks as it bypasses the environment setup and dependency management handled by <code>tox</code>, potentially leading to incorrect results or missed/incorrectly skipped tests.</p>"},{"location":"contributing/testing_strategy/#handling-optional-dependencies","title":"Handling Optional Dependencies","text":"<p>OpenMAS handles optional dependencies primarily through:</p> <ol> <li>Directory Structure: Separating tests requiring optional dependencies into specific directories (e.g., <code>integration/mcp/</code>, <code>integration/grpc/</code>).</li> <li>Tox Environments with Extras: Dedicated <code>tox</code> environments (e.g., <code>integration-mock</code>, <code>integration-real-mcp</code>) install the necessary extras (defined in <code>pyproject.toml</code> using <code>poetry install --extras ...</code>) and target the relevant test directories.</li> <li>Pytest <code>skipif</code>: Tests requiring real services (in <code>integration/.../real/</code>) must use <code>pytest.mark.skipif</code> to check for the availability of the service or necessary libraries/configuration, ensuring they are skipped gracefully if the dependencies aren't met.</li> </ol>"},{"location":"contributing/testing_strategy/#mocking-strategy","title":"Mocking Strategy","text":"<ul> <li>Unit tests (<code>tests/unit/</code>): All external dependencies MUST be mocked (<code>pytest-mock</code>).</li> <li>Core integration tests (<code>tests/integration/core/</code>): Typically use mocks for external systems (<code>MockCommunicator</code>, <code>AgentTestHarness</code>).</li> <li>Mocked integration tests (<code>tests/integration/.../mock/</code>): Use the feature's library but mock the actual network/service interaction (e.g., using <code>MockCommunicator</code> or specific mocking utilities like <code>McpTestHarness</code> configured for mocking).</li> <li>Real service integration tests (<code>tests/integration/.../real/</code>): Use the real libraries and attempt to connect to real services (or test harnesses simulating them).</li> <li>Example tests (<code>examples/*/</code>): Run actual example code, potentially against real services depending on the example.</li> </ul>"},{"location":"contributing/testing_strategy/#common-testing-challenges","title":"Common Testing Challenges","text":"<p>Here are some common issues you might encounter when writing tests:</p>"},{"location":"contributing/testing_strategy/#1-cannot-instantiate-abstract-class-x-with-abstract-methods","title":"1. \"Cannot instantiate abstract class X with abstract methods...\"","text":"<p>This means your agent class doesn't implement all required abstract methods from BaseAgent. At minimum, implement: - <code>async def setup(self) -&gt; None</code> - <code>async def run(self) -&gt; None</code> - <code>async def shutdown(self) -&gt; None</code></p>"},{"location":"contributing/testing_strategy/#2-attributeerror-mockcommunicator-object-has-no-attribute-send","title":"2. \"AttributeError: 'MockCommunicator' object has no attribute 'send'\"","text":"<p>The method is named <code>send_request()</code>, not <code>send()</code>. Use:</p> <pre><code>await communicator.send_request(\n    target_service=\"service_name\",\n    method=\"method_name\",\n    params={\"key\": \"value\"}\n)\n</code></pre>"},{"location":"contributing/testing_strategy/#3-unexpected-request-xy-with-params-z-available-requests-none","title":"3. \"Unexpected request: X:Y with params: Z. Available requests: none\"","text":"<p>You need to set up expectations for all requests:</p> <pre><code>communicator.expect_request(\n    target_service=\"X\",\n    method=\"Y\",\n    params={\"key\": \"value\"},\n    response={\"result\": \"success\"}\n)\n</code></pre>"},{"location":"contributing/testing_strategy/#contribution-guide","title":"Contribution Guide","text":"<p>When contributing tests to OpenMAS:</p> <ol> <li>Add unit tests to <code>tests/unit/</code> matching the module structure in <code>src/</code>. Ensure all external dependencies are mocked.</li> <li>Add integration tests for core features (no optional extras) to <code>tests/integration/core/</code>. Use mocks where appropriate.</li> <li>Add integration tests for features requiring optional extras:<ul> <li>If the test mocks the external service interaction, place it in <code>tests/integration/&lt;feature&gt;/mock/</code> (e.g., <code>tests/integration/mcp/mock/</code>). Ensure it runs in the <code>integration-mock</code> tox environment.</li> <li>If the test requires a real service/library interaction, place it in <code>tests/integration/&lt;feature&gt;/real/</code> (e.g., <code>tests/integration/mcp/real/</code>) or <code>tests/integration/&lt;feature&gt;/</code> if no mock/real split exists for that feature. Use <code>skipif</code> appropriately for real service tests. Ensure it runs in the correct <code>integration-real-&lt;feature&gt;</code> tox environment.</li> </ul> </li> <li>Ensure tests run correctly within their designated <code>tox</code> environment(s).</li> <li>Do not rely on <code>pytest</code> markers (<code>@pytest.mark.&lt;feature&gt;</code>) for controlling test execution; rely on the directory structure and <code>tox</code> environments.</li> </ol>"},{"location":"core_concepts/architecture/","title":"OpenMAS Architecture","text":"<p>OpenMAS is designed with a modular and extensible architecture to simplify the creation, deployment, and management of Multi-Agent Systems (MAS). This document outlines the core components and how they interact.</p>"},{"location":"core_concepts/architecture/#core-philosophy-recap","title":"Core Philosophy Recap","text":"<p>Before diving into components, remember the core principles:</p> <ul> <li>Simplicity &amp; Composability: Use simple, understandable building blocks.</li> <li>Modularity &amp; Pluggability: Easily extend with new communication methods, agent patterns, or tools.</li> <li>Separation of Concerns: Isolate agent logic, communication, configuration, and deployment.</li> <li>Agent Reasoning Agnosticism: The framework provides the agent's structure and interaction capabilities, not its internal decision-making logic.</li> <li>Developer Experience: Streamline common tasks with clear conventions and helpful tooling.</li> </ul> <p>(See the full Design Philosophy for more details).</p>"},{"location":"core_concepts/architecture/#high-level-architecture-overview","title":"High-Level Architecture Overview","text":"<p>The architecture revolves around distinct agents running within a defined project structure, leveraging shared communication and configuration mechanisms, and managed by developer-friendly tooling.</p>"},{"location":"core_concepts/architecture/#key-components","title":"Key Components","text":""},{"location":"core_concepts/architecture/#1-baseagent-openmasagentbaseagent","title":"1. <code>BaseAgent</code> (<code>openmas.agent.BaseAgent</code>)","text":"<p>This is the fundamental building block for any active entity within an OpenMAS system. All custom agents inherit from <code>BaseAgent</code>.</p> <ul> <li>Responsibilities:<ul> <li>Manages the agent's lifecycle (<code>setup</code>, <code>run</code>, <code>shutdown</code>).</li> <li>Handles configuration loading (<code>self.config</code>).</li> <li>Instantiates and holds a reference to the agent's communicator (<code>self.communicator</code>).</li> <li>Provides standard utilities like logging (<code>self.logger</code>).</li> <li>Acts as the container for the agent's specific logic and state.</li> </ul> </li> <li>Lifecycle Methods: Defines standard asynchronous methods developers override:<ul> <li><code>async setup()</code>: For initialization, loading resources, registering communication handlers. Called once on start.</li> <li><code>async run()</code>: The main execution logic/loop of the agent. Called after <code>setup()</code> completes.</li> <li><code>async shutdown()</code>: For cleanup (e.g., closing connections, saving state). Called once on graceful stop.</li> </ul> </li> <li>Instantiation: Agents are typically discovered and instantiated by the <code>openmas run</code> command based on the project configuration, or manually in custom scripts.</li> </ul>"},{"location":"core_concepts/architecture/#2-basecommunicator-openmascommunicationbasebasecommunicator","title":"2. <code>BaseCommunicator</code> (<code>openmas.communication.base.BaseCommunicator</code>)","text":"<p>This abstract base class defines the interface for all communication methods, decoupling agent logic from the specifics of network protocols or interaction mechanisms (like MCP).</p> <ul> <li>Responsibilities:<ul> <li>Sending requests to other services/agents and receiving responses (<code>send_request</code>).</li> <li>Sending notifications (fire-and-forget messages) (<code>send_notification</code>).</li> <li>Registering handlers for incoming requests (<code>register_handler</code>).</li> <li>Managing the underlying communication channels (e.g., starting/stopping HTTP servers, managing MCP sessions, connecting to MQTT brokers).</li> </ul> </li> <li>Implementations: OpenMAS provides concrete implementations:<ul> <li><code>HttpCommunicator</code>: Standard request/response over HTTP.</li> <li><code>McpSseCommunicator</code>: Client for interacting with MCP servers via Server-Sent Events.</li> <li><code>McpStdioCommunicator</code>: Client for interacting with MCP servers via standard input/output.</li> <li><code>GrpcCommunicator</code>: Experimental support for gRPC-based communication (v0.1.0).</li> <li><code>MqttCommunicator</code>: Experimental support for MQTT publish/subscribe patterns (v0.1.0).</li> <li>(Extensibility: Developers can add custom communicators.)</li> </ul> </li> <li>Selection &amp; Instantiation: The specific communicator for an agent is determined by its configuration (<code>communicator_type</code> and <code>communicator_options</code> in <code>openmas_project.yml</code> or environment-specific config). <code>BaseAgent</code> automatically instantiates the configured communicator during its initialization.</li> </ul>"},{"location":"core_concepts/architecture/#3-configuration-system-openmasconfig","title":"3. Configuration System (<code>openmas.config</code>)","text":"<p>OpenMAS uses a layered configuration system (powered by Pydantic) to manage settings robustly.</p> <ul> <li>Sources: Loads settings hierarchically from environment variables, <code>.env</code> files, the main project YAML (<code>openmas_project.yml</code>), and environment-specific YAML files (<code>config/*.yml</code>). Later sources override earlier ones.</li> <li>Loading: The <code>load_config()</code> function uses Pydantic models (like <code>AgentConfig</code> or custom subclasses) for validation and type-safe access.</li> <li>Access: Configuration is validated during agent startup and made available within the agent via <code>self.config</code>.</li> </ul> <p>(See the Configuration Guide for details).</p>"},{"location":"core_concepts/architecture/#4-project-structure-conventions","title":"4. Project Structure &amp; Conventions","text":"<p>OpenMAS promotes (but doesn't strictly enforce) a standard project layout to enhance organization and maintainability.</p> <ul> <li><code>agents/</code>: Contains subdirectories for each agent's code.</li> <li><code>config/</code>: Holds environment-specific configuration files (e.g., <code>development.yml</code>, <code>production.yml</code>).</li> <li><code>shared/</code>: Optional directory for code shared between agents within the project.</li> <li><code>extensions/</code>: Optional directory for project-local extensions (e.g., custom communicators).</li> <li><code>packages/</code>: Optional directory for vendored external dependencies.</li> <li><code>openmas_project.yml</code>: The main project definition file, specifying agents, default configurations, etc.</li> <li><code>requirements.txt</code>: Standard Python dependencies.</li> </ul> <p>(See Project Structure for details).</p>"},{"location":"core_concepts/architecture/#5-openmas-cli-openmas-command","title":"5. OpenMAS CLI (<code>openmas</code> command)","text":"<p>Provides command-line tools to streamline the development workflow.</p> <ul> <li><code>openmas init</code>: Initializes a new OpenMAS project structure.</li> <li><code>openmas run</code>: Discovers and runs agents defined in the project configuration.</li> <li><code>openmas validate</code>: Checks configuration files and project structure.</li> <li><code>openmas deps</code>: Manages dependencies specified in <code>packages/</code>.</li> <li><code>openmas generate-dockerfile</code>: Creates Dockerfiles for deploying agents.</li> <li><code>openmas generate-compose</code>: Creates a Docker Compose file for multi-agent deployments.</li> </ul> <p>(See the CLI Documentation for details).</p>"},{"location":"core_concepts/architecture/#how-components-interact","title":"How Components Interact","text":"<ol> <li>Initialization: The <code>openmas run</code> command parses <code>openmas_project.yml</code>, discovers agent code, loads configuration (from files and environment), and instantiates the specified agents.</li> <li>Agent Startup: For each agent, its <code>__init__</code> method is called, which in turn instantiates the configured <code>BaseCommunicator</code>. The agent's <code>start()</code> method is called, executing <code>setup()</code> (where communication handlers are often registered) and then <code>run()</code>.</li> <li>Communication: An agent uses its <code>self.communicator</code> instance (<code>send_request</code> or <code>send_notification</code>) to interact with other agents or external services. The communicator handles the protocol-specific details. Incoming messages are routed by the communicator to handlers registered during <code>setup()</code>.</li> <li>Tool Use (MCP): If using an MCP communicator, an agent can interact with MCP servers (potentially running as separate processes or external services) to discover and invoke tools or access resources, enabling complex capabilities.</li> </ol>"},{"location":"core_concepts/architecture/#positioning-in-the-ai-ecosystem","title":"Positioning in the AI Ecosystem","text":"<p>Understanding where OpenMAS fits relative to other tools can help clarify its purpose:</p> <ul> <li>vs. Low-Level Distributed Frameworks (e.g., Ray):<ul> <li>Ray: Focuses on general-purpose distributed computing, scaling Python/ML tasks using actors and parallel primitives. It's like a powerful engine.</li> <li>OpenMAS: A higher-level application framework specifically for structuring, developing, and deploying Multi-Agent Systems. It provides MAS-specific abstractions (agents, communicators), conventions, and tooling. It's more like the car's chassis and controls designed for the specific task of building MAS. They could be complementary (e.g., an OpenMAS agent using Ray for heavy computation).</li> </ul> </li> <li>vs. LLM Orchestration/Agent Frameworks (e.g., LangChain, CrewAI, AutoGen):<ul> <li>LangChain: A versatile library primarily focused on composing chains and components for LLM applications, including agent patterns and tool use. Highly flexible.</li> <li>CrewAI: Focuses on collaborative agent patterns (\"crews\") with defined roles and tasks.</li> <li>AutoGen: Specializes in orchestrating conversations between multiple agents.</li> <li>OpenMAS: Aims to be a more general MAS framework. While supporting LLM integration, its focus is broader, emphasizing the overall architecture of systems with multiple independent agents, flexible communication protocols (especially MCP), and an integrated development workflow from project initialization to deployment. Its strong stance on MCP offers a distinct path for standardized tool integration.</li> </ul> </li> <li>vs. Tool Protocols (e.g., MCP):<ul> <li>MCP: An open protocol standardizing how AI agents discover and interact with tools/data sources. It defines how communication happens for tool use.</li> <li>OpenMAS: An application framework that implements and utilizes protocols like MCP (alongside others like HTTP, gRPC). It provides the structure (<code>BaseAgent</code>) and mechanisms (<code>McpCommunicator</code>) to easily build agents that can speak MCP and leverage its ecosystem.</li> </ul> </li> </ul> <p>In essence, OpenMAS provides the structured environment and essential services (lifecycle, configuration, communication abstraction, tooling) needed to build, run, and deploy applications composed of multiple interacting agents, with a particular strength in leveraging the standardized MCP for tool integration.</p>"},{"location":"core_concepts/design/","title":"Design Philosophy","text":"<p>OpenMAS is built to enable the rapid development and deployment of robust Multi-Agent Systems (MAS). The design philosophy prioritizes a Pythonic, modular, and transparent environment, reducing complexity and accelerating the MAS development lifecycle.</p>"},{"location":"core_concepts/design/#goals","title":"Goals","text":"<p>The primary goal of the OpenMAS ecosystem is to provide a cohesive Pythonic environment that simplifies the end-to-end lifecycle of MAS development. This means:</p> <ul> <li>Reducing Boilerplate: Offer a lightweight framework to handle common tasks like agent lifecycle management, configuration loading, and communication setup, allowing developers to focus on core agent logic.</li> <li>Promoting Structure: Provide conventions and optional tooling (like the <code>openmas</code> CLI and project templates) to help organize MAS projects, making them more understandable, maintainable, and scalable.</li> <li>Enabling Modularity: Design for easy integration and extension, allowing agents to use various communication protocols and incorporate custom or shared components.</li> <li>Streamlining Development: Offer tools and utilities to simplify common development workflows, including local execution, dependency management (for agent components), and testing.</li> </ul>"},{"location":"core_concepts/design/#core-principles","title":"Core Principles","text":"<p>OpenMAS is architected around several core principles to ensure it is robust, extensible, maintainable, and developer-friendly. These principles guide the design of the framework, the structure of OpenMAS projects, and the developer experience.</p> <ul> <li>Simplicity &amp; Composability: We favor simple, understandable components (like <code>BaseAgent</code> and <code>BaseCommunicator</code>) that serve as building blocks. We aim to avoid complex, opaque abstractions where possible, allowing developers to compose sophisticated systems from these fundamental parts.</li> <li>Transparency: Interactions between components, especially communication, should be as clear as possible to aid understanding, debugging, and system monitoring.</li> <li>Pragmatism: We focus on solving common, practical challenges encountered in MAS development, such as configuration management, communication abstraction, reducing repetitive code, and standardizing project structure, providing tangible benefits to the developer.</li> <li>Protocol Flexibility: While providing robust support for common web protocols (HTTP) and specialized ones like MCP, the communication system is designed to be extensible to other protocols via custom <code>BaseCommunicator</code> implementations, ensuring OpenMAS can adapt to diverse integration needs.</li> <li>Agent Reasoning Agnosticism: The OpenMAS framework provides the agent's \"body\" (its structure, lifecycle, communication capabilities) but does not dictate its \"brain\" (the internal reasoning or decision-making logic). Developers are free to implement simple logic, complex state machines, BDI patterns, or integrate with external reasoning engines (like LLMs), offering maximum flexibility in agent design.</li> </ul>"},{"location":"core_concepts/design/#separation-of-concerns","title":"Separation of Concerns","text":"<p>OpenMAS rigorously distinguishes between the core framework, the developer's application logic, the tools for managing the development lifecycle, and operational deployment. This separation allows developers to focus on their specific tasks at the appropriate level of abstraction, enhancing clarity and maintainability.</p> <ul> <li> <p>1. The OpenMAS Core Framework:</p> <ul> <li>This is the foundational engine providing the core building blocks, extensible abstractions, and runtime environment for multi-agent systems. It acts as the \"backend\" framework that developers build upon.</li> <li>Key Components:<ul> <li>Core abstractions like <code>BaseAgent</code>, <code>BaseCommunicator</code>, <code>BasePromptManager</code>, and <code>BaseSampler</code>.</li> <li>Agent lifecycle management and inter-agent communication mechanisms.</li> <li>Standardized Pydantic-based interfaces (e.g., <code>AgentConfig</code>, <code>PromptConfig</code>, <code>SamplingParams</code>) for configuring framework components.</li> <li>A system of core exceptions for predictable error handling.</li> </ul> </li> <li>Developers primarily interact with this layer by extending its base classes and utilizing its core services within their custom agent logic.</li> </ul> </li> <li> <p>2. Developer's Application Layer (Your OpenMAS Project):</p> <ul> <li>This is where you, the developer, define the unique intelligence, behavior, and composition of your multi-agent system by utilizing and extending the OpenMAS Framework.</li> <li>Project Structure: Follows a standardized Project Layout for organizing:<ul> <li>Custom agent implementations (e.g., in <code>agents/</code>).</li> <li>Shared business logic or data models (e.g., in <code>shared/</code>).</li> <li>Custom framework extensions (e.g., new communicator types in <code>extensions/</code>).</li> </ul> </li> <li>Declarative Configuration (<code>openmas_project.yml</code>): This YAML file is the primary \"developer-facing interface\" for defining and configuring your system. It's where you:<ul> <li>Specify which agents to run, their classes, and initial parameters.</li> <li>Select and configure framework components (e.g., choosing an agent's communicator, defining its prompt templates, setting LLM sampling parameters).</li> <li>Manage project-level settings and dependencies.</li> </ul> </li> <li>This layer allows you to focus on your application's specific domain, declaratively wiring up and customizing framework capabilities like prompting and sampling through the <code>openmas_project.yml</code> file.</li> </ul> </li> <li> <p>3. Developer Experience Tooling (The <code>openmas</code> CLI):</p> <ul> <li>A command-line interface designed to streamline the development workflow and provide an \"operational frontend\" for managing OpenMAS projects.</li> <li>Key Commands:<ul> <li>Project scaffolding (<code>openmas init</code>).</li> <li>Local development runs (<code>openmas run</code>).</li> <li>Configuration and dependency validation (<code>openmas validate</code>, <code>openmas deps</code>).</li> <li>Code/artifact generation (e.g., <code>openmas generate-dockerfile</code>).</li> </ul> </li> <li>The CLI interacts with both the framework (e.g., to validate configurations against defined Pydantic models) and your application structure.</li> <li>See CLI Docs for more details.</li> </ul> </li> <li> <p>4. Operational Deployment:</p> <ul> <li>OpenMAS aims to simplify the path from development to production by enabling the generation of standardized deployment artifacts (e.g., Dockerfiles, Docker Compose files via <code>openmas generate-*</code>).</li> <li>This clearly separates the concerns of application development from the intricacies of operational deployment, promoting best practices and consistency.</li> <li>See the Deployment Guide.</li> </ul> </li> </ul>"},{"location":"core_concepts/design/#modularity-extensibility-and-lazy-loading","title":"Modularity, Extensibility, and Lazy Loading","text":"<p>OpenMAS is fundamentally designed for modularity and extension, ensuring the core system remains lightweight while supporting a rich ecosystem of capabilities.</p> <ul> <li> <p>Pluggable Architecture: Key components, such as communicators, are designed to be pluggable. This allows developers to introduce support for different communication protocols (e.g., HTTP, MCP, gRPC, MQTT) or even entirely new types of framework extensions without altering core agent logic. The architecture facilitates this through project-local extensions (via the <code>extensions/</code> directory) and the ability to integrate shareable external packages (via the <code>packages/</code> directory or standard Python dependencies).</p> </li> <li> <p>Lazy Loading for Efficiency: To maintain a lean core footprint, optional components\u2014especially those with significant external dependencies (like specific communicators such as <code>GrpcCommunicator</code> or <code>MqttCommunicator</code>, or specialized LLM samplers from different providers)\u2014are loaded dynamically using <code>importlib</code> only when explicitly configured and required by an application.</p> <ul> <li>Benefits:<ul> <li>Keeps the core <code>openmas</code> library lean and fast to install.</li> <li>Minimizes unnecessary package installations for users who don't need certain specialized features.</li> <li>Enhances overall extensibility, as new components can be discovered and loaded without requiring modifications to the core framework.</li> </ul> </li> <li>For example, if an agent in <code>openmas_project.yml</code> is configured with <code>communicator: {type: \"mqtt\", ...}</code>, only then will the <code>MqttCommunicator</code> code and its dependencies (like <code>paho-mqtt</code>) be imported and utilized by that agent's process.</li> <li>This principle is crucial for managing dependencies effectively and ensuring that projects only carry the performance and size overhead of the components they actively use.</li> </ul> </li> </ul> <p>See Architecture Overview and Communication Guide for further details on these architectural aspects.</p>"},{"location":"core_concepts/design/#inspiration-vision","title":"Inspiration &amp; Vision","text":"<p>The creation of OpenMAS was driven by the desire to democratize the development of sophisticated agentic solutions. We observed the increasing power of agent-based systems but also the significant engineering effort often required to build them effectively.</p> <p>Key inspirations include:</p> <ol> <li>The Power of Agentic Tools: Witnessing the capabilities of modern tools like Cursor IDE, where advanced LLMs (e.g., Claude, Gemini) work behind the scenes as agents to perform complex tasks like code generation, editing, and command execution, highlighted the potential for specialized, capable agents. OpenMAS aims to provide the foundation for building such powerful, task-specific agents more easily.</li> <li>Addressing Practical Challenges: Our own experience building <code>Chesspal.ai</code> \u2013 an agent designed for chess playing with personality and competence \u2013 revealed the challenges and repetitive nature of implementing complex agent behaviors, communication, and lifecycle management from scratch. This underscored the need for a reusable framework to handle these common infrastructure concerns.</li> <li>Enabling an Ecosystem via MCP: The emergence of the Model Context Protocol (MCP) presents a significant opportunity. OpenMAS is designed with MCP integration in mind, envisioning a future where a vast ecosystem of community-built MCP servers, each offering unique capabilities (like specific tools, data access, or reasoning modules), can be easily packaged and integrated into OpenMAS agents. This allows developers to rapidly assemble agents with diverse skills by leveraging community contributions.</li> <li>Developer Productivity Frameworks: We also draw inspiration from successful developer tools in other domains which enhance productivity and project maintainability through clear structure, configuration management, and command-line workflows. OpenMAS adopts similar principles to streamline the MAS development process.</li> </ol> <p>Ultimately, OpenMAS aims to provide the building blocks and structure necessary for developers to readily create, combine, and deploy powerful and diverse agentic systems.</p>"},{"location":"core_concepts/project_structure/","title":"OpenMAS Project Structure","text":"<p>OpenMAS promotes a standardized project structure to enhance organization, maintainability, and collaboration in Multi-Agent System (MAS) development. This structure is automatically generated when you use the <code>openmas init</code> command.</p>"},{"location":"core_concepts/project_structure/#standard-directory-layout","title":"Standard Directory Layout","text":"<p>A typical OpenMAS project, initialized via <code>openmas init your_mas_project_name</code>, looks like this:</p> <pre><code>your_mas_project_name/\n\u251c\u2500\u2500 agents/              # Code for individual agents/components\n\u2502   \u251c\u2500\u2500 &lt;agent_name_1&gt;/\n\u2502   \u2502   \u251c\u2500\u2500 agent.py          # BaseAgent subclass implementation\n\u2502   \u2502   \u251c\u2500\u2500 requirements.txt  # Optional: Agent-specific deps (rarely needed)\n\u2502   \u2502   \u2514\u2500\u2500 openmas.deploy.yaml # Optional: Deployment hints for this agent\n\u2502   \u2514\u2500\u2500 &lt;agent_name_2&gt;/\n\u2502       \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 extensions/          # Project-local OpenMAS extensions\n\u2502   \u2514\u2500\u2500 my_custom_comm/\n\u2502       \u2514\u2500\u2500 communicator.py   # Example: Custom BaseCommunicator subclass\n\u251c\u2500\u2500 shared/              # Project-internal shared Python code\n\u2502   \u2514\u2500\u2500 utils.py           # Example: Utility functions used by multiple agents\n\u251c\u2500\u2500 packages/            # Installed external OpenMAS packages (Git ignored)\n\u2502   \u2514\u2500\u2500 openmas_kafka/     # Example: Content of an installed package\n\u251c\u2500\u2500 config/              # Environment-specific config files\n\u2502   \u251c\u2500\u2500 default.yml        # Base configuration\n\u2502   \u2514\u2500\u2500 production.yml     # Example: Production environment overrides\n\u251c\u2500\u2500 tests/               # Project/Application-level tests\n\u2502   \u2514\u2500\u2500 test_integration.py\n\u251c\u2500\u2500 .env                 # Optional: Local environment variables (Git ignored)\n\u251c\u2500\u2500 .gitignore           # Standard git ignore file\n\u251c\u2500\u2500 openmas_project.yml  # Central project configuration (Required)\n\u251c\u2500\u2500 requirements.txt     # Top-level Python dependencies (incl. openmas framework)\n\u2514\u2500\u2500 README.md            # Project description\n</code></pre>"},{"location":"core_concepts/project_structure/#core-directory-roles","title":"Core Directory Roles","text":"<ul> <li> <p><code>agents/</code>:</p> <ul> <li>Purpose: Contains the primary logic for each distinct agent or component in the MAS. Each subdirectory typically represents one runnable agent instance.</li> <li>Contents: Inside each <code>&lt;agent_name&gt;/</code> directory, the key file is <code>agent.py</code>, which must contain a class inheriting from <code>openmas.agent.BaseAgent</code>. It might also contain helper modules specific to that agent, optional agent-specific Python dependencies (<code>requirements.txt</code>, though uncommon), and an optional <code>openmas.deploy.yaml</code> for deployment hints.</li> <li>Registration: Agents defined here must be registered in the <code>agents:</code> section of <code>openmas_project.yml</code> to be recognized by the <code>openmas run</code> command.</li> </ul> </li> <li> <p><code>extensions/</code> (Local Extensions):</p> <ul> <li>Purpose: Holds project-specific Python code that extends or customizes the OpenMAS framework locally within this project. This is the place for custom <code>BaseCommunicator</code> subclasses, specialized <code>BaseAgent</code> types tailored to this project, reusable patterns specific to this MAS, or utility functions tightly coupled to the framework's extension points used only in this project.</li> <li>Nature: Code written directly within this project, not intended for easy sharing across different MAS projects without copying.</li> <li>Discovery: The framework finds code here based on the directories listed in <code>extension_paths</code> in <code>openmas_project.yml</code>. These paths are added to <code>sys.path</code> during execution (e.g., by <code>openmas run</code>), making modules within importable. Framework mechanisms (like communicator lookup) search within these paths.</li> </ul> </li> <li> <p><code>shared/</code>:</p> <ul> <li>Purpose: Contains general-purpose Python code (utility functions, data models/schemas defined with Pydantic, constants, business logic helpers) that needs to be shared between multiple local components within the same project. For instance, code used by several agents in the <code>agents/</code> directory or by code within <code>extensions/</code>.</li> <li>Nature: Project-internal library code. Not directly extending the framework, but providing common functionality for the application's components.</li> <li>Discovery: The framework finds code here based on the directories listed in <code>shared_paths</code> in <code>openmas_project.yml</code>. These paths are added to <code>sys.path</code> during execution, allowing agents and extensions to import modules from <code>shared/</code>.</li> </ul> </li> <li> <p><code>packages/</code> (External Packages):</p> <ul> <li>Purpose: Contains reusable OpenMAS components (communicators, agents, patterns) developed externally and installed into the project as dependencies. This directory is managed by the <code>openmas deps</code> command based on the <code>dependencies:</code> section in <code>openmas_project.yml</code>.</li> <li>Nature: Shareable, often versioned code fetched from external sources (currently Git repositories. Planned: local paths and the OpenMAS package hub). This directory should typically be added to <code>.gitignore</code>, as dependencies should be fetched declaratively via <code>openmas deps</code>.</li> <li>Discovery: The framework searches within the installed package directories (specifically configured subdirectories within it, often <code>src/</code> or the root) for components (e.g., communicators defined via entry points or convention) and adds relevant paths to <code>sys.path</code>.</li> </ul> </li> <li> <p><code>config/</code>:</p> <ul> <li>Purpose: Stores environment-specific configuration files (YAML format). See the Configuration Guide.</li> <li>Contents: Typically includes <code>default.yml</code> (base configuration) and files for different environments like <code>local.yml</code>, <code>development.yml</code>, <code>production.yml</code>.</li> </ul> </li> <li> <p><code>tests/</code>:</p> <ul> <li>Purpose: Contains project-level tests (unit, integration) for your agents and shared code. These are distinct from the internal tests used for developing the OpenMAS framework itself.</li> </ul> </li> </ul>"},{"location":"core_concepts/project_structure/#central-configuration-openmas_projectyml","title":"Central Configuration (<code>openmas_project.yml</code>)","text":"<p>This required YAML file resides at the project root and defines the overall structure and metadata for your OpenMAS project.</p> <pre><code># Example openmas_project.yml\nname: \"my_mas_project\"        # Project name (used by CLI, logging)\nversion: \"0.1.0\"              # Project version\n\n# Defines the agents in the system and their locations\nagents:\n    orchestrator: \"agents/orchestrator\" # Maps logical name 'orchestrator' to its code path\n    data_fetcher: \"agents/fetcher\"\n    analyzer: \"agents/analyzer\"\n\n# List of directories containing shared Python code used by agents/extensions\nshared_paths:\n    - \"shared/utils\"\n    - \"shared/models\"\n\n# List of directories containing project-local framework extensions\nextension_paths:\n    - \"extensions\"\n\n# Defines external OpenMAS package dependencies (managed by `openmas deps`)\ndependencies:\n    - git: https://github.com/some_org/openmas-kafka-comm.git\n    revision: v1.2.0 # Can be a tag, branch, or commit hash\n    # - package: vendor/some-pattern # Future: PyPI-like packages\n    #   version: \"&gt;=1.0,&lt;2.0\"\n    # - local: ../shared-openmas-components # Future: Local path dependencies\n\n# Default configuration values (lowest precedence)\ndefault_config:\n    log_level: \"INFO\"\n    communicator_type: \"http\"\n    communicator_options:\n    timeout: 30\n    # Other default parameters accessible via agent.config\n    default_retry_attempts: 3\n</code></pre> <p>Key Sections:</p> <ul> <li><code>name</code>: The name of your MAS project.</li> <li><code>version</code>: The version of your project.</li> <li><code>agents</code>: A mapping where keys are the logical names used to refer to agents (e.g., in <code>openmas run orchestrator</code> or in <code>service_urls</code>) and values are the relative paths to the agent's code directory from the project root. For example:   <pre><code>agents:\n  orchestrator: \"agents/orchestrator\"\n  data_fetcher: \"agents/fetcher\"\n  analyzer: \"agents/analyzer\"\n</code></pre>   Note: While the path-based format is recommended for simplicity, OpenMAS also supports a more explicit dictionary format (e.g., <code>agent_name: {module: 'path.to.module', class: 'ClassName'}</code>). This can be useful in advanced scenarios, such as when an agent's main class is not named <code>Agent</code> or is not located within an <code>agent.py</code> file inside the specified directory. Example:   <pre><code>agents:\n  custom_agent:\n    module: \"agents.custom_path.custom_module\"\n    class: \"CustomAgentClass\"\n</code></pre></li> <li><code>shared_paths</code>: A list of relative paths (from the project root) to directories containing shared Python modules accessible by agents and extensions.</li> <li><code>extension_paths</code>: A list of relative paths to directories containing project-local framework extensions (like custom communicators or base agents).</li> <li><code>dependencies</code>: A list defining external OpenMAS package dependencies. Currently supports <code>git</code> dependencies with an optional <code>revision</code>. Used by the <code>openmas deps</code> command to populate the <code>packages/</code> directory.</li> <li><code>default_config</code>: A dictionary containing default configuration parameters that apply to all agents in the project. These have the lowest precedence in the configuration layering. See Configuration Guide.</li> </ul>"},{"location":"core_concepts/project_structure/#how-components-interact","title":"How Components Interact","text":"<p>When a command like <code>openmas run &lt;agent_name&gt;</code> executes:</p> <ol> <li>It finds the project root and parses <code>openmas_project.yml</code>.</li> <li>It identifies the target agent's path from the <code>agents:</code> section.</li> <li>It determines the paths from <code>shared_paths</code> and <code>extension_paths</code>.</li> <li>It identifies installed packages in the <code>packages/</code> directory (based on <code>dependencies:</code> metadata).</li> <li>It constructs the Python <code>sys.path</code> to include the agent's directory, shared paths, extension paths, and relevant paths within installed packages.</li> <li>It loads the agent code (<code>agent.py</code>), which can now successfully <code>import</code> modules from <code>shared/</code>, <code>extensions/</code>, and installed <code>packages/</code>.</li> <li>Framework mechanisms, like the communicator lookup based on <code>communicator_type</code>, search across built-in components, then <code>extension_paths</code>, then installed <code>packages/</code>.</li> </ol> <p>The <code>openmas_project.yml</code> serves as the root-level configuration file that defines the project structure, agent entry points, dependencies, and the primary reference in the configuration layering. See Configuration Guide.</p>"},{"location":"guides/asset_management/","title":"Asset Management in OpenMAS","text":"<p>OpenMAS provides a robust Asset Management system to help developers manage, download, verify, and access external assets required by their agents. This guide explains how to configure and use this feature.</p>"},{"location":"guides/asset_management/#overview","title":"Overview","text":"<p>The Asset Management feature allows you to:</p> <ul> <li>Declaratively define external assets required by your agents in your project configuration</li> <li>Automatically download and cache assets as needed</li> <li>Verify asset integrity with checksums</li> <li>Support various source types: HTTP, Hugging Face Hub, and local files</li> <li>Secure access to gated resources with authentication</li> <li>Configure download retries, progress reporting, and archive unpacking</li> <li>Access assets programmatically from your agents</li> </ul>"},{"location":"guides/asset_management/#configuring-assets","title":"Configuring Assets","text":"<p>Assets are defined in your <code>openmas_project.yml</code> file in two main sections:</p> <ol> <li>The global <code>assets</code> list defines all assets available to your project</li> <li>Each agent's <code>required_assets</code> list specifies which assets that agent needs</li> </ol>"},{"location":"guides/asset_management/#global-assets-configuration","title":"Global Assets Configuration","text":"<pre><code># openmas_project.yml\nname: \"my_project\"\nversion: \"0.1.0\"\n\n# Define all assets used in the project\nassets:\n  - name: \"llama3-8b\"\n    version: \"1.0\"\n    asset_type: \"model\"\n    description: \"Llama 3 8B model weights\"\n    source:\n      type: \"hf\"\n      repo_id: \"meta-llama/Llama-3-8B\"\n      filename: \"model.safetensors\"\n      revision: \"main\"\n    checksum: \"sha256:a1b2c3d4e5f6...\"\n    # Authentication for gated models\n    authentication:\n      strategy: \"env_token\"\n      hf:\n        token_env_var: \"HUGGING_FACE_HUB_TOKEN\"\n    # Download retry configuration\n    retries: 3\n    retry_delay_seconds: 10\n    # Progress reporting\n    progress_report: true\n\n  - name: \"prompt-templates\"\n    version: \"latest\"\n    asset_type: \"template\"\n    description: \"Collection of prompt templates\"\n    source:\n      type: \"http\"\n      url: \"https://example.com/assets/prompt-templates.zip\"\n    checksum: \"sha256:f6e5d4c3b2a1...\"\n    # Unpacking configuration\n    unpack: true\n    unpack_format: \"zip\"\n    # Authentication for HTTP\n    authentication:\n      strategy: \"env_token\"\n      http:\n        token_env_var: \"MY_API_KEY\"\n        scheme: \"Bearer\"\n        header_name: \"Authorization\"\n    # Progress reporting\n    progress_report: true\n    progress_report_interval_mb: 10\n\n  - name: \"knowledge-index\"\n    version: \"2023-06\"\n    asset_type: \"index\"\n    description: \"Vector index of knowledge base\"\n    source:\n      type: \"local\"\n      path: \"/opt/shared-assets/knowledge-index.bin\"\n    checksum: \"sha256:1a2b3c4d5e6f...\"\n\n# Settings for asset management\nsettings:\n  assets:\n    cache_dir: \"/app/data/asset-cache\"  # Optional, defaults to ~/.openmas/assets/\n</code></pre>"},{"location":"guides/asset_management/#agent-asset-requirements","title":"Agent Asset Requirements","text":"<pre><code># openmas_project.yml (continued)\nagents:\n  rag_agent:\n    module: \"agents.rag_agent\"\n    class: \"RAGAgent\"\n    required_assets:\n      - \"llama3-8b\"\n      - \"knowledge-index\"\n\n  template_agent:\n    module: \"agents.template_agent\"\n    class: \"TemplateAgent\"\n    required_assets:\n      - \"prompt-templates\"\n</code></pre>"},{"location":"guides/asset_management/#asset-configuration-options","title":"Asset Configuration Options","text":""},{"location":"guides/asset_management/#asset-configuration","title":"Asset Configuration","text":"Field Type Description Required <code>name</code> string Unique name for the asset Yes <code>version</code> string Asset version No (defaults to \"latest\") <code>asset_type</code> string Type of asset (e.g., \"model\", \"data\", \"template\") No (defaults to \"model\") <code>source</code> object Source configuration (see below) Yes <code>checksum</code> string SHA256 checksum for verification (format: \"sha256:\") No <code>unpack</code> boolean Whether to unpack an archive file No (defaults to false) <code>unpack_format</code> string Archive format (\"zip\", \"tar\", \"tar.gz\", \"tar.bz2\") Yes if <code>unpack</code> is true <code>unpack_destination_is_file</code> boolean If true and unpack is set, the unpacked content is expected to be a single file, and the path returned will be to this file directly No (defaults to false) <code>description</code> string Human-readable description No <code>authentication</code> object Authentication configuration (see below) No <code>retries</code> integer Number of times to retry download on failure No (defaults to 0) <code>retry_delay_seconds</code> float Seconds to wait between retries No (defaults to 5.0) <code>progress_report</code> boolean Enable progress reporting for this asset during download No (defaults to true) <code>progress_report_interval_mb</code> float For HttpDownloader, report progress approximately every X MB downloaded No (defaults to 5.0)"},{"location":"guides/asset_management/#authentication-configuration","title":"Authentication Configuration","text":"<p>The <code>authentication</code> field allows you to configure secure access to gated assets:</p> <pre><code>authentication:\n  strategy: \"env_token\"  # Currently the only supported strategy\n\n  # For Hugging Face Hub assets:\n  hf:\n    token_env_var: \"HUGGING_FACE_HUB_TOKEN\"  # Name of env var containing the token\n\n  # For HTTP/HTTPS assets:\n  http:\n    token_env_var: \"MY_API_KEY\"  # Name of env var containing the token\n    scheme: \"Bearer\"             # Auth scheme (e.g., \"Bearer\", \"Token\", \"Basic\", or \"\" for none)\n    header_name: \"Authorization\" # HTTP header name (e.g., \"Authorization\", \"X-API-Key\")\n</code></pre> <p>The <code>token_env_var</code> specifies which environment variable contains the actual authentication token. This approach keeps sensitive tokens out of your configuration files and allows different developers or environments to use different tokens without changing the configuration.</p> <p>For Hugging Face Hub, the default environment variable is <code>HUGGING_FACE_HUB_TOKEN</code> if no <code>hf</code> block is provided.</p>"},{"location":"guides/asset_management/#source-configurations","title":"Source Configurations","text":""},{"location":"guides/asset_management/#http-source","title":"HTTP Source","text":"<pre><code>source:\n  type: \"http\"\n  url: \"https://example.com/path/to/asset.file\"\n</code></pre>"},{"location":"guides/asset_management/#hugging-face-hub-source","title":"Hugging Face Hub Source","text":"<pre><code>source:\n  type: \"hf\"\n  repo_id: \"organization/model-name\"\n  filename: \"model.safetensors\"  # File within the repo\n  revision: \"main\"  # Optional: branch, tag, or commit hash\n</code></pre>"},{"location":"guides/asset_management/#local-file-source","title":"Local File Source","text":"<pre><code>source:\n  type: \"local\"\n  path: \"/path/to/local/file.bin\"  # Absolute path or relative to project root\n</code></pre>"},{"location":"guides/asset_management/#download-progress-reporting","title":"Download Progress Reporting","text":"<p>OpenMAS provides flexible progress reporting during asset downloads:</p> <ol> <li>HTTP Downloads: Shows progress in two ways:</li> <li>In terminal environments: Uses tqdm progress bars for a rich interactive experience</li> <li> <p>In non-terminal environments: Logs progress at regular intervals (configurable with <code>progress_report_interval_mb</code>)</p> </li> <li> <p>Hugging Face Downloads: Uses Hugging Face's native progress display system</p> </li> <li>Can be disabled by setting <code>progress_report: false</code></li> </ol> <p>Configure progress reporting in your asset configuration:</p> <pre><code>assets:\n  - name: \"large-model\"\n    # ... other config ...\n    progress_report: true                 # Enable/disable progress reporting\n    progress_report_interval_mb: 10.0     # Report every 10 MB (for HTTP sources)\n</code></pre>"},{"location":"guides/asset_management/#retry-mechanism","title":"Retry Mechanism","text":"<p>For handling transient network issues or temporary server errors, configure download retries:</p> <pre><code>assets:\n  - name: \"large-model\"\n    # ... other config ...\n    retries: 3                 # Number of retry attempts after initial download failure\n    retry_delay_seconds: 10.0  # Seconds to wait between retry attempts\n</code></pre> <p>The asset manager will: 1. Attempt the download 2. If it fails, wait for the specified delay 3. Retry up to the specified number of times 4. Report detailed error information if all attempts fail</p>"},{"location":"guides/asset_management/#asset-cache","title":"Asset Cache","text":"<p>By default, assets are cached in <code>~/.openmas/assets/</code>. This location follows this structure:</p> <pre><code>~/.openmas/assets/\n  \u251c\u2500\u2500 model/                         # asset_type\n  \u2502   \u2514\u2500\u2500 llama3-8b/                 # asset name\n  \u2502       \u2514\u2500\u2500 1.0/                   # asset version\n  \u2502           \u251c\u2500\u2500 model.safetensors  # the actual asset\n  \u2502           \u2514\u2500\u2500 .asset_info.json   # metadata\n  \u2514\u2500\u2500 .locks/                        # lock files for concurrent access\n</code></pre> <p>You can override the cache location in three ways (in order of precedence):</p> <ol> <li>Environment variable: <code>OPENMAS_ASSETS_DIR=/path/to/cache</code></li> <li>Project config: <code>settings.assets.cache_dir: \"/path/to/cache\"</code> in <code>openmas_project.yml</code></li> <li>Default: <code>~/.openmas/assets/</code></li> </ol>"},{"location":"guides/asset_management/#using-assets-in-agents","title":"Using Assets in Agents","text":"<p>Agents can access their configured assets programmatically using the <code>asset_manager</code> provided by OpenMAS:</p> <pre><code>from openmas.agent import BaseAgent\nfrom pathlib import Path\n\nclass MyAgent(BaseAgent):\n    async def setup(self):\n        # Get path to a required asset\n        model_path: Path = await self.asset_manager.get_asset_path(\"llama3-8b\")\n        self.model = load_model(model_path)\n\n        # Force re-download an asset if needed\n        model_path = await self.asset_manager.get_asset_path(\"llama3-8b\", force_download=True)\n\n        # The asset_manager handles:\n        # - Checking if the asset exists in cache\n        # - Downloading if needed (with locking for concurrent access)\n        # - Verifying integrity via checksum\n        # - Unpacking archives if configured\n        # - Implementing retries and progress reporting\n        # - Managing authentication for gated assets\n        # - Returning the final path\n</code></pre> <p>The <code>get_asset_path()</code> method is asynchronous and will:</p> <ol> <li>Look up the asset configuration by name</li> <li>Check if it exists in the cache and is valid</li> <li>Download it if necessary (with proper locking to prevent race conditions)</li> <li>Verify its checksum (if provided)</li> <li>Unpack it (if configured)</li> <li>Return the path to the asset</li> </ol>"},{"location":"guides/asset_management/#cli-commands","title":"CLI Commands","text":"<p>OpenMAS provides CLI commands to manage assets:</p> <pre><code># List all configured assets and their status\nopenmas assets list\n\n# Download a specific asset\nopenmas assets download llama3-8b\nopenmas assets download llama3-8b --force  # Force re-download even if cached\n\n# Verify asset integrity\nopenmas assets verify llama3-8b\nopenmas assets verify  # Verify all cached assets\n\n# Clear asset cache\nopenmas assets clear-cache --asset llama3-8b  # Clear specific asset\nopenmas assets clear-cache --all  # Clear entire cache (with confirmation)\n</code></pre> <p>See the Assets CLI documentation for more details.</p>"},{"location":"guides/asset_management/#concurrency-and-locking","title":"Concurrency and Locking","text":"<p>OpenMAS uses file-based locking to ensure that multiple processes can safely access the asset cache without conflicts. This is particularly important when:</p> <ul> <li>Multiple agents request the same asset simultaneously</li> <li>Multiple instances of the same agent are running across different processes</li> <li>Assets are being downloaded while others are trying to use them</li> </ul> <p>The locking system is transparent to the agent code and is handled automatically by the asset manager.</p>"},{"location":"guides/asset_management/#handling-secrets-for-asset-authentication","title":"Handling Secrets for Asset Authentication","text":"<p>For assets that require authentication (like gated Hugging Face models), use environment variables to store tokens:</p> <ol> <li> <p>Add your tokens to your <code>.env</code> file (which is automatically loaded by OpenMAS):    <pre><code>HUGGING_FACE_HUB_TOKEN=hf_abcdefghijklmnopqrstuvwxyz\nMY_CUSTOM_API_KEY=api_123456789abcdef\n</code></pre></p> </li> <li> <p>Reference these environment variables in your asset configuration:    <pre><code>authentication:\n  strategy: \"env_token\"\n  hf:\n    token_env_var: \"HUGGING_FACE_HUB_TOKEN\"\n</code></pre></p> </li> <li> <p>Make sure to include <code>.env</code> in your <code>.gitignore</code> to avoid committing sensitive tokens.</p> </li> </ol> <p>The asset downloader will automatically use the appropriate token from your environment when accessing protected resources.</p>"},{"location":"guides/asset_management/#best-practices","title":"Best Practices","text":"<ul> <li>Always provide checksums for important assets to ensure integrity</li> <li>Configure appropriate retries for large files or unreliable networks</li> <li>Use authentication blocks for gated resources</li> <li>Enable progress reporting for large downloads</li> <li>Consider unpacking large archives directly in the cache to avoid duplicating storage</li> <li>Use version tags for assets to manage updates and ensure reproducibility</li> <li>Add <code>.env</code> to your `.gitignore to prevent exposing secrets</li> <li>Set appropriate cache locations based on your deployment environment:</li> <li>Development: Use default or local directory</li> <li>Docker: Mount a volume for the cache to persist between container restarts</li> <li>Production: Consider a shared network volume for clusters</li> </ul>"},{"location":"guides/configuration/","title":"OpenMAS Configuration System","text":"<p>OpenMAS provides a flexible configuration system that supports layered configuration from multiple sources. This guide explains how the configuration system works, the precedence of different configuration sources, and how to use it in your projects.</p>"},{"location":"guides/configuration/#configuration-sources-and-precedence","title":"Configuration Sources and Precedence","text":"<p>OpenMAS loads configuration from multiple sources in the following order (from lowest to highest precedence):</p> <ol> <li>SDK Internal Defaults: Default values defined in the Pydantic models (e.g., <code>AgentConfig</code>).</li> <li>Project Configuration (<code>openmas_project.yml</code>): Values in the <code>default_config</code> section of the project configuration file.</li> <li>Default Configuration File (<code>config/default.yml</code>): Settings shared by all environments.</li> <li>Environment-Specific Configuration (<code>config/&lt;OPENMAS_ENV&gt;.yml</code>): Settings specific to the current environment.</li> <li>Environment Variables in <code>.env</code>: Variables loaded from the <code>.env</code> file in your project root.</li> <li>Environment Variables: The highest precedence, overriding all other sources.</li> </ol> <p>This layered approach allows you to define sane defaults, environment-specific configurations, and easily override settings for testing or deployment without modifying code.</p>"},{"location":"guides/configuration/#automatic-env-file-loading","title":"Automatic .env File Loading","text":"<p>OpenMAS automatically detects and loads environment variables from a <code>.env</code> file located in your project root whenever any OpenMAS CLI command is executed. This provides a convenient way to manage project-specific secrets and configurations without polluting your global shell environment.</p> <p>Example <code>.env</code> file:</p> <pre><code># API Keys\nHUGGING_FACE_HUB_TOKEN=hf_abcdefghijklmnopqrstuvwxyz\nMY_CUSTOM_SERVICE_API_KEY=sk-1234567890abcdef\n\n# Configuration overrides\nLOG_LEVEL=DEBUG\nSERVICE_URL_VISION=http://localhost:8001\n</code></pre> <p>Benefits of using a <code>.env</code> file: - Keeps sensitive values out of your codebase and shell history - Makes it easy to switch between different configurations - Provides a standard location for environment variables - Works seamlessly with the rest of the OpenMAS configuration system</p> <p>Best practices: - Add <code>.env</code> to your <code>.gitignore</code> to prevent accidentally committing secrets - Create a <code>.env.example</code> file with dummy values as a template for other developers - Use <code>.env</code> for development and test environments, but prefer proper environment variables or secrets management in production</p> <p>For compatibility with containerized environments, you can still use standard environment variables which will take precedence over values in the <code>.env</code> file.</p>"},{"location":"guides/configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"guides/configuration/#project-configuration-openmas_projectyml","title":"Project Configuration (<code>openmas_project.yml</code>)","text":"<p>The central project configuration file, located at the root of your project:</p> <pre><code>name: \"my_mas_project\"\nversion: \"0.1.0\"\nagents:\n  orchestrator: \"agents/orchestrator\"\n  worker: \"agents/worker\"\n# Define paths for code shared between agents in this project\nshared_paths:\n  - \"shared\"\n# Define paths for project-local framework extensions (e.g., custom communicators)\nextension_paths:\n  - \"extensions\"\n# Define assets required by agents\nassets:\n  - name: \"llama3-8b\"\n    version: \"1.0\"\n    source:\n      type: \"hf\"\n      repo_id: \"meta-llama/Llama-3-8B\"\n      filename: \"model.safetensors\"\n    checksum: \"sha256:a1b2c3d4e5f6...\"\ndefault_config:\n  log_level: \"INFO\"\n  communicator_type: \"http\"\n  communicator_options:\n    timeout: 30\n</code></pre> <p>The <code>default_config</code> section provides base configuration values for all agents in the project. The <code>shared_paths</code> and <code>extension_paths</code> sections define locations where OpenMAS will look for project-specific shared code or framework extensions (like custom communicators).</p> <p>The <code>assets</code> section defines external resources that your agents might need. See the Asset Management guide for details on configuring and using assets.</p>"},{"location":"guides/configuration/#agent-configuration-with-prompts-sampling-and-assets","title":"Agent Configuration with Prompts, Sampling, and Assets","text":"<p>OpenMAS supports defining prompts, sampling parameters, and required assets directly in the agent configuration. These configurations can be specified in the <code>openmas_project.yml</code> file:</p> <pre><code>agents:\n  llm_analyst:\n    module: \"agents.llm_analyst\"\n    class: \"LlmAnalystAgent\"\n    # Define prompts for the agent\n    prompts_dir: \"prompts\"  # Directory relative to project root\n    prompts:\n      - name: \"summarize_text\"\n        template_file: \"summarize.txt\"  # File in prompts_dir\n        input_variables: [\"text_to_summarize\"]\n      - name: \"generate_greeting\"\n        template: \"Hello, {{user_name}}! Welcome to {{service}}.\"\n        input_variables: [\"user_name\", \"service\"]\n    # Define sampling parameters\n    sampling:\n      provider: \"mcp\"       # \"mcp\", \"mock\", or others supported\n      model: \"claude-3-opus-20240229\"  # model identifier\n      temperature: 0.7      # Controls randomness (0.0-1.0)\n      max_tokens: 2000      # Maximum tokens in completion\n      top_p: 0.9            # Nucleus sampling parameter\n    # Define required assets\n    required_assets:\n      - \"llama3-8b\"         # References an asset defined in the global assets list\n</code></pre>"},{"location":"guides/configuration/#prompt-configuration","title":"Prompt Configuration","text":"<p>The <code>prompts</code> field is a list of prompt configurations with these properties:</p> Property Description Required <code>name</code> Unique name for the prompt Yes <code>template</code> Inline template with variables in Handlebars syntax (<code>{{variable}}</code>) One of <code>template</code> or <code>template_file</code> required <code>template_file</code> Path to template file (relative to <code>prompts_dir</code>) One of <code>template</code> or <code>template_file</code> required <code>input_variables</code> List of variable names used in the template No, but recommended for validation <p>The <code>prompts_dir</code> field specifies the directory where template files are stored, relative to the project root. It defaults to <code>prompts</code> if not specified.</p>"},{"location":"guides/configuration/#sampling-configuration","title":"Sampling Configuration","text":"<p>The <code>sampling</code> field configures how the agent samples from language models:</p> Property Description Default <code>provider</code> Sampling provider (e.g., \"mcp\", \"mock\") None <code>model</code> Model name/identifier to use for sampling None <code>temperature</code> Controls randomness (0.0-1.0) 0.7 <code>max_tokens</code> Maximum tokens to generate None <code>top_p</code> Nucleus sampling parameter (0.0-1.0) None <code>top_k</code> Top-k sampling parameter None <code>stop_sequences</code> List of strings that stop generation None <code>frequency_penalty</code> Penalizes repeated tokens None <code>presence_penalty</code> Penalizes repeated topics None <code>seed</code> Seed for random sampling None <p>When using the <code>\"mcp\"</code> provider, the MCP communication protocol will be used to interact with language models. This requires an appropriate MCP communicator configuration.</p>"},{"location":"guides/configuration/#environment-configuration-files","title":"Environment Configuration Files","text":"<p>OpenMAS looks for YAML configuration files in the <code>config/</code> directory of your project:</p> <ol> <li>Default Configuration (<code>config/default.yml</code>): Shared settings for all environments:</li> </ol> <pre><code># config/default.yml\nlog_level: \"INFO\"\ncommunicator_type: \"http\"\nservice_urls:\n  chess-engine: \"http://chess-engine:8000\"\n  vision: \"http://vision-service:8001\"\ncommunicator_options:\n  timeout: 30\n  retries: 3\n</code></pre> <ol> <li>Environment-Specific Configuration (<code>config/&lt;env&gt;.yml</code>): Settings for specific environments (development, staging, production):</li> </ol> <pre><code># config/production.yml\nlog_level: \"WARNING\"\nservice_urls:\n  chess-engine: \"http://prod-chess-engine.internal:8000\"\n  vision: \"http://prod-vision.internal:8001\"\ncommunicator_options:\n  timeout: 60\n</code></pre> <p>To use environment-specific configuration, set the <code>OPENMAS_ENV</code> environment variable (defaults to <code>local</code> if not set):</p> <pre><code>export OPENMAS_ENV=production\n</code></pre>"},{"location":"guides/configuration/#using-environment-variables","title":"Using Environment Variables","text":"<p>Environment variables have the highest precedence and can override any configuration value:</p>"},{"location":"guides/configuration/#standard-configuration-variables","title":"Standard Configuration Variables","text":"<ul> <li><code>AGENT_NAME</code>: Name of the agent</li> <li><code>LOG_LEVEL</code>: Logging level (e.g., \"DEBUG\", \"INFO\", \"WARNING\")</li> <li><code>COMMUNICATOR_TYPE</code>: Type of communicator to use (e.g., \"http\", \"mcp_sse\", \"mcp_stdio\")</li> </ul>"},{"location":"guides/configuration/#configuring-service-urls","title":"Configuring Service URLs","text":"<p>There are two ways to configure service URLs (the external services your agent connects to):</p> <ol> <li>JSON Dictionary (all services at once):</li> </ol> <pre><code>export SERVICE_URLS='{\"chess-engine\": \"http://localhost:8000\", \"vision\": \"http://localhost:8001\"}'\n</code></pre> <ol> <li>Individual Service URLs (one service at a time):</li> </ol> <pre><code>export SERVICE_URL_CHESS_ENGINE=\"http://localhost:8000\"\nexport SERVICE_URL_VISION=\"http://localhost:8001\"\n</code></pre>"},{"location":"guides/configuration/#communicator-options","title":"Communicator Options","text":"<p>Similarly, communicator options can be set in two ways:</p> <ol> <li>JSON Dictionary:</li> </ol> <pre><code>export COMMUNICATOR_OPTIONS='{\"timeout\": 60, \"retries\": 5}'\n</code></pre> <ol> <li>Individual Options:</li> </ol> <pre><code>export COMMUNICATOR_OPTION_TIMEOUT=60\nexport COMMUNICATOR_OPTION_RETRIES=5\n</code></pre>"},{"location":"guides/configuration/#plugin-configuration","title":"Plugin Configuration","text":"<p>In the <code>openmas_project.yml</code> file, you can specify paths to plugin directories:</p> <pre><code>plugin_paths:\n  - \"plugins/communicators\"\n  - \"plugins/agents\"\n</code></pre> <p>OpenMAS will automatically discover and load plugins from these directories. For custom communicators, they will be available for use by specifying the communicator type in your configuration.</p>"},{"location":"guides/configuration/#configuration-in-code","title":"Configuration in Code","text":"<p>In your agent code, use the <code>load_config</code> function along with a Pydantic model (typically <code>AgentConfig</code> or a subclass) to load and validate configuration:</p> <pre><code>from openmas.config import load_config, AgentConfig\nfrom pydantic import Field\n\n# Load standard agent configuration using the base AgentConfig model\nconfig: AgentConfig = load_config(AgentConfig)\n\n# --- Or define and load a custom configuration model ---\n\nclass MyLLMAgentConfig(AgentConfig):\n    \"\"\"Custom configuration including LLM settings.\"\"\"\n    llm_api_key: str = Field(..., description=\"API key for external LLM service\")\n    llm_model_name: str = Field(\"gpt-4o\", description=\"Model name to use\")\n\n# Load configuration using your custom model\nmy_config: MyLLMAgentConfig = load_config(MyLLMAgentConfig)\n\n# Access validated config values later in your agent:\n# api_key = my_config.llm_api_key\n# agent_name = my_config.name\n</code></pre> <p>The <code>load_config</code> function handles the layering logic, environment variable parsing, and Pydantic validation, providing a type-safe configuration object.</p>"},{"location":"guides/configuration/#common-configuration-patterns","title":"Common Configuration Patterns","text":""},{"location":"guides/configuration/#best-practices","title":"Best Practices","text":"<ol> <li>Use YAML for Static Configuration: Put relatively static configuration in YAML files.</li> <li>Use Environment Variables for Dynamic or Sensitive Configuration: Use environment variables for values that change between deployments or for secrets.</li> <li>External Service Configuration: Define service URLs in your YAML configuration files, and override for local development or specific deployments using environment variables.</li> </ol>"},{"location":"guides/configuration/#external-service-configuration-examples","title":"External Service Configuration Examples","text":"<p>For configuring external services, typically in a containerized environment:</p> <p>config/default.yml: <pre><code>service_urls:\n  database: \"postgresql://postgres:5432/mydb\"\n  cache: \"redis://redis:6379/0\"\n  mcp-server: \"http://mcp-server:8080/v1\"\n</code></pre></p> <p>config/local.yml: <pre><code>service_urls:\n  database: \"postgresql://localhost:5432/mydb\"\n  cache: \"redis://localhost:6379/0\"\n  mcp-server: \"http://localhost:8080/v1\"\n</code></pre></p> <p>In your Dockerfile or docker-compose environment: <pre><code>OPENMAS_ENV=production\nSERVICE_URL_MCP_SERVER=http://production-mcp.internal:8080/v1\n</code></pre></p>"},{"location":"guides/configuration/#debugging-configuration","title":"Debugging Configuration","text":"<p>If you're having trouble with configuration, you can enable DEBUG logging to see where values are coming from:</p> <pre><code>export LOG_LEVEL=DEBUG\n</code></pre> <p>This will show detailed logs about configuration loading, including which files are being read and what values are being applied from each source.</p>"},{"location":"guides/configuration/#configuration-keys-reference","title":"Configuration Keys Reference","text":"<p>Here are the commonly used configuration keys in OpenMAS:</p> Key Description Default <code>name</code> Agent name <code>\"agent\"</code> <code>log_level</code> Logging level <code>\"INFO\"</code> <code>communicator_type</code> Type of communicator <code>\"http\"</code> <code>service_urls</code> Dictionary of service URLs <code>{}</code> <code>communicator_options</code> Dictionary of options for the communicator <code>{}</code> <code>plugin_paths</code> List of paths to look for plugins <code>[]</code> <code>extension_paths</code> List of paths to look for local framework extensions <code>[]</code> <p>For communicator-specific options, refer to the Communication Guide.</p>"},{"location":"guides/deployment/","title":"Deploying OpenMAS Systems","text":"<p>This document provides guidance on deploying multi-agent systems built with OpenMAS using common technologies like Docker and Kubernetes.</p>"},{"location":"guides/deployment/#deployment-strategies","title":"Deployment Strategies","text":"<p>Depending on the complexity and requirements of your system, you might choose different deployment strategies:</p>"},{"location":"guides/deployment/#single-process-deployment","title":"Single-Process Deployment","text":"<p>All agents run within the same operating system process. This is suitable for:</p> <ul> <li>Simple systems with few agents.</li> <li>Testing and development.</li> <li>Scenarios where high-performance, low-latency communication via in-memory communicators (like a potential future <code>InMemoryCommunicator</code> or specific MCP setups) is crucial.</li> </ul> <p>Example Structure (<code>main_app.py</code>):</p> <pre><code>import asyncio\nfrom openmas.agent import BaseAgent\n# Assume an in-memory or suitable local communicator exists or is mocked\n# from openmas.communication.memory import InMemoryCommunicator\nfrom openmas.testing import MockCommunicator # Using Mock for illustration\nfrom openmas.logging import configure_logging\n\nconfigure_logging()\n\nasync def main():\n    # Define shared communicator or links\n    comm1 = MockCommunicator(agent_name=\"agent1\")\n    comm2 = MockCommunicator(agent_name=\"agent2\")\n    # Link mock communicators for in-process testing/simulation\n    comm1.link_communicator(comm2)\n    comm2.link_communicator(comm1)\n\n    # Create agents in the same process\n    agent1 = BaseAgent(name=\"agent1\")\n    agent1.set_communicator(comm1) # Manually set communicator\n    # Register handlers...\n    # @agent1.register_handler(...)\n\n    agent2 = BaseAgent(name=\"agent2\")\n    agent2.set_communicator(comm2)\n    # Register handlers...\n\n    # Start agents\n    await agent1.start()\n    await agent2.start()\n\n    # System runs here\n    try:\n        print(\"Single-process system running. Press Ctrl+C to stop.\")\n        # Keep the main process alive\n        while True:\n            await asyncio.sleep(3600)\n    except KeyboardInterrupt:\n        print(\"\\nShutting down...\")\n        await agent1.stop()\n        await agent2.stop()\n        print(\"System stopped.\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"guides/deployment/#multi-process-deployment","title":"Multi-Process Deployment","text":"<p>Each agent (or a small group of related agents) runs in its own operating system process on the same machine or different machines. This is the most common approach for non-trivial systems.</p> <ul> <li>Communication: Requires network-based communicators like <code>HttpCommunicator</code>, <code>McpSseCommunicator</code>, <code>GrpcCommunicator</code>, or <code>MqttCommunicator</code>.</li> <li>Configuration: Each agent process needs its configuration, especially <code>service_urls</code> pointing to the network addresses (host/port) of other agents/services it needs to contact.</li> </ul> <p>Example (<code>agent1_main.py</code>):</p> <pre><code># agent1_main.py\nimport asyncio\nfrom openmas.agent import BaseAgent\nfrom openmas.config import load_config, AgentConfig\nfrom openmas.logging import configure_logging\n\nconfigure_logging()\n\nasync def main():\n    config = load_config(AgentConfig) # Loads from env vars, files\n    # Ensure config has necessary communicator_type, http_port, service_urls\n\n    agent = BaseAgent(config=config)\n    # Register handlers...\n\n    await agent.start()\n\n    try:\n        print(f\"Agent '{agent.name}' running. Press Ctrl+C to stop.\")\n        while True:\n            await asyncio.sleep(3600)\n    except KeyboardInterrupt:\n        print(f\"\\nShutting down agent '{agent.name}'...\")\n        await agent.stop()\n        print(f\"Agent '{agent.name}' stopped.\")\n\nif __name__ == \"__main__\":\n    # Example: Run with specific config via env vars\n    # export AGENT_NAME=agent1\n    # export COMMUNICATOR_TYPE=http\n    # export COMMUNICATOR_OPTION_HTTP_PORT=8000\n    # export SERVICE_URL_AGENT2=\"http://localhost:8001\"\n    asyncio.run(main())\n</code></pre> <p>(A similar <code>agent2_main.py</code> would be created, typically listening on a different port, e.g., 8001).</p>"},{"location":"guides/deployment/#containerization-with-docker","title":"Containerization with Docker","text":"<p>Containerizing agents with Docker is highly recommended for consistent environments and easier deployment.</p>"},{"location":"guides/deployment/#creating-a-dockerfile","title":"Creating a Dockerfile","text":"<p>A typical Dockerfile for an OpenMAS agent using Poetry might look like this:</p> <pre><code># Dockerfile for a single agent\nARG PYTHON_VERSION=3.10\nFROM python:${PYTHON_VERSION}-slim\n\nENV PYTHONDONTWRITEBYTECODE=1\nENV PYTHONUNBUFFERED=1\nENV POETRY_NO_INTERACTION=1 \\\n    POETRY_VIRTUALENVS_CREATE=false \\\n    POETRY_CACHE_DIR='/var/cache/pypoetry' \\\n    POETRY_HOME='/opt/poetry'\n\nWORKDIR /app\n\n# Install poetry\nRUN pip install --no-cache-dir poetry==1.7.1 # Use a specific stable version\n\n# Copy only dependency files first for caching\nCOPY pyproject.toml poetry.lock ./\n\n# Install dependencies\n# Use --only main if you don't need dev dependencies in the image\nRUN poetry install --no-root --sync\n\n# Copy the rest of the application code\nCOPY . .\n\n# Default port exposure (can be overridden)\nEXPOSE 8000\n\n# Command to run the agent (adjust path if needed)\n# Assumes your agent entrypoint script is src/my_project/agent1_main.py\nCMD [\"poetry\", \"run\", \"python\", \"src/my_project/agent1_main.py\"]\n</code></pre>"},{"location":"guides/deployment/#generating-a-dockerfile-experimental","title":"Generating a Dockerfile (Experimental)","text":"<p>OpenMAS provides an experimental CLI command to help generate a basic Dockerfile for a specific agent defined in your <code>openmas_project.yml</code>:</p> <pre><code>poetry run openmas generate-dockerfile &lt;agent_name&gt; --output-file Dockerfile.&lt;agent_name&gt;\n</code></pre> <p>Replace <code>&lt;agent_name&gt;</code> with the name of the agent defined in your project file. Review and customize the generated Dockerfile as needed.</p>"},{"location":"guides/deployment/#building-and-running","title":"Building and Running","text":"<pre><code># Build the image\ndocker build -t my-agent-image:latest .\n\n# Run the container\ndocker run -d --rm \\\n    -p 8000:8000 \\\n    -e AGENT_NAME=agent1 \\\n    -e COMMUNICATOR_OPTION_HTTP_PORT=8000 \\\n    -e SERVICE_URL_AGENT2=\"http://&lt;agent2_host_or_ip&gt;:8001\" \\\n    --name my-agent1-container \\\n    my-agent-image:latest\n</code></pre>"},{"location":"guides/deployment/#orchestration-with-docker-compose","title":"Orchestration with Docker Compose","text":"<p>For running multiple agents locally or in simple deployments, Docker Compose is useful.</p> <p>Example (<code>docker-compose.yml</code>):</p> <pre><code>version: '3.8'\n\nservices:\n  agent1:\n    build:\n      context: . # Assumes Dockerfile is in the current directory\n      # target: production # Optional: if using multi-stage builds\n    container_name: agent1\n    ports:\n      - \"8000:8000\" # Expose agent1's port 8000 on the host\n    environment:\n      # --- OpenMAS Configuration ---\n      - OPENMAS_ENV=production # Or development, local, etc.\n      - LOG_LEVEL=INFO\n      - AGENT_NAME=agent1\n      - COMMUNICATOR_TYPE=http\n      # --- Agent 1 Specific Options ---\n      - COMMUNICATOR_OPTION_HTTP_PORT=8000 # Port inside the container\n      # --- Service URLs (using Docker Compose service names) ---\n      - SERVICE_URL_AGENT2=http://agent2:8001 # Agent 2 listens on 8001 internally\n      # - SERVICE_URL_REDIS=redis://redis_db:6379 # Example external service\n    # volumes: # Optional: Mount config files if not using env vars exclusively\n      # - ./config:/app/config\n    networks:\n      - openmas_net\n\n  agent2:\n    build:\n      context: .\n    container_name: agent2\n    ports:\n      - \"8001:8001\"\n    environment:\n      - OPENMAS_ENV=production\n      - LOG_LEVEL=INFO\n      - AGENT_NAME=agent2\n      - COMMUNICATOR_TYPE=http\n      - COMMUNICATOR_OPTION_HTTP_PORT=8001\n      - SERVICE_URL_AGENT1=http://agent1:8000 # Agent 1 listens on 8000 internally\n    networks:\n      - openmas_net\n\n  # redis_db: # Example dependency\n  #   image: redis:alpine\n  #   networks:\n  #     - openmas_net\n\nnetworks:\n  openmas_net:\n    driver: bridge\n</code></pre> <p>Run:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"guides/deployment/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>For production-grade, scalable deployments, Kubernetes is recommended. You will typically define <code>Deployment</code> and <code>Service</code> resources for each agent.</p> <p>Example (<code>agent1-k8s.yaml</code>):</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: agent1-deployment\n  labels:\n    app: agent1\nspec:\n  replicas: 1 # Adjust as needed\n  selector:\n    matchLabels:\n      app: agent1\n  template:\n    metadata:\n      labels:\n        app: agent1\n    spec:\n      containers:\n      - name: agent1-container\n        image: your-repo/my-agent-image:latest # Replace with your image registry path\n        # If your agent entrypoint is different from Dockerfile CMD:\n        # command: [\"poetry\", \"run\", \"python\", \"src/my_project/agent1_main.py\"]\n        ports:\n        - name: http # Name the port\n          containerPort: 8000 # Agent listens on this port internally\n        env:\n        # --- OpenMAS Configuration via Env Vars ---\n        - name: OPENMAS_ENV\n          value: \"production\"\n        - name: LOG_LEVEL\n          value: \"INFO\"\n        - name: AGENT_NAME\n          value: \"agent1\"\n        - name: COMMUNICATOR_TYPE\n          value: \"http\"\n        - name: COMMUNICATOR_OPTION_HTTP_PORT\n          value: \"8000\" # Port inside the container\n        # --- Service URLs (using Kubernetes service DNS names) ---\n        - name: SERVICE_URL_AGENT2\n          # Assumes a K8s Service named 'agent2-service' exists in the same namespace\n          value: \"http://agent2-service:8001\" # agent2 listens on port 8001\n        # Add other env vars for API keys, etc.\n        # Consider using Secrets or ConfigMaps for sensitive/config data\n        resources: # Optional: Define resource requests/limits\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: agent1-service # This is the DNS name other services will use\n  labels:\n    app: agent1\nspec:\n  selector:\n    app: agent1 # Selects pods with the 'app: agent1' label\n  ports:\n  - name: http\n    port: 8000 # Port the Service exposes within the cluster\n    targetPort: http # Name of the container port to target (defined in Deployment)\n  type: ClusterIP # Only exposes the service within the cluster\n  # Use LoadBalancer or NodePort for external access if needed\n</code></pre> <p>(A similar <code>agent2-k8s.yaml</code> would define the Deployment and Service for <code>agent2</code>, listening on port 8001 and referencing <code>agent1-service</code> in its <code>SERVICE_URL_AGENT1</code> environment variable).</p> <p>Apply:</p> <pre><code>kubectl apply -f agent1-k8s.yaml\nkubectl apply -f agent2-k8s.yaml\n</code></pre>"},{"location":"guides/deployment/#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>Effective monitoring and logging are crucial for deployed systems.</p> <ul> <li>Logging: OpenMAS uses standard Python logging. Configure <code>configure_logging</code> (e.g., setting <code>json_format=True</code>) to output logs in a structured format (like JSON) suitable for log aggregation systems (e.g., Elasticsearch, Loki, Datadog).     <pre><code>from openmas.logging import configure_logging, get_logger\n\n# In your main entrypoint or agent setup:\nconfigure_logging(log_level=\"INFO\", json_format=True)\n\nlogger = get_logger(__name__)\n\n# Logs will now be in JSON format\nlogger.info(\"Agent started\", extra={\"agent_id\": self.name, \"status\": \"active\"})\n</code></pre></li> <li>Metrics: Integrate with metrics libraries (like <code>prometheus-client</code> or <code>opentelemetry-python</code>) to expose key agent metrics (e.g., messages processed, queue lengths, task durations). Expose these via an HTTP endpoint scraped by Prometheus or pushed to a monitoring backend.</li> <li>Tracing: For complex interactions, consider distributed tracing using OpenTelemetry to track requests across multiple agents and services.</li> </ul>"},{"location":"guides/getting_started/","title":"Getting Started with OpenMAS","text":"<p>This guide will walk you through the standard OpenMAS workflow to create and run your first agent using the official OpenMAS CLI tools.</p>"},{"location":"guides/getting_started/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have OpenMAS installed:</p> <pre><code>pip install openmas\n</code></pre> <p>If you haven't installed OpenMAS yet, see the detailed Installation Guide for more information on virtual environments and optional dependencies.</p>"},{"location":"guides/getting_started/#step-1-initialize-your-project","title":"Step 1: Initialize Your Project","text":"<p>First, let's create a new OpenMAS project:</p> <pre><code>openmas init my_first_mas\n</code></pre> <p>This command creates a new directory <code>my_first_mas</code> with the standard OpenMAS project structure:</p> <pre><code>my_first_mas/\n\u251c\u2500\u2500 agents/              # Directory for your agents\n\u2502   \u2514\u2500\u2500 sample_agent/    # A pre-generated sample agent\n\u251c\u2500\u2500 config/              # Configuration files\n\u251c\u2500\u2500 extensions/          # Custom framework extensions\n\u251c\u2500\u2500 packages/            # External dependencies\n\u251c\u2500\u2500 shared/              # Shared code between agents\n\u251c\u2500\u2500 tests/               # Project tests\n\u251c\u2500\u2500 openmas_project.yml  # Main project configuration\n\u2514\u2500\u2500 README.md            # Project documentation\n</code></pre> <p>The most important files are: - <code>openmas_project.yml</code> - The central project configuration - <code>agents/sample_agent/agent.py</code> - A sample agent ready to run</p>"},{"location":"guides/getting_started/#step-2-explore-the-sample-agent","title":"Step 2: Explore the Sample Agent","text":"<p>When you initialize a project, OpenMAS automatically creates a sample agent for you. Let's examine its code:</p> <pre><code># agents/sample_agent/agent.py\nimport asyncio\nfrom openmas.agent import BaseAgent\n\nclass Agent(BaseAgent):\n    '''Sample agent implementation.'''\n\n    async def setup(self) -&gt; None:\n        '''Set up the agent.'''\n        self.logger.info(\"Sample agent initializing...\")\n\n    async def run(self) -&gt; None:\n        '''Run the agent.'''\n        self.logger.info(\"Sample agent running...\")\n\n        # Example periodic task\n        for i in range(5):\n            self.logger.info(f\"Sample agent tick {i}...\")\n            await asyncio.sleep(1)\n\n        self.logger.info(\"Sample agent completed.\")\n\n    async def shutdown(self) -&gt; None:\n        '''Clean up when the agent stops.'''\n        self.logger.info(\"Sample agent shutting down...\")\n</code></pre> <p>This is a simple agent with three lifecycle methods:</p> <ul> <li>setup(): Runs once when the agent starts - use this for initialization</li> <li>run(): The main agent logic - this sample counts to 5 and exits</li> <li>shutdown(): Cleanup logic that runs when the agent stops</li> </ul>"},{"location":"guides/getting_started/#step-3-run-the-agent","title":"Step 3: Run the Agent","text":"<p>Navigate into your project directory:</p> <pre><code>cd my_first_mas\n</code></pre> <p>Run the sample agent using the OpenMAS CLI:</p> <pre><code>openmas run sample_agent\n</code></pre> <p>You should see output similar to:</p> <pre><code>2023-09-24 15:30:45 [info     ] Loaded project config from ./openmas_project.yml\n2023-09-24 15:30:45 [info     ] Initialized agent              [Agent] agent_name=sample_agent agent_type=Agent\n2023-09-24 15:30:45 [info     ] Starting agent                 [Agent] agent_name=sample_agent\n2023-09-24 15:30:45 [info     ] Started HTTP communicator      [openmas.communication.http]\n2023-09-24 15:30:45 [info     ] Sample agent initializing...   [Agent]\n2023-09-24 15:30:45 [info     ] Agent started                  [Agent] agent_name=sample_agent\nAgent is running. Waiting for completion or Ctrl+C...\n2023-09-24 15:30:45 [info     ] Sample agent running...        [Agent]\n2023-09-24 15:30:45 [info     ] Sample agent tick 0...         [Agent]\n2023-09-24 15:30:46 [info     ] Sample agent tick 1...         [Agent]\n2023-09-24 15:30:47 [info     ] Sample agent tick 2...         [Agent]\n2023-09-24 15:30:48 [info     ] Sample agent tick 3...         [Agent]\n2023-09-24 15:30:49 [info     ] Sample agent tick 4...         [Agent]\n2023-09-24 15:30:50 [info     ] Sample agent completed.        [Agent]\n</code></pre> <p>The sample agent runs, counts from 0 to 4, and then completes. You can also stop the agent at any time by pressing <code>Ctrl+C</code>. This will trigger the <code>shutdown()</code> method to be called.</p>"},{"location":"guides/getting_started/#step-4-modify-the-agent","title":"Step 4: Modify the Agent","text":"<p>Let's make a simple change to the agent. Open the <code>agents/sample_agent/agent.py</code> file in your editor and modify the log message in the <code>run()</code> method:</p> <pre><code>async def run(self) -&gt; None:\n    '''Run the agent.'''\n    self.logger.info(\"My first agent is running!\")  # Changed message\n\n    # Example periodic task\n    for i in range(5):\n        self.logger.info(f\"Sample agent tick {i}...\")\n        await asyncio.sleep(1)\n\n    self.logger.info(\"Sample agent completed.\")\n</code></pre>"},{"location":"guides/getting_started/#step-5-run-the-modified-agent","title":"Step 5: Run the Modified Agent","text":"<p>Run the agent again to see your changes:</p> <pre><code>openmas run sample_agent\n</code></pre> <p>Now you should see your modified message in the output:</p> <pre><code>2023-09-24 15:32:45 [info     ] Initialized agent              [Agent] agent_name=sample_agent agent_type=Agent\n2023-09-24 15:32:45 [info     ] Starting agent                 [Agent] agent_name=sample_agent\n2023-09-24 15:32:45 [info     ] Started HTTP communicator      [openmas.communication.http]\n2023-09-24 15:32:45 [info     ] Sample agent initializing...   [Agent]\n2023-09-24 15:32:45 [info     ] Agent started                  [Agent] agent_name=sample_agent\nAgent is running. Waiting for completion or Ctrl+C...\n2023-09-24 15:32:45 [info     ] My first agent is running!     [Agent]  # Your modified message\n2023-09-24 15:32:45 [info     ] Sample agent tick 0...         [Agent]\n2023-09-24 15:32:46 [info     ] Sample agent tick 1...         [Agent]\n2023-09-24 15:32:47 [info     ] Sample agent tick 2...         [Agent]\n2023-09-24 15:32:48 [info     ] Sample agent tick 3...         [Agent]\n2023-09-24 15:32:49 [info     ] Sample agent tick 4...         [Agent]\n2023-09-24 15:32:50 [info     ] Sample agent completed.        [Agent]\n</code></pre>"},{"location":"guides/getting_started/#conclusion-next-steps","title":"Conclusion &amp; Next Steps","text":"<p>Congratulations! You've successfully: 1. Created a new OpenMAS project with the standard structure 2. Examined the sample agent 3. Run the agent using the OpenMAS CLI 4. Modified the agent and verified your changes</p> <p>From here, you can explore more advanced topics:</p> <ul> <li>Configuration Guide - Learn how to configure your agents</li> <li>Communication Guide - Understand how agents communicate</li> <li>Patterns Guide - Explore common agent patterns</li> <li>MCP Integration - Connect your agents to AI models using MCP</li> <li>Testing Utilities - Learn how to test your agents</li> <li>Project Structure - Understand the OpenMAS project layout</li> </ul>"},{"location":"guides/installation/","title":"Installation","text":"<p>This guide explains how to install the <code>openmas</code> package.</p>"},{"location":"guides/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or newer.</li> </ul>"},{"location":"guides/installation/#standard-installation","title":"Standard Installation","text":"<p>The quickest way to install OpenMAS is using pip:</p> <pre><code>pip install openmas\n</code></pre>"},{"location":"guides/installation/#using-virtual-environments-recommended","title":"Using Virtual Environments (Recommended)","text":"venv (Built-in)Poetryuvconda <p>Python's built-in tool for creating lightweight virtual environments.</p> <ol> <li> <p>Create the environment: <pre><code>python -m venv .venv # Or choose a different name like 'venv'\n</code></pre></p> </li> <li> <p>Activate the environment:</p> <ul> <li>macOS/Linux: <code>source .venv/bin/activate</code></li> <li>Windows (Command Prompt): <code>.venv\\Scripts\\activate.bat</code></li> <li>Windows (PowerShell): <code>.venv\\Scripts\\Activate.ps1</code></li> </ul> </li> <li> <p>Install OpenMAS: <pre><code>pip install openmas\n</code></pre></p> </li> </ol> <p>A modern tool for Python dependency management and packaging, which automatically handles virtual environments.</p> <ol> <li> <p>Add OpenMAS to your Poetry project:     (Run this command inside your project directory where <code>pyproject.toml</code> is located)     <pre><code>poetry add openmas\n</code></pre></p> <ul> <li>Poetry will create a virtual environment if one doesn't exist for the project and install <code>openmas</code> into it.</li> <li>If you haven't initialized your project with Poetry yet, run <code>poetry init</code> first or <code>poetry new your-project-name</code>.</li> </ul> </li> <li> <p>Run commands within the environment:</p> <ul> <li>Either prefix commands with <code>poetry run</code> (e.g., <code>poetry run python your_script.py</code>)</li> <li>Or activate the shell explicitly: <code>poetry shell</code></li> </ul> </li> </ol> <p>An extremely fast Python package installer and resolver, capable of replacing pip and venv.</p> <ol> <li> <p>Create the environment: <pre><code>uv venv\n</code></pre></p> </li> <li> <p>Activate the environment:</p> <ul> <li>macOS/Linux: <code>source .venv/bin/activate</code></li> <li>Windows (Command Prompt): <code>.venv\\Scripts\\activate.bat</code></li> <li>Windows (PowerShell): <code>.venv\\Scripts\\Activate.ps1</code></li> </ul> </li> <li> <p>Install OpenMAS using uv: <pre><code>uv pip install openmas\n</code></pre></p> </li> </ol> <p>A popular package and environment manager, often used in data science.</p> <ol> <li> <p>Create the environment: <pre><code>conda create -n openmas-env python=3.10 # Or your preferred Python version\n</code></pre></p> </li> <li> <p>Activate the environment: <pre><code>conda activate openmas-env\n</code></pre></p> </li> <li> <p>Install OpenMAS: <pre><code>pip install openmas\n# Note: You can use pip within a conda environment.\n</code></pre></p> </li> </ol>"},{"location":"guides/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>OpenMAS is modular. Install optional features as needed:</p> <ul> <li><code>mcp</code>: Model Context Protocol integration.</li> <li><code>grpc</code>: gRPC communication support.</li> <li><code>mqtt</code>: MQTT communication support.</li> <li><code>all</code>: All optional dependencies.</li> </ul> <p>Install these extras using brackets <code>[]</code>. The specific command depends on how you manage your environment:</p> <ul> <li> <p>If using <code>pip</code> or <code>uv</code>: <pre><code># Example: Install MCP and gRPC support\npip install 'openmas[mcp,grpc]'\n# Or using uv:\n# uv pip install 'openmas[mcp,grpc]'\n\n# Example: Install all extras\npip install 'openmas[all]'\n# Or using uv:\n# uv pip install 'openmas[all]'\n</code></pre></p> </li> <li> <p>If using <code>Poetry</code>: <pre><code># Example: Add MCP and gRPC support (Poetry handles the environment)\npoetry add 'openmas[mcp,grpc]'\n\n# Example: Add all extras\npoetry add 'openmas[all]'\n</code></pre></p> </li> </ul>"},{"location":"guides/installation/#verify-installation-optional","title":"Verify Installation (Optional)","text":"<p>After installation, you can verify it using one of these methods:</p> <ol> <li>Use the <code>--version</code> flag to quickly check the installed version:</li> </ol> <pre><code>openmas --version\n</code></pre> <ol> <li>Use the <code>info</code> command which shows detailed information about the installation including version and module information:</li> </ol> <pre><code>openmas info\n</code></pre> <p>Example output: <pre><code>OpenMAS version: 0.1.0\nPython version: 3.10.17 (CPython)\nPlatform: macOS-15.4.1-arm64-arm-64bit\n\nOptional modules:\n  base       \u2713\n  http       \u2713\n  mcp        \u2713\n  grpc       \u2717\n  mqtt       \u2713\n\nFor more information, visit: https://docs.openmas.ai/\n</code></pre></p> <p>For JSON output (useful for scripting), use: <pre><code>openmas info --json\n</code></pre></p> <ol> <li>You can also verify installation by importing the package:</li> </ol> <pre><code>python -c \"import openmas; print(openmas.__version__)\"\n</code></pre>"},{"location":"guides/llm_integration/","title":"Integrating Large Language Models (LLMs)","text":"<p>OpenMAS agents can easily integrate with various Large Language Models (LLMs) like OpenAI's GPT, Anthropic's Claude, or Google's Gemini to add sophisticated reasoning capabilities.</p> <p>The recommended approach is straightforward: initialize the official LLM client library (e.g., <code>openai</code>, <code>anthropic</code>, <code>google-generativeai</code>) directly within your agent's <code>setup()</code> method, using configuration loaded via OpenMAS's standard mechanisms.</p> <p>This pattern offers several advantages: *   Simplicity: Leverages the official, feature-rich SDKs provided by the LLM vendors. *   Direct Control: Gives you full control over model parameters, error handling, and interaction logic. *   Standard Configuration: Uses OpenMAS's environment variable and configuration file loading for API keys and model names. *   No Extra Abstraction: Avoids adding unnecessary abstraction layers over the LLM clients.</p>"},{"location":"guides/llm_integration/#steps","title":"Steps","text":""},{"location":"guides/llm_integration/#1-install-the-llm-client-library","title":"1. Install the LLM Client Library","text":"<p>Ensure you have the necessary Python package for your chosen LLM installed in your project's environment:</p> <pre><code># Example for OpenAI\npip install openai\n# poetry add openai\n\n# Example for Anthropic\npip install anthropic\n# poetry add anthropic\n\n# Example for Google\npip install google-generativeai\n# poetry add google-generativeai\n</code></pre>"},{"location":"guides/llm_integration/#2-configure-api-keys-and-model-names","title":"2. Configure API Keys and Model Names","text":"<p>Set environment variables for your LLM service. OpenMAS configuration will automatically pick these up if you map them in your agent's config or access them directly.</p> <pre><code>export OPENAI_API_KEY=\"your_openai_api_key\"\nexport OPENAI_MODEL_NAME=\"gpt-4o\" # Or your preferred model\n\nexport ANTHROPIC_API_KEY=\"your_anthropic_api_key\"\nexport ANTHROPIC_MODEL_NAME=\"claude-3-opus-20240229\"\n\nexport GOOGLE_API_KEY=\"your_google_api_key\"\nexport GOOGLE_MODEL_NAME=\"gemini-1.5-pro-latest\"\n</code></pre>"},{"location":"guides/llm_integration/#3-initialize-the-client-in-setup","title":"3. Initialize the Client in <code>setup()</code>","text":"<p>In your agent's code (subclassing <code>BaseAgent</code>), import the LLM library and initialize its client within the <code>setup</code> method.</p> <pre><code>import asyncio\nimport os\nfrom openmas.agent import BaseAgent\n# Assuming you might use a custom config, or access os.environ directly\n# from openmas.config import AgentConfig\n\n# --- Example using OpenAI ---\nclass OpenAIAgent(BaseAgent):\n    \"\"\"Agent that uses OpenAI for reasoning.\"\"\"\n\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the agent by initializing the OpenAI client.\"\"\"\n        try:\n            import openai\n            self.logger.info(\"Initializing OpenAI client...\")\n            # Load API key from environment variable\n            api_key = os.environ.get(\"OPENAI_API_KEY\")\n            if not api_key:\n                self.logger.error(\"OPENAI_API_KEY environment variable not set.\")\n                raise ValueError(\"Missing OpenAI API Key\")\n\n            # Get model name from environment or use a default\n            self.model_name = os.environ.get(\"OPENAI_MODEL_NAME\", \"gpt-4o\")\n\n            # Use the official OpenAI async client\n            self.aclient = openai.AsyncOpenAI(api_key=api_key)\n            self.logger.info(\"OpenAI client initialized.\", model=self.model_name)\n\n        except ImportError:\n            self.logger.error(\"OpenAI package not installed. Run: pip install openai\")\n            raise\n        except Exception as e:\n            self.logger.error(f\"Failed to initialize OpenAI client: {e}\")\n            raise\n\n    async def get_llm_response(self, prompt: str, system_prompt: str = \"You are a helpful assistant.\") -&gt; str:\n        \"\"\"Get a response from the initialized OpenAI LLM.\"\"\"\n        if not hasattr(self, 'aclient'):\n            raise RuntimeError(\"OpenAI client not initialized. Call setup() first.\")\n\n        try:\n            response = await self.aclient.chat.completions.create(\n                model=self.model_name,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_prompt},\n                    {\"role\": \"user\", \"content\": prompt}\n                ]\n            )\n            # Basic error check (you might want more robust handling)\n            if response.choices:\n                return response.choices[0].message.content\n            else:\n                self.logger.warning(\"LLM response had no choices.\")\n                return \"\"\n        except Exception as e:\n            self.logger.error(f\"Error getting LLM response: {e}\")\n            # Decide how to handle errors - raise, return default, etc.\n            raise\n\n    async def run(self) -&gt; None:\n        \"\"\"Example run loop using the LLM.\"\"\"\n        self.logger.info(\"LLM Agent running...\")\n        try:\n            response = await self.get_llm_response(\"What is the capital of France?\")\n            self.logger.info(f\"LLM Response: {response}\")\n        except Exception as e:\n            self.logger.error(f\"Failed during run loop: {e}\")\n\n        # Keep agent alive or perform other tasks\n        await asyncio.sleep(3600)\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        self.logger.info(\"Shutting down LLM agent.\")\n        if hasattr(self, 'aclient'):\n             # Use await for the async client's close method if available\n             # await self.aclient.close() # Check specific SDK docs for cleanup\n             pass\n        await super().shutdown()\n\n# --- Example using Anthropic ---\n# (Similar structure: import, init in setup, use client method)\n# Remember to use the official async client: anthropic.AsyncAnthropic\n\n# --- Example using Google Gemini ---\n# (Similar structure: import, configure/init model in setup, use model method)\n# Ensure you use async methods if available in the google-generativeai library\n</code></pre>"},{"location":"guides/llm_integration/#4-use-the-client-in-agent-logic","title":"4. Use the Client in Agent Logic","text":"<p>Call the methods of the initialized LLM client (like <code>aclient.chat.completions.create</code> for OpenAI) within your agent's <code>run</code> loop or request handlers to generate responses based on prompts.</p>"},{"location":"guides/llm_integration/#best-practices","title":"Best Practices","text":"<ul> <li>Use Async Clients: Always use the asynchronous versions of the LLM client libraries (e.g., <code>openai.AsyncOpenAI</code>, <code>anthropic.AsyncAnthropic</code>) to avoid blocking your agent's event loop.</li> <li>Configuration: Load API keys and model names securely from environment variables or configuration files managed by OpenMAS.</li> <li>Error Handling: Implement robust error handling for API calls, considering network issues, rate limits, and invalid responses.</li> <li>Resource Management: Ensure any necessary client cleanup is performed in the agent's <code>shutdown</code> method (refer to the specific LLM SDK documentation).</li> <li>Prompt Engineering: Develop clear and effective prompts, potentially using system messages to provide context about the agent's role and goals.</li> <li>Dependency Management: Add the required LLM client library to your project's dependencies (e.g., in <code>pyproject.toml</code> or <code>requirements.txt</code>).</li> </ul> <p>(See the specific documentation for the OpenAI, Anthropic, or Google Generative AI Python libraries for detailed API usage.)</p>"},{"location":"guides/mcp_developer_guide/","title":"MCP v1.7.1 Developer Guide (OpenMAS Integration)","text":"<p>Version: 2.0 (Based on <code>mcp</code> Python SDK v1.7.1)</p>"},{"location":"guides/mcp_developer_guide/#1-introduction","title":"1. Introduction","text":"<p>MCP stands for Model Context Protocol. Developed by Anthropic, it provides a standardized interface for AI models and services to communicate, enabling features like tool use, resource sharing, and prompting across different transport layers.</p> <p>Goal: This document serves as the definitive guide for developers working with MCP (specifically <code>mcp</code> Python SDK v1.7.1) within the OpenMAS framework. It outlines best practices, setup instructions, server/client implementation patterns, testing strategies, and solutions to common issues encountered during integration.</p> <p>Target Audience: Developers building or integrating MCP-based agents, tools, or communication components in OpenMAS.</p> <p>Key MCP Concepts: *   Transport: The underlying protocol for communication (e.g., stdio, SSE). *   Server (<code>FastMCP</code>): Hosts tools and resources. *   Client (<code>ClientSession</code>): Connects to a server to use tools/resources. *   Tools: Functions exposed by a server for clients to call. *   Streams: Underlying communication channels managed by the transport layer.</p> <p>Official Resources: *   Concepts &amp; Architecture: https://modelcontextprotocol.io/docs/concepts/architecture *   Python SDK (GitHub): https://github.com/modelcontextprotocol/python-sdk *   MCP Documentation: https://modelcontextprotocol.io/docs/</p>"},{"location":"guides/mcp_developer_guide/#2-setup","title":"2. Setup","text":"<ol> <li> <p>Install <code>mcp</code>: Use <code>poetry</code> (or <code>pip</code>) to add the <code>mcp</code> package. For CLI tools like the inspector, include the <code>cli</code> extra:     <pre><code>poetry add \"mcp[cli]&gt;=1.7.1\"\n# or\n# pip install \"mcp[cli]&gt;=1.7.1\"\n</code></pre></p> </li> <li> <p>Dependencies for SSE: If using the SSE transport, ensure <code>aiohttp</code> and <code>httpx</code> are installed (they are typically included as dependencies of <code>mcp</code>, but verify):     <pre><code>poetry add aiohttp httpx\n# or\n# pip install aiohttp httpx\n</code></pre></p> </li> </ol>"},{"location":"guides/mcp_developer_guide/#3-creating-an-mcp-server-fastmcp","title":"3. Creating an MCP Server (<code>FastMCP</code>)","text":"<p>The server exposes tools that clients can call.</p>"},{"location":"guides/mcp_developer_guide/#31-basic-server-setup","title":"3.1. Basic Server Setup","text":"<pre><code># Example: src/my_mcp_server.py\nimport asyncio\nimport logging\nimport sys\nimport json\nfrom mcp.server.fastmcp import FastMCP, Context\nfrom mcp.types import TextContent\n\n# Configure logging (stderr is often useful for debugging subprocesses)\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n    handlers=[logging.StreamHandler(sys.stderr)],\n)\nlogger = logging.getLogger(\"MyMCPServer\")\n\n# Create the FastMCP instance\nmcp_server = FastMCP(\n    name=\"MyExampleServer\",\n    log_level=\"DEBUG\", # Use DEBUG for detailed MCP logs\n)\n</code></pre>"},{"location":"guides/mcp_developer_guide/#32-defining-tools","title":"3.2. Defining Tools","text":"<p>Tools are async functions that can be added to the FastMCP server.</p> <pre><code># Define a simple echo tool\nasync def echo_tool(ctx: Context) -&gt; list[TextContent]:\n    \"\"\"\n    Simple echo tool.\n\n    Args:\n        ctx: The MCP context object containing request information.\n\n    Returns:\n        A list of TextContent objects.\n    \"\"\"\n    logger.debug(f\"Echo tool called with context: {ctx}\")\n\n    # Extract the message from context\n    message = None\n    if hasattr(ctx, \"arguments\") and ctx.arguments:\n        if \"message\" in ctx.arguments:\n            message = ctx.arguments[\"message\"]\n        elif \"content\" in ctx.arguments and isinstance(ctx.arguments[\"content\"], list):\n            # Handle content array format\n            for item in ctx.arguments[\"content\"]:\n                if isinstance(item, dict) and \"text\" in item:\n                    message = item[\"text\"]\n                    break\n\n    if message is None:\n        logger.error(\"No message found in context\")\n        return [TextContent(type=\"text\", text=json.dumps({\"error\": \"No message found\"}))]\n\n    try:\n        # Prepare the success payload\n        response_obj = {\"echoed\": message}\n        return [TextContent(type=\"text\", text=json.dumps(response_obj))]\n    except Exception as e:\n        logger.error(f\"Error in echo tool: {e}\", exc_info=True)\n        return [TextContent(type=\"text\", text=json.dumps({\"error\": str(e)}))]\n\n# Add the tool to the server\nmcp_server.add_tool(\n    name=\"echo\",\n    description=\"Echo back the input message as JSON\",\n    fn=echo_tool,\n)\n\n# Add more tools as needed...\n</code></pre> <p>Key Points for Tools (v1.7.1): *   Return Value: Tools must return a list of TextContent objects. For simple text responses, wrap your string in a TextContent object. *   Context Handling: The context object now has an <code>arguments</code> attribute that contains the request parameters. *   Error Handling: Return error messages as TextContent objects rather than raising exceptions, as exceptions won't be properly formatted for clients.</p>"},{"location":"guides/mcp_developer_guide/#4-running-the-mcp-server","title":"4. Running the MCP Server","text":"<p>How you run the server depends on the desired transport.</p>"},{"location":"guides/mcp_developer_guide/#41-sse-transport-recommended-for-networked-agents","title":"4.1. SSE Transport (Recommended for Networked Agents)","text":"<p>With MCP 1.7.1, running an SSE server is simpler and more reliable.</p> <pre><code># Example: src/my_mcp_server.py (continued)\n\nimport uvicorn\nfrom fastapi import FastAPI\n\n# --- FastAPI Integration ---\n\n# 1. Create a FastAPI app instance\napp = FastAPI(title=\"My MCP Server\", version=\"1.0\")\n\n# 2. Mount the FastMCP server at /sse endpoint\napp = mcp_server.mount_to_app(app)\n\n# Optional: Add a root endpoint for basic health check\n@app.get(\"/\", tags=[\"General\"])\nasync def read_root():\n    return {\"message\": \"MCP SSE Server is running. Connect via /sse.\"}\n\n# --- Main Execution ---\n\nasync def start_server(host=\"127.0.0.1\", port=8765):\n    \"\"\"Configures and runs the Uvicorn server.\"\"\"\n    logger.info(\"Configuring Uvicorn...\")\n    config = uvicorn.Config(\n        app=app, # Run the FastAPI app instance\n        host=host,\n        port=port,\n        log_level=\"debug\" # Use debug for detailed Uvicorn/ASGI logs\n    )\n    server = uvicorn.Server(config)\n\n    # **CRITICAL for Testing:** Print the URL *before* starting the server\n    # Allows test harnesses to know where to connect.\n    sys.stderr.write(f\"SSE_SERVER_URL=http://{host}:{port}\\n\")\n    sys.stderr.flush()\n\n    logger.info(f\"Starting Uvicorn server for FastAPI+MCP on {host}:{port}\")\n    await server.serve() # This blocks until shutdown\n\nif __name__ == \"__main__\":\n    import argparse\n\n    # Parse command line arguments\n    parser = argparse.ArgumentParser(description=\"Run MCP SSE server\")\n    parser.add_argument(\"--host\", default=\"127.0.0.1\", help=\"Host to bind to\")\n    parser.add_argument(\"--port\", type=int, default=8765, help=\"Port to listen on\")\n    args = parser.parse_args()\n\n    logger.info(\"Starting main function\")\n    try:\n        asyncio.run(start_server(args.host, args.port))\n    except KeyboardInterrupt:\n        logger.info(\"Keyboard interrupt received, shutting down\")\n    except Exception as e:\n        logger.error(f\"Unhandled exception in top-level: {e}\", exc_info=True)\n        sys.exit(1)\n</code></pre> <p>Running the SSE Server: <pre><code>python src/my_mcp_server.py --host 0.0.0.0 --port 8000\n</code></pre></p>"},{"location":"guides/mcp_developer_guide/#42-stdio-transport-for-local-inter-process-communication","title":"4.2. Stdio Transport (For Local Inter-Process Communication)","text":"<p>For stdio transport, the approach is similar to previous versions:</p> <pre><code># Example: src/my_mcp_server.py (modified main section)\n\n# (Keep FastMCP instance and tool definitions from above)\n\nasync def start_stdio_server():\n    \"\"\"Runs the MCP server over stdio.\"\"\"\n    # Signal readiness BEFORE running the server loop\n    # Use stderr for signals, as stdout is used for MCP JSON messages\n    sys.stderr.write(\"STDIO_SERVER_READY\\n\")\n    sys.stderr.flush()\n\n    logger.info(\"Starting MCP server over stdio\")\n    try:\n        await mcp_server.run_stdio()\n    except Exception as e:\n        logger.error(f\"Error in stdio server: {e}\", exc_info=True)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    if len(sys.argv) &gt; 1 and sys.argv[1] == \"--stdio\":\n        try:\n            asyncio.run(start_stdio_server())\n        except KeyboardInterrupt:\n            logger.info(\"Keyboard interrupt received, shutting down stdio server\")\n        except Exception as e:\n            logger.error(f\"Unhandled exception in stdio server: {e}\", exc_info=True)\n            sys.exit(1)\n    else:\n        # Default to SSE server\n        # (SSE server code from previous section)\n</code></pre> <p>Running the Stdio Server: <pre><code>python src/my_mcp_server.py --stdio\n</code></pre></p>"},{"location":"guides/mcp_developer_guide/#5-creating-an-mcp-client","title":"5. Creating an MCP Client","text":"<p>Clients connect to servers and call tools.</p>"},{"location":"guides/mcp_developer_guide/#51-sse-client","title":"5.1. SSE Client","text":"<pre><code># Example: src/my_mcp_client.py\nimport asyncio\nimport logging\nimport sys\nimport json\n\nfrom mcp.client.session import ClientSession\nfrom mcp.client.sse import sse_client\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n    handlers=[logging.StreamHandler(sys.stderr)],\n)\nlogger = logging.getLogger(\"MyMCPClient\")\n\nasync def call_echo_tool(server_url: str, message: str, timeout: float = 30.0):\n    \"\"\"Call the echo tool on the server.\n\n    Args:\n        server_url: URL of the SSE server, e.g., http://localhost:8765/sse\n        message: Message to echo\n        timeout: Timeout in seconds\n    \"\"\"\n    logger.info(f\"Connecting to server: {server_url}\")\n\n    try:\n        # Connect to the SSE server\n        async with sse_client(server_url) as (read_stream, write_stream):\n            # Create a session\n            async with ClientSession(read_stream, write_stream) as session:\n                # Initialize the session\n                logger.info(\"Initializing session\")\n                await asyncio.wait_for(session.initialize(), timeout=timeout)\n                logger.info(\"Session initialized successfully\")\n\n                # Call the echo tool\n                logger.info(f\"Calling echo tool with message: {message}\")\n                result = await asyncio.wait_for(\n                    session.call_tool(\"echo\", {\"message\": message}),\n                    timeout=timeout\n                )\n\n                # Check for errors\n                if result.isError:\n                    logger.error(f\"Tool call failed: {result}\")\n                    print(f\"Error: {result}\")\n                    return\n\n                # Process the response\n                if result.content and len(result.content) &gt; 0:\n                    response_text = result.content[0].text\n                    try:\n                        response_data = json.loads(response_text)\n                        logger.info(f\"Got response: {response_data}\")\n                        print(f\"Echo response: {response_data}\")\n                    except json.JSONDecodeError:\n                        logger.error(f\"Failed to parse response JSON: {response_text}\")\n                        print(f\"Invalid response: {response_text}\")\n                else:\n                    logger.warning(\"Empty response from server\")\n                    print(\"Empty response\")\n\n    except asyncio.TimeoutError:\n        logger.error(f\"Operation timed out after {timeout} seconds\")\n        print(f\"Error: Timeout after {timeout} seconds\")\n    except Exception as e:\n        logger.error(f\"Error: {e}\", exc_info=True)\n        print(f\"Error: {e}\")\n\nasync def main():\n    # Parse command line arguments\n    import argparse\n    parser = argparse.ArgumentParser(description=\"MCP SSE Client\")\n    parser.add_argument(\"--server\", default=\"http://localhost:8765/sse\", help=\"Server URL\")\n    parser.add_argument(\"--message\", default=\"Hello World\", help=\"Message to echo\")\n    parser.add_argument(\"--timeout\", type=float, default=30.0, help=\"Timeout in seconds\")\n    args = parser.parse_args()\n\n    # Call the echo tool\n    await call_echo_tool(args.server, args.message, args.timeout)\n\nif __name__ == \"__main__\":\n    try:\n        asyncio.run(main())\n    except KeyboardInterrupt:\n        logger.info(\"Keyboard interrupt received, shutting down client\")\n    except Exception as e:\n        logger.error(f\"Unhandled exception in top-level: {e}\", exc_info=True)\n        sys.exit(1)\n</code></pre>"},{"location":"guides/mcp_developer_guide/#52-stdio-client","title":"5.2. Stdio Client","text":"<pre><code># Example: src/my_mcp_stdio_client.py\nimport asyncio\nimport logging\nimport sys\nimport json\nimport subprocess\nfrom typing import Tuple, Optional\n\nfrom mcp.client.session import ClientSession\nfrom mcp.client.stdio import stdio_client\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n    handlers=[logging.StreamHandler(sys.stderr)],\n)\nlogger = logging.getLogger(\"MyMCPStdioClient\")\n\nasync def start_server_process(server_cmd: list[str]) -&gt; Tuple[subprocess.Popen, bool]:\n    \"\"\"Start the server process and wait for it to be ready.\n\n    Args:\n        server_cmd: Command to start the server\n\n    Returns:\n        Tuple of (process, is_ready)\n    \"\"\"\n    logger.info(f\"Starting server process: {' '.join(server_cmd)}\")\n\n    # Start the server process\n    process = subprocess.Popen(\n        server_cmd,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=False,  # Binary mode for better pipe handling\n    )\n\n    # Wait for the ready signal on stderr\n    is_ready = False\n    ready_timeout = 10.0  # seconds\n\n    async def read_stderr():\n        nonlocal is_ready\n        while process.poll() is None:  # While process is running\n            try:\n                line = process.stderr.readline()\n                if line:\n                    line_str = line.decode('utf-8', errors='replace').strip()\n                    logger.debug(f\"Server stderr: {line_str}\")\n                    if \"STDIO_SERVER_READY\" in line_str:\n                        logger.info(\"Server signaled ready\")\n                        is_ready = True\n                        break\n            except Exception as e:\n                logger.error(f\"Error reading stderr: {e}\")\n                break\n\n    # Run stderr reader with timeout\n    stderr_task = asyncio.create_task(read_stderr())\n    try:\n        await asyncio.wait_for(stderr_task, timeout=ready_timeout)\n    except asyncio.TimeoutError:\n        logger.warning(f\"Timed out waiting for server ready signal after {ready_timeout}s\")\n        # Continue anyway, as the server might still be usable\n\n    # Check if the process is still running\n    if process.poll() is not None:\n        logger.error(f\"Server process exited prematurely with code {process.returncode}\")\n        return process, False\n\n    return process, is_ready\n\nasync def call_echo_tool_stdio(server_cmd: list[str], message: str, timeout: float = 30.0):\n    \"\"\"Call the echo tool using stdio transport.\n\n    Args:\n        server_cmd: Command to start the server\n        message: Message to echo\n        timeout: Timeout in seconds\n    \"\"\"\n    # Start the server process\n    process, is_ready = await start_server_process(server_cmd)\n\n    if not is_ready:\n        logger.warning(\"Server may not be ready, but attempting to connect anyway\")\n\n    try:\n        # Connect to the stdio server\n        logger.info(\"Connecting to stdio server\")\n        async with stdio_client(process.stdout, process.stdin) as (read_stream, write_stream):\n            # Create a session\n            async with ClientSession(read_stream, write_stream) as session:\n                # Initialize the session\n                logger.info(\"Initializing session\")\n                await asyncio.wait_for(session.initialize(), timeout=timeout)\n                logger.info(\"Session initialized successfully\")\n\n                # Call the echo tool\n                logger.info(f\"Calling echo tool with message: {message}\")\n                result = await asyncio.wait_for(\n                    session.call_tool(\"echo\", {\"message\": message}),\n                    timeout=timeout\n                )\n\n                # Check for errors\n                if result.isError:\n                    logger.error(f\"Tool call failed: {result}\")\n                    print(f\"Error: {result}\")\n                    return\n\n                # Process the response\n                if result.content and len(result.content) &gt; 0:\n                    response_text = result.content[0].text\n                    try:\n                        response_data = json.loads(response_text)\n                        logger.info(f\"Got response: {response_data}\")\n                        print(f\"Echo response: {response_data}\")\n                    except json.JSONDecodeError:\n                        logger.error(f\"Failed to parse response JSON: {response_text}\")\n                        print(f\"Invalid response: {response_text}\")\n                else:\n                    logger.warning(\"Empty response from server\")\n                    print(\"Empty response\")\n\n    except asyncio.TimeoutError:\n        logger.error(f\"Operation timed out after {timeout} seconds\")\n        print(f\"Error: Timeout after {timeout} seconds\")\n    except Exception as e:\n        logger.error(f\"Error: {e}\", exc_info=True)\n        print(f\"Error: {e}\")\n    finally:\n        # Terminate the server process\n        if process.poll() is None:  # If still running\n            logger.info(\"Terminating server process\")\n            process.terminate()\n            try:\n                process.wait(timeout=5.0)  # Wait for graceful termination\n            except subprocess.TimeoutExpired:\n                logger.warning(\"Server process did not terminate gracefully, killing\")\n                process.kill()\n\nasync def main():\n    # Parse command line arguments\n    import argparse\n    parser = argparse.ArgumentParser(description=\"MCP Stdio Client\")\n    parser.add_argument(\"--server-cmd\", default=\"python src/my_mcp_server.py --stdio\",\n                        help=\"Command to start the server\")\n    parser.add_argument(\"--message\", default=\"Hello World\", help=\"Message to echo\")\n    parser.add_argument(\"--timeout\", type=float, default=30.0, help=\"Timeout in seconds\")\n    args = parser.parse_args()\n\n    # Call the echo tool\n    server_cmd = args.server_cmd.split()\n    await call_echo_tool_stdio(server_cmd, args.message, args.timeout)\n\nif __name__ == \"__main__\":\n    try:\n        asyncio.run(main())\n    except KeyboardInterrupt:\n        logger.info(\"Keyboard interrupt received, shutting down client\")\n    except Exception as e:\n        logger.error(f\"Unhandled exception in top-level: {e}\", exc_info=True)\n        sys.exit(1)\n</code></pre>"},{"location":"guides/mcp_developer_guide/#6-openmas-integration","title":"6. OpenMAS Integration","text":"<p>OpenMAS provides a high-level abstraction over MCP through its communicator classes.</p>"},{"location":"guides/mcp_developer_guide/#61-using-mcpssecommunicator","title":"6.1. Using McpSseCommunicator","text":"<pre><code>from openmas.communication.mcp.sse_communicator import McpSseCommunicator\n\n# Server mode\nserver_communicator = McpSseCommunicator(\n    agent_name=\"tool_provider\",\n    service_urls={},  # Server doesn't need service URLs\n    server_mode=True,\n    http_port=8080,\n    http_host=\"0.0.0.0\",\n    server_instructions=\"A service that provides text processing tools\",\n)\n\n# Register a tool\nawait server_communicator.register_tool(\n    name=\"process_text\",\n    description=\"Process text by converting to uppercase and counting words\",\n    function=async_process_text_handler,\n)\n\n# Client mode\nclient_communicator = McpSseCommunicator(\n    agent_name=\"tool_user\",\n    service_urls={\"tool_provider\": \"http://localhost:8080/sse\"},\n    server_mode=False,\n)\n\n# Call a tool\nresult = await client_communicator.call_tool(\n    target_service=\"tool_provider\",\n    tool_name=\"process_text\",\n    arguments={\"text\": \"Hello, world!\"},\n    timeout=10.0,\n)\n</code></pre>"},{"location":"guides/mcp_developer_guide/#62-using-mcpstdiocommunicator","title":"6.2. Using McpStdioCommunicator","text":"<pre><code>from openmas.communication.mcp.stdio_communicator import McpStdioCommunicator\n\n# Server mode\nserver_communicator = McpStdioCommunicator(\n    agent_name=\"tool_provider\",\n    service_urls={},  # Server doesn't need service URLs\n)\n\n# Register a tool\nawait server_communicator.register_tool(\n    name=\"process_text\",\n    description=\"Process text by converting to uppercase and counting words\",\n    function=async_process_text_handler,\n)\n\n# Client mode (assumes server is started separately)\nclient_communicator = McpStdioCommunicator(\n    agent_name=\"tool_user\",\n    service_urls={\"tool_provider\": \"python -m agents.tool_provider.agent\"},\n)\n\n# Call a tool\nresult = await client_communicator.call_tool(\n    target_service=\"tool_provider\",\n    tool_name=\"process_text\",\n    arguments={\"text\": \"Hello, world!\"},\n    timeout=10.0,\n)\n</code></pre>"},{"location":"guides/mcp_developer_guide/#7-best-practices-for-mcp-171","title":"7. Best Practices for MCP 1.7.1","text":""},{"location":"guides/mcp_developer_guide/#71-tool-implementation","title":"7.1. Tool Implementation","text":"<ol> <li>Return Format: Always return a list of TextContent objects.</li> <li>Error Handling: Handle errors within the tool and return appropriate error messages as TextContent rather than raising exceptions.</li> <li>Argument Extraction: Be flexible when extracting arguments from the context - check both direct arguments and content arrays.</li> <li>Logging: Add detailed logging to aid debugging.</li> </ol>"},{"location":"guides/mcp_developer_guide/#72-connection-management","title":"7.2. Connection Management","text":"<ol> <li>Timeouts: Always use timeouts for network operations to prevent hanging.</li> <li>Graceful Shutdown: Properly close connections and stop servers to prevent resource leaks.</li> <li>Connection Pooling: For high-traffic applications, consider implementing connection pooling.</li> <li>Error Recovery: Implement retry logic for transient errors.</li> </ol>"},{"location":"guides/mcp_developer_guide/#73-testing","title":"7.3. Testing","text":"<ol> <li>Mock Testing: Use <code>MockCommunicator</code> for unit tests.</li> <li>Integration Testing: Create real network tests for end-to-end validation.</li> <li>Test Harnesses: Build test harnesses that simulate different failure modes.</li> <li>Logging Verification: Verify log outputs to ensure proper operation.</li> </ol>"},{"location":"guides/mcp_developer_guide/#8-troubleshooting","title":"8. Troubleshooting","text":""},{"location":"guides/mcp_developer_guide/#81-common-issues","title":"8.1. Common Issues","text":"<ol> <li>Connection Timeouts: Check firewall settings and ensure the server is running.</li> <li>Tool Not Found: Verify that the tool is registered with the exact name you're trying to call.</li> <li>Argument Format Errors: Ensure you're passing the correct argument format.</li> <li>Event Loop Errors: These can occur during cleanup and are typically harmless but indicate a resource wasn't closed properly.</li> </ol>"},{"location":"guides/mcp_developer_guide/#82-debugging-techniques","title":"8.2. Debugging Techniques","text":"<ol> <li>Enable DEBUG Logging: Set logging level to DEBUG to see detailed info about MCP operations.</li> <li>Use MCP Inspector: The MCP CLI includes an inspector tool for debugging.</li> <li>Check Network Traffic: Use tools like Wireshark to inspect network traffic for SSE transport.</li> <li>Validate JSON: Ensure all JSON payloads are valid.</li> </ol>"},{"location":"guides/mcp_developer_guide/#9-advanced-topics","title":"9. Advanced Topics","text":""},{"location":"guides/mcp_developer_guide/#91-concurrent-tool-calls","title":"9.1. Concurrent Tool Calls","text":"<p>MCP 1.7.1 improves handling of concurrent connections. Here's a pattern for making concurrent tool calls:</p> <pre><code>async def call_tools_concurrently(communicator, target_service, tools_and_args):\n    \"\"\"Call multiple tools concurrently.\n\n    Args:\n        communicator: The MCP communicator\n        target_service: Target service name\n        tools_and_args: List of (tool_name, arguments) tuples\n\n    Returns:\n        Dictionary mapping tool names to results\n    \"\"\"\n    # Create tasks for each tool call\n    tasks = {\n        tool_name: asyncio.create_task(\n            communicator.call_tool(\n                target_service=target_service,\n                tool_name=tool_name,\n                arguments=args,\n            )\n        )\n        for tool_name, args in tools_and_args\n    }\n\n    # Wait for all tasks to complete\n    results = {}\n    for tool_name, task in tasks.items():\n        try:\n            results[tool_name] = await task\n        except Exception as e:\n            results[tool_name] = {\"error\": str(e)}\n\n    return results\n</code></pre>"},{"location":"guides/mcp_developer_guide/#92-custom-transport-implementation","title":"9.2. Custom Transport Implementation","text":"<p>If you need a custom transport mechanism beyond SSE and stdio, you can implement your own transport:</p> <ol> <li>Create classes that implement the <code>ReadStream</code> and <code>WriteStream</code> interfaces.</li> <li>Implement a client connector function similar to <code>sse_client</code> or <code>stdio_client</code>.</li> <li>Create a server transport similar to <code>SseServerTransport</code>.</li> </ol>"},{"location":"guides/mcp_developer_guide/#10-future-directions","title":"10. Future Directions","text":"<p>MCP continues to evolve. Here are some areas to watch:</p> <ol> <li>Better Error Handling: Improved error handling and reporting.</li> <li>Enhanced Tool Argument Schema: More robust tool argument validation.</li> <li>WebSocket Transport: Potential support for WebSocket as an alternative to SSE.</li> <li>Performance Optimizations: Ongoing improvements to connection handling and message serialization.</li> </ol> <p>Keep an eye on the official MCP documentation and GitHub repositories for updates.</p>"},{"location":"guides/mcp_developer_guide/#11-further-resources","title":"11. Further Resources","text":"<ul> <li>Complete MCP Documentation</li> <li>MCP Python SDK GitHub</li> <li>OpenMAS MCP Integration Guide</li> <li>MCP SSE Tool Call Tutorial</li> <li>MCP Stdio Tool Call Tutorial</li> </ul>"},{"location":"guides/mcp_integration/","title":"MCP Integration Guide","text":"<p>This guide explains how to use OpenMAS with MCP (Model Context Protocol) version 1.7.1. MCP is a protocol that enables standardized communication between language models, tools, and other services.</p>"},{"location":"guides/mcp_integration/#mcp-171-features","title":"MCP 1.7.1 Features","text":"<p>OpenMAS integrates with MCP 1.7.1, which provides:</p> <ul> <li>Stable SSE transport implementation</li> <li>Robust connection resilience and error handling</li> <li>Efficient serialization of complex data types</li> <li>Comprehensive support for tool calling with error handling</li> </ul>"},{"location":"guides/mcp_integration/#prerequisites","title":"Prerequisites","text":"<p>To use MCP with OpenMAS, you need to install the <code>mcp</code> package:</p> <pre><code>poetry add mcp==1.7.1\n</code></pre> <p>Or if you're installing OpenMAS with poetry:</p> <pre><code>poetry install --extras mcp\n</code></pre>"},{"location":"guides/mcp_integration/#supported-transports","title":"Supported Transports","text":"<p>MCP supports two primary transport mechanisms:</p> <ol> <li>SSE (Server-Sent Events) - Used for HTTP-based communication between agents</li> <li>STDIO - Used for direct pipe-based communication, typically for local processes</li> </ol>"},{"location":"guides/mcp_integration/#creating-mcp-communicators","title":"Creating MCP Communicators","text":""},{"location":"guides/mcp_integration/#sse-communicator-server-mode","title":"SSE Communicator (Server Mode)","text":"<pre><code>from openmas.communication.mcp.sse_communicator import McpSseCommunicator\n\n# Create a server-mode communicator\ncommunicator = McpSseCommunicator(\n    agent_name=\"tool_provider\",\n    service_urls={},  # Server doesn't need service URLs\n    server_mode=True,\n    http_port=8081,  # Optional: specify a port (defaults to 8080)\n)\n</code></pre>"},{"location":"guides/mcp_integration/#sse-communicator-client-mode","title":"SSE Communicator (Client Mode)","text":"<pre><code>from openmas.communication.mcp.sse_communicator import McpSseCommunicator\n\n# Create a client-mode communicator\ncommunicator = McpSseCommunicator(\n    agent_name=\"tool_user\",\n    service_urls={\"service_name\": \"http://localhost:8081\"},\n    server_mode=False,  # Client mode\n)\n</code></pre>"},{"location":"guides/mcp_integration/#stdio-communicator","title":"STDIO Communicator","text":"<pre><code>from openmas.communication.mcp.stdio_communicator import McpStdioCommunicator\n\n# Create a STDIO communicator\ncommunicator = McpStdioCommunicator(\n    agent_name=\"tool_provider\",\n    service_urls={},  # Not used for STDIO\n)\n</code></pre>"},{"location":"guides/mcp_integration/#registering-and-using-tools","title":"Registering and Using Tools","text":""},{"location":"guides/mcp_integration/#registering-a-tool-server-side","title":"Registering a Tool (Server-side)","text":"<pre><code>async def process_text_handler(payload: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Process text by converting to uppercase and counting words.\"\"\"\n    # Get the input text from the payload\n    text = payload.get(\"text\", \"\")\n\n    # Process the text\n    processed_text = text.upper()\n    word_count = len(text.split())\n\n    # Return the result\n    return {\n        \"processed_text\": processed_text,\n        \"word_count\": word_count,\n        \"status\": \"success\"\n    }\n\n# Register the tool with the communicator\nawait communicator.register_tool(\n    name=\"process_text\",\n    description=\"Process text input by converting to uppercase and counting words\",\n    function=process_text_handler,\n)\n</code></pre>"},{"location":"guides/mcp_integration/#calling-a-tool-client-side","title":"Calling a Tool (Client-side)","text":"<pre><code># Create a payload for the tool\npayload = {\n    \"text\": \"Hello, this is a test message.\",\n    # Optionally add a content field in MCP 1.7.1 format\n    \"content\": [{\"type\": \"text\", \"text\": \"Hello, this is a test message.\"}],\n}\n\n# Call the tool\nresult = await communicator.call_tool(\n    target_service=\"tool_provider\",\n    tool_name=\"process_text\",\n    arguments=payload,\n    timeout=10.0,  # Optional timeout in seconds\n)\n</code></pre>"},{"location":"guides/mcp_integration/#error-handling","title":"Error Handling","text":"<p>MCP 1.7.1 provides improved error handling. Here's how to handle errors properly:</p> <pre><code>from openmas.exceptions import CommunicationError\n\ntry:\n    result = await communicator.call_tool(\n        target_service=\"tool_provider\",\n        tool_name=\"process_text\",\n        arguments=payload,\n    )\n    # Process successful result\nexcept asyncio.TimeoutError:\n    # Handle timeout\n    print(\"Tool call timed out\")\nexcept CommunicationError as e:\n    # Handle communication error\n    print(f\"Communication error: {e}\")\nexcept Exception as e:\n    # Handle other errors\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"guides/mcp_integration/#complete-example","title":"Complete Example","text":"<p>See the following examples for complete implementations:</p> <ol> <li>SSE Example: <code>examples/example_08_mcp/01_mcp_sse_tool_call/</code></li> <li>STDIO Example: <code>examples/example_08_mcp/02_mcp_stdio_tool_call/</code></li> </ol>"},{"location":"guides/mcp_integration/#best-practices","title":"Best Practices","text":"<ol> <li>Proper Initialization: Always initialize and start your communicator before using it.</li> <li>Error Handling: Add appropriate error handling for all tool calls.</li> <li>Resource Cleanup: Ensure proper cleanup of resources with try/finally blocks.</li> <li>Timeout Handling: Set appropriate timeouts for tool calls to prevent hanging.</li> <li>Graceful Shutdown: Always shut down communicators properly when your agent stops.</li> </ol>"},{"location":"guides/mcp_integration/#known-limitations","title":"Known Limitations","text":"<ol> <li>SSE connections can be sensitive to network issues - implement retry logic for production systems.</li> <li>The <code>test_openmas_mcp_sse_integration</code> test is currently skipped due to SSE endpoint compatibility issues.</li> <li>The <code>test_concurrent_sse_connections</code> test is skipped due to asyncio event loop issues that need to be addressed.</li> </ol>"},{"location":"guides/mcp_integration/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>404 Not Found errors: Ensure the server is running and the URL is correct.</li> <li>Connection refused: Check that the server is running and the port is correct.</li> <li>Event loop is closed errors: These can occur during cleanup. They're typically harmless but indicate a resource wasn't closed properly.</li> </ol>"},{"location":"guides/mcp_integration/#future-improvements","title":"Future Improvements","text":"<ol> <li>Enhanced resilience for SSE connections with automatic reconnection.</li> <li>Better handling of concurrent connections.</li> <li>More comprehensive end-to-end tests.</li> </ol>"},{"location":"guides/mcp_sse_tool_call_tutorial/","title":"MCP SSE Tool Call Tutorial","text":"<p>This tutorial walks through implementing MCP tool calls using Server-Sent Events (SSE) transport in OpenMAS. The SSE transport allows for network-based communication between agents, enabling more flexible deployment scenarios than stdio-based communication.</p>"},{"location":"guides/mcp_sse_tool_call_tutorial/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have:</p> <ol> <li>OpenMAS installed</li> <li>Python 3.10 or later</li> <li>Dependencies: <code>mcp&gt;=1.7.1</code>, <code>aiohttp</code>, <code>httpx</code></li> <li>A basic understanding of MCP concepts (see the MCP Developer Guide)</li> <li>An available HTTP port (this tutorial uses 8000)</li> </ol>"},{"location":"guides/mcp_sse_tool_call_tutorial/#overview","title":"Overview","text":"<p>We'll create a simple example with two agents:</p> <ol> <li>Tool Provider Agent: Starts an HTTP server with an SSE endpoint that exposes the <code>process_text</code> tool</li> <li>Tool User Agent: Connects to the provider via HTTP and calls the tool to process text data</li> </ol>"},{"location":"guides/mcp_sse_tool_call_tutorial/#project-structure","title":"Project Structure","text":"<p>The full example is available in the repository at <code>examples/example_08_mcp/01_mcp_sse_tool_call/</code>.</p> <pre><code>01_mcp_sse_tool_call/\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 tool_provider/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 agent.py\n\u2502   \u251c\u2500\u2500 tool_user/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 agent.py\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 openmas_project.yml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 test_example.py\n</code></pre>"},{"location":"guides/mcp_sse_tool_call_tutorial/#step-1-create-the-project-configuration","title":"Step 1: Create the Project Configuration","text":"<p>First, create an <code>openmas_project.yml</code> file with the following configuration:</p> <pre><code>name: example_08_mcp_sse_tool_call\nversion: 0.1.0\ndescription: \"Example demonstrating MCP tool calls over Server-Sent Events (SSE) using MCP 1.7.1\"\n\n# Define the available agents\nagents:\n  tool_provider: \"agents/tool_provider\"\n  tool_user: \"agents/tool_user\"\n\n# Default configuration for all agents\ndefault_config:\n  log_level: INFO\n\n# Default communicator settings\ncommunicator_defaults:\n  type: mcp-sse\n  options:\n    server_mode: false\n\n# Agent-specific configurations\nagent_configs:\n  # Tool provider config - run in server mode to expose tools via HTTP\n  tool_provider:\n    communicator_options:\n      server_mode: true\n      server_instructions: \"A service that processes text using an MCP tool\"\n      http_host: \"127.0.0.1\"\n      http_port: 8000\n\n  # Tool user config - client mode with service URLs to connect to the provider\n  tool_user:\n    service_urls:\n      tool_provider: \"http://127.0.0.1:8000/sse\"\n</code></pre> <p>Key points: - The communicator type is <code>mcp-sse</code> for Server-Sent Events transport - The tool provider runs in server mode on port 8000 - The tool user connects via HTTP URL, specifically to the <code>/sse</code> endpoint - Note the <code>http_host</code> and <code>http_port</code> fields align with MCP 1.7.1 naming conventions</p>"},{"location":"guides/mcp_sse_tool_call_tutorial/#step-2-implement-the-tool-provider-agent","title":"Step 2: Implement the Tool Provider Agent","text":"<p>Create the tool provider agent in <code>agents/tool_provider/agent.py</code>:</p> <pre><code>\"\"\"Tool provider agent that registers and exposes an MCP tool via SSE.\"\"\"\n\nimport asyncio\nimport signal\nfrom typing import Any, Dict\n\nfrom openmas.agent import BaseAgent\nfrom openmas.logging import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass ToolProviderAgent(BaseAgent):\n    \"\"\"Agent that provides an MCP tool over SSE.\n\n    This agent registers a tool called \"process_text\" that handles\n    incoming data and returns a processed result.\n\n    Unlike stdio-based tools, this provider runs as an HTTP server that\n    clients can connect to via SSE. The server will continue running\n    until explicitly shut down.\n    \"\"\"\n\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the agent by registering the MCP tool.\"\"\"\n        logger.info(\"Setting up ToolProviderAgent\")\n\n        # Register signal handlers for graceful shutdown\n        for sig in (signal.SIGINT, signal.SIGTERM):\n            self.loop.add_signal_handler(sig, lambda s=sig: asyncio.create_task(self._handle_signal(s)))\n\n        # Register the MCP tool\n        tool_name = \"process_text\"\n\n        try:\n            await self.communicator.register_tool(\n                name=tool_name,\n                description=\"Process incoming text and return the result\",\n                function=self.process_text_handler,\n            )\n            logger.info(f\"Registered MCP tool: {tool_name}\")\n\n            # Get server details if available\n            if hasattr(self.communicator, \"get_server_info\"):\n                server_info = await self.communicator.get_server_info()\n                if server_info:\n                    logger.info(f\"SSE Server running at: {server_info.get('url', 'unknown')}\")\n\n        except Exception as e:\n            logger.error(f\"Error registering tool: {e}\")\n            raise\n\n        logger.info(\"ToolProviderAgent setup complete\")\n\n    async def process_text_handler(self, payload: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle incoming tool calls by processing the provided text.\n\n        Args:\n            payload: Dictionary containing the text to process\n\n        Returns:\n            Dictionary containing the processed result\n        \"\"\"\n        logger.info(f\"Tool handler received payload: {payload}\")\n\n        # MCP 1.7.1 can send arguments in different ways, so check both formats\n        text = None\n\n        # Check for direct text field\n        if \"text\" in payload:\n            text = payload[\"text\"]\n            logger.info(\"Found text in direct text field\")\n\n        # Check for content array format (MCP 1.7.1 style)\n        elif \"content\" in payload and isinstance(payload[\"content\"], list) and len(payload[\"content\"]) &gt; 0:\n            content_item = payload[\"content\"][0]\n            if isinstance(content_item, dict) and \"text\" in content_item:\n                text = content_item[\"text\"]\n                logger.info(\"Found text in content[0].text\")\n            elif hasattr(content_item, \"text\"):\n                # Handle MCP TextContent object\n                text = content_item.text\n                logger.info(\"Found text in content[0].text object\")\n\n        # Process the text if found\n        if text is None:\n            result = {\"error\": \"No text field found in payload\", \"status\": \"error\"}\n            logger.error(f\"Missing text field in payload: {payload}\")\n        else:\n            # Simple processing - convert to uppercase and count words\n            processed_text = text.upper()\n            word_count = len(text.split())\n            result = {\"processed_text\": processed_text, \"word_count\": word_count, \"status\": \"success\"}\n\n        logger.info(f\"Tool handler returning result: {result}\")\n        return result\n\n    async def run(self) -&gt; None:\n        \"\"\"Run the agent.\n\n        For SSE server, we need to keep the agent alive while the server is running.\n        This method will block indefinitely until the server is shut down.\n        \"\"\"\n        logger.info(\"ToolProviderAgent running, waiting for tool calls via SSE\")\n\n        # Create an event to signal shutdown\n        self._shutdown_event = asyncio.Event()\n\n        # Wait for the shutdown signal\n        try:\n            await self._shutdown_event.wait()\n            logger.info(\"Shutdown event received, preparing to stop\")\n        except asyncio.CancelledError:\n            logger.info(\"Run method cancelled, preparing to stop\")\n\n    async def _handle_signal(self, sig: signal.Signals) -&gt; None:\n        \"\"\"Handle termination signals for graceful shutdown.\n\n        Args:\n            sig: The signal received\n        \"\"\"\n        logger.info(f\"Received signal {sig.name}, initiating shutdown\")\n        if hasattr(self, \"_shutdown_event\"):\n            self._shutdown_event.set()\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Shut down the agent.\n\n        For SSE servers, we need to properly stop the HTTP server.\n        \"\"\"\n        logger.info(\"ToolProviderAgent shutting down\")\n\n        # If using a real MCP communicator with a server, properly shut down the server\n        if hasattr(self.communicator, \"stop_server\"):\n            logger.info(\"Stopping SSE server\")\n            try:\n                await self.communicator.stop_server()\n                logger.info(\"SSE server stopped successfully\")\n            except Exception as e:\n                logger.error(f\"Error stopping SSE server: {e}\")\n\n        # Set the shutdown event if it exists\n        if hasattr(self, \"_shutdown_event\"):\n            self._shutdown_event.set()\n</code></pre> <p>Don't forget to create <code>agents/tool_provider/__init__.py</code>:</p> <pre><code>\"\"\"Tool provider agent for MCP SSE.\"\"\"\n\nfrom .agent import ToolProviderAgent\n</code></pre>"},{"location":"guides/mcp_sse_tool_call_tutorial/#step-3-implement-the-tool-user-agent","title":"Step 3: Implement the Tool User Agent","text":"<p>Create the tool user agent in <code>agents/tool_user/agent.py</code>:</p> <pre><code>\"\"\"Tool user agent that calls an MCP tool via SSE.\"\"\"\n\nimport asyncio\nfrom typing import Any, Dict, Optional\n\nfrom openmas.agent import BaseAgent\nfrom openmas.logging import get_logger\nfrom openmas.exceptions import CommunicationError\n\nlogger = get_logger(__name__)\n\n\nclass ToolUserAgent(BaseAgent):\n    \"\"\"Agent that uses an MCP tool over SSE.\n\n    This agent calls the \"process_text\" tool provided by the ToolProviderAgent,\n    sends text data, and processes the result.\n    \"\"\"\n\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the agent.\"\"\"\n        logger.info(\"Setting up ToolUserAgent\")\n        self.result: Optional[Dict[str, Any]] = None\n        self.error: Optional[Dict[str, str]] = None\n        logger.info(\"ToolUserAgent setup complete\")\n\n    async def run(self) -&gt; None:\n        \"\"\"Run the agent by calling the process_text tool.\"\"\"\n        logger.info(\"ToolUserAgent running, calling process_text tool\")\n\n        # Prepare the text to process\n        test_text = \"Hello, this is a sample text that needs processing.\"\n\n        try:\n            # Call the process_text tool with timeout protection\n            result = await self._call_process_text(test_text)\n\n            # Store the result for verification\n            self.result = result\n\n            # Log the result\n            logger.info(f\"Process text tool result: {result}\")\n\n            if result.get(\"status\") == \"success\":\n                logger.info(f\"Successfully processed text: {result.get('processed_text')}\")\n                logger.info(f\"Word count: {result.get('word_count')}\")\n            else:\n                logger.error(f\"Tool call failed: {result.get('error')}\")\n\n        except Exception as e:\n            logger.error(f\"Error during tool call: {e}\")\n            self.error = {\"error\": str(e), \"status\": \"error\"}\n\n        logger.info(\"ToolUserAgent completed its run method\")\n\n    async def _call_process_text(self, text: str, timeout: float = 10.0) -&gt; Dict[str, Any]:\n        \"\"\"Call the process_text tool with timeout protection.\n\n        Args:\n            text: The text to process\n            timeout: Timeout in seconds\n\n        Returns:\n            The result from the tool\n\n        Raises:\n            CommunicationError: If there's an error calling the tool\n            asyncio.TimeoutError: If the call times out\n        \"\"\"\n        logger.info(f\"Calling process_text tool with text: {text}\")\n\n        # Create a payload that works with MCP 1.7.1\n        # Include both direct text field and content array format\n        payload = {\n            \"text\": text,\n            # Add content array for MCP 1.7.1 compatibility\n            \"content\": [{\"type\": \"text\", \"text\": text}]\n        }\n\n        try:\n            # Call the tool with timeout protection\n            result = await asyncio.wait_for(\n                self.communicator.call_tool(\n                    target_service=\"tool_provider\",\n                    tool_name=\"process_text\",\n                    arguments=payload,\n                ),\n                timeout=timeout,\n            )\n\n            logger.info(f\"Received raw result: {result}\")\n            return result\n\n        except asyncio.TimeoutError:\n            error_msg = f\"Tool call timed out after {timeout} seconds\"\n            logger.error(error_msg)\n            raise\n        except Exception as e:\n            error_msg = f\"Error calling process_text tool: {e}\"\n            logger.error(error_msg)\n            raise CommunicationError(error_msg)\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Shut down the agent.\"\"\"\n        logger.info(\"ToolUserAgent shutting down\")\n</code></pre> <p>Don't forget to create <code>agents/tool_user/__init__.py</code>:</p> <pre><code>\"\"\"Tool user agent for MCP SSE.\"\"\"\n\nfrom .agent import ToolUserAgent\n</code></pre>"},{"location":"guides/mcp_sse_tool_call_tutorial/#step-4-create-a-test-script","title":"Step 4: Create a Test Script","text":"<p>Create a test script <code>test_example.py</code> to verify that the example works:</p> <pre><code>\"\"\"Test script for the MCP SSE tool call example.\"\"\"\n\nimport asyncio\nimport logging\nimport sys\nfrom typing import Dict, Any\n\nfrom openmas.agent_factory import AgentFactory\nfrom openmas.logging import configure_logging\n\n# Configure logging\nconfigure_logging(logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nasync def run_test():\n    \"\"\"Run the test.\"\"\"\n    logger.info(\"Starting MCP SSE tool call test\")\n\n    # Create the agent factory\n    factory = AgentFactory()\n\n    # Create the agents\n    tool_provider = await factory.create_agent(\"tool_provider\")\n    tool_user = await factory.create_agent(\"tool_user\")\n\n    try:\n        # Start the provider first\n        await tool_provider.start()\n        logger.info(\"Tool provider agent started\")\n\n        # Give the server a moment to initialize\n        await asyncio.sleep(1.0)\n\n        # Start the user agent\n        await tool_user.start()\n        logger.info(\"Tool user agent started\")\n\n        # Wait for the user to complete its task\n        await asyncio.sleep(2.0)\n\n        # Verify the result\n        result = getattr(tool_user, \"result\", None)\n        error = getattr(tool_user, \"error\", None)\n\n        if result:\n            logger.info(f\"Test result: {result}\")\n            assert result.get(\"status\") == \"success\", \"Tool call failed\"\n            assert \"processed_text\" in result, \"Missing processed_text in result\"\n            assert \"word_count\" in result, \"Missing word_count in result\"\n            logger.info(\"Test passed! Tool call was successful.\")\n        elif error:\n            logger.error(f\"Test failed with error: {error}\")\n            sys.exit(1)\n        else:\n            logger.error(\"Test failed - no result or error found\")\n            sys.exit(1)\n\n    finally:\n        # Always clean up the agents\n        logger.info(\"Cleaning up agents\")\n        await tool_user.stop()\n        await tool_provider.stop()\n        logger.info(\"Agents stopped\")\n\n\nif __name__ == \"__main__\":\n    try:\n        asyncio.run(run_test())\n    except KeyboardInterrupt:\n        logger.info(\"Test interrupted by user\")\n        sys.exit(130)\n    except Exception as e:\n        logger.error(f\"Error running test: {e}\", exc_info=True)\n        sys.exit(1)\n</code></pre>"},{"location":"guides/mcp_sse_tool_call_tutorial/#step-5-run-the-example","title":"Step 5: Run the Example","text":"<p>Run the example using the following command:</p> <pre><code>python test_example.py\n</code></pre> <p>You should see output showing: 1. The tool provider starting with the MCP SSE server 2. The tool user connecting to the server 3. A successful tool call being made 4. The result being processed</p>"},{"location":"guides/mcp_sse_tool_call_tutorial/#key-concepts","title":"Key Concepts","text":""},{"location":"guides/mcp_sse_tool_call_tutorial/#mcp-sse-communicator","title":"MCP SSE Communicator","text":"<p>The <code>McpSseCommunicator</code> in OpenMAS handles all the complexities of setting up an MCP server with SSE transport. When configured with <code>server_mode=True</code>, it:</p> <ol> <li>Creates an HTTP server using FastAPI and Uvicorn</li> <li>Sets up the MCP FastMCP instance</li> <li>Configures the SSE endpoint</li> <li>Handles tool registration</li> </ol>"},{"location":"guides/mcp_sse_tool_call_tutorial/#tool-registration-and-handling","title":"Tool Registration and Handling","text":"<p>Tools are registered with the communicator using the <code>register_tool</code> method. The tool handler function:</p> <ol> <li>Receives a payload dictionary containing the arguments</li> <li>Processes the input data</li> <li>Returns a result dictionary that will be sent back to the client</li> </ol> <p>With MCP 1.7.1, it's important to handle different argument formats: - Direct arguments like <code>payload[\"text\"]</code> - Content array format like <code>payload[\"content\"][0][\"text\"]</code></p>"},{"location":"guides/mcp_sse_tool_call_tutorial/#tool-calling","title":"Tool Calling","text":"<p>When calling a tool with MCP 1.7.1, it's best to provide arguments in multiple formats to ensure compatibility:</p> <pre><code>payload = {\n    \"text\": \"Hello world\",\n    \"content\": [{\"type\": \"text\", \"text\": \"Hello world\"}]\n}\n</code></pre>"},{"location":"guides/mcp_sse_tool_call_tutorial/#error-handling","title":"Error Handling","text":"<p>Proper error handling is crucial when working with network-based communication. Always use:</p> <ol> <li>Timeouts to prevent hanging</li> <li>Try/except blocks to catch and handle errors</li> <li>Proper logging to aid in debugging</li> </ol>"},{"location":"guides/mcp_sse_tool_call_tutorial/#best-practices-for-mcp-171-sse-communication","title":"Best Practices for MCP 1.7.1 SSE Communication","text":"<ol> <li>Flexible Argument Handling: Always check for arguments in multiple formats</li> <li>Robust Error Handling: Handle all network and protocol errors gracefully</li> <li>Timeouts: Use timeouts for all network operations to prevent hanging</li> <li>Graceful Shutdown: Always stop the server properly to release resources</li> <li>Detailed Logging: Log all operations to aid in debugging</li> </ol>"},{"location":"guides/mcp_sse_tool_call_tutorial/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues:</p> <ol> <li>Connection Refused: Make sure the server is running and the port is correct</li> <li>Tool Not Found: Verify the tool name matches between provider and user</li> <li>Timeout Errors: Increase the timeout value or check for network issues</li> <li>Serialization Errors: Ensure all data sent and received is JSON-serializable</li> <li>Event Loop Errors: These can occur during cleanup but are typically harmless</li> </ol>"},{"location":"guides/mcp_sse_tool_call_tutorial/#next-steps","title":"Next Steps","text":"<ul> <li>Try modifying the tool to perform different text processing operations</li> <li>Add more tools to the provider agent</li> <li>Implement a more complex application using multiple tools</li> <li>Explore the stdio transport for local communication in MCP Stdio Tool Call Tutorial</li> </ul> <p>For more details on MCP integration in OpenMAS, see the MCP Integration Guide and the MCP Developer Guide.</p>"},{"location":"guides/mcp_stdio_tool_call_tutorial/","title":"MCP STDIO Tool Call Tutorial","text":"<p>This tutorial walks you through creating a simple OpenMAS project that demonstrates MCP tool calls over standard input/output (STDIO). You'll build a tool provider agent that exposes a text processing tool, and a tool user agent that calls this tool.</p>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>Poetry (recommended) or pip</li> <li>OpenMAS with MCP extras installed</li> </ul> <p>If you haven't installed OpenMAS with MCP extras yet:</p> <pre><code># With poetry\npoetry add \"openmas[mcp]\"\n\n# With pip\npip install \"openmas[mcp]\"\n</code></pre> <p>Ensure you have MCP 1.7.1 or later:</p> <pre><code># With poetry\npoetry add \"mcp&gt;=1.7.1\"\n\n# With pip\npip install \"mcp&gt;=1.7.1\"\n</code></pre>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#project-setup","title":"Project Setup","text":"<ol> <li>Create a new project directory:</li> </ol> <pre><code>mkdir mcp_stdio_example\ncd mcp_stdio_example\n</code></pre> <ol> <li>Create the project structure:</li> </ol> <pre><code>mkdir -p agents/tool_provider agents/tool_user config\ntouch openmas_project.yml\ntouch agents/tool_provider/__init__.py\ntouch agents/tool_provider/agent.py\ntouch agents/tool_user/__init__.py\ntouch agents/tool_user/agent.py\ntouch README.md\n</code></pre> <ol> <li>Initialize the <code>__init__.py</code> files:</li> </ol> <p>agents/tool_provider/init.py: <pre><code>\"\"\"Tool provider agent package.\"\"\"\n\nfrom .agent import ToolProviderAgent\n</code></pre></p> <p>agents/tool_user/init.py: <pre><code>\"\"\"Tool user agent package.\"\"\"\n\nfrom .agent import ToolUserAgent\n</code></pre></p>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#step-1-implement-the-tool-provider-agent","title":"Step 1: Implement the Tool Provider Agent","text":"<p>Create the tool provider agent that registers and exposes an MCP tool:</p> <p>agents/tool_provider/agent.py: <pre><code>\"\"\"Tool provider agent that registers and exposes an MCP tool via stdio.\"\"\"\n\nimport asyncio\nfrom typing import Any, Dict, List\n\nfrom openmas.agent import BaseAgent\nfrom openmas.logging import get_logger\n\n# Import MCP types if available, otherwise use Any\ntry:\n    from mcp.types import TextContent\n    HAS_MCP_TYPES = True\nexcept ImportError:\n    HAS_MCP_TYPES = False\n    TextContent = Any  # type: ignore\n\nlogger = get_logger(__name__)\n\n\nclass ToolProviderAgent(BaseAgent):\n    \"\"\"Agent that provides an MCP tool over stdio.\n\n    This agent registers a tool called \"process_text\" that handles\n    incoming text and returns a processed result.\n    \"\"\"\n\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the agent by registering the MCP tool.\"\"\"\n        logger.info(\"Setting up ToolProviderAgent\")\n\n        # Register the process_text tool with the MCP communicator\n        await self.communicator.register_tool(\n            name=\"process_text\",\n            description=\"Process incoming text and return a result\",\n            function=self.process_text_handler,\n        )\n        logger.info(\"Registered MCP tool: process_text\")\n        logger.info(\"ToolProviderAgent setup complete\")\n\n    async def process_text_handler(self, payload: Dict[str, Any]) -&gt; List[Any]:\n        \"\"\"Handle incoming tool calls by processing the provided text.\n\n        Args:\n            payload: Dictionary containing the text to process\n\n        Returns:\n            List of TextContent objects containing the processed result\n        \"\"\"\n        logger.info(f\"Tool handler received payload: {payload}\")\n\n        # MCP 1.7.1 can send arguments in different ways, so check both formats\n        text = None\n\n        # Check for direct text field\n        if \"text\" in payload:\n            text = payload[\"text\"]\n            logger.info(\"Found text in direct text field\")\n\n        # Check for content array format (MCP 1.7.1 style)\n        elif \"content\" in payload and isinstance(payload[\"content\"], list) and len(payload[\"content\"]) &gt; 0:\n            content_item = payload[\"content\"][0]\n            if isinstance(content_item, dict) and \"text\" in content_item:\n                text = content_item[\"text\"]\n                logger.info(\"Found text in content[0].text\")\n            elif hasattr(content_item, \"text\"):\n                # Handle MCP TextContent object\n                text = content_item.text\n                logger.info(\"Found text in content[0].text object\")\n\n        # Process the text if found\n        if text is None:\n            error_msg = \"No text field found in payload\"\n            logger.error(f\"{error_msg}: {payload}\")\n\n            # Return error message as TextContent for MCP 1.7.1\n            if HAS_MCP_TYPES:\n                import json\n                return [TextContent(type=\"text\", text=json.dumps({\"error\": error_msg, \"status\": \"error\"}))]\n            else:\n                # Fallback for when TextContent is not available (testing)\n                return [{\"type\": \"text\", \"text\": f'{{\"error\": \"{error_msg}\", \"status\": \"error\"}}'}]\n\n        # Simple processing - convert to uppercase and count words\n        processed_text = text.upper()\n        word_count = len(text.split())\n\n        # Format the result according to MCP 1.7.1 requirements\n        import json\n        result_json = json.dumps({\n            \"processed_text\": processed_text,\n            \"word_count\": word_count,\n            \"status\": \"success\"\n        })\n\n        logger.info(f\"Tool handler returning result: {result_json}\")\n\n        # Return the result as TextContent for MCP 1.7.1\n        if HAS_MCP_TYPES:\n            return [TextContent(type=\"text\", text=result_json)]\n        else:\n            # Fallback for when TextContent is not available (testing)\n            return [{\"type\": \"text\", \"text\": result_json}]\n\n    async def run(self) -&gt; None:\n        \"\"\"Run the agent.\n\n        The tool provider agent doesn't need to actively do anything in its run method.\n        It primarily waits for incoming tool calls and responds to them.\n        \"\"\"\n        logger.info(\"ToolProviderAgent running, waiting for tool calls\")\n\n        # Keep the agent alive while waiting for tool calls\n        try:\n            while True:\n                await asyncio.sleep(1)\n        except asyncio.CancelledError:\n            logger.info(\"Tool provider run loop cancelled\")\n            raise\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Shut down the agent.\"\"\"\n        logger.info(\"ToolProviderAgent shutting down\")\n</code></pre></p>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#step-2-implement-the-tool-user-agent","title":"Step 2: Implement the Tool User Agent","text":"<p>Create the tool user agent that calls the tool exposed by the provider:</p> <p>agents/tool_user/agent.py: <pre><code>\"\"\"Tool user agent that calls an MCP tool via stdio.\"\"\"\n\nimport asyncio\nfrom typing import Any, Dict, Optional\n\nfrom openmas.agent import BaseAgent\nfrom openmas.logging import get_logger\nfrom openmas.exceptions import CommunicationError\n\nlogger = get_logger(__name__)\n\n\nclass ToolUserAgent(BaseAgent):\n    \"\"\"Agent that uses an MCP tool over stdio.\n\n    This agent calls the \"process_text\" tool provided by the ToolProviderAgent,\n    sends text data, and processes the result.\n    \"\"\"\n\n    async def setup(self) -&gt; None:\n        \"\"\"Set up the agent.\"\"\"\n        logger.info(\"Setting up ToolUserAgent\")\n        self.result: Optional[Dict[str, Any]] = None\n        self.error: Optional[Dict[str, str]] = None\n        logger.info(\"ToolUserAgent setup complete\")\n\n    async def run(self) -&gt; None:\n        \"\"\"Run the agent by calling the process_text tool.\"\"\"\n        logger.info(\"ToolUserAgent running, calling process_text tool\")\n\n        # Prepare the text to process\n        test_text = \"Hello, this is a sample text that needs processing.\"\n\n        try:\n            # Call the process_text tool with timeout protection\n            result = await self._call_process_text(test_text)\n\n            # Store the result for verification\n            self.result = result\n\n            # Log the result\n            logger.info(f\"Process text tool result: {result}\")\n\n            if result.get(\"status\") == \"success\":\n                logger.info(f\"Successfully processed text: {result.get('processed_text')}\")\n                logger.info(f\"Word count: {result.get('word_count')}\")\n            else:\n                logger.error(f\"Tool call failed: {result.get('error')}\")\n\n        except Exception as e:\n            logger.error(f\"Error during tool call: {e}\")\n            self.error = {\"error\": str(e), \"status\": \"error\"}\n\n        logger.info(\"ToolUserAgent completed its run method\")\n\n    async def _call_process_text(self, text: str, timeout: float = 10.0) -&gt; Dict[str, Any]:\n        \"\"\"Call the process_text tool with timeout protection.\n\n        Args:\n            text: The text to process\n            timeout: Timeout in seconds\n\n        Returns:\n            The result from the tool\n\n        Raises:\n            CommunicationError: If there's an error calling the tool\n            asyncio.TimeoutError: If the call times out\n        \"\"\"\n        logger.info(f\"Calling process_text tool with text: {text}\")\n\n        # Create a payload that works with MCP 1.7.1\n        # Include both direct text field and content array format\n        payload = {\n            \"text\": text,\n            # Add content array for MCP 1.7.1 compatibility\n            \"content\": [{\"type\": \"text\", \"text\": text}]\n        }\n\n        try:\n            # Call the tool with timeout protection\n            result = await asyncio.wait_for(\n                self.communicator.call_tool(\n                    target_service=\"tool_provider\",\n                    tool_name=\"process_text\",\n                    arguments=payload,\n                ),\n                timeout=timeout,\n            )\n\n            logger.info(f\"Received raw result: {result}\")\n            return result\n\n        except asyncio.TimeoutError:\n            error_msg = f\"Tool call timed out after {timeout} seconds\"\n            logger.error(error_msg)\n            raise\n        except Exception as e:\n            error_msg = f\"Error calling process_text tool: {e}\"\n            logger.error(error_msg)\n            raise CommunicationError(error_msg)\n\n    async def shutdown(self) -&gt; None:\n        \"\"\"Shut down the agent.\"\"\"\n        logger.info(\"ToolUserAgent shutting down\")\n</code></pre></p>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#step-3-configure-the-project","title":"Step 3: Configure the Project","text":"<p>Create the OpenMAS project configuration:</p> <p>openmas_project.yml: <pre><code>name: mcp_stdio_tool_call_example\nversion: 0.1.0\ndescription: \"Example demonstrating MCP tool calls over standard input/output (stdio) using MCP 1.7.1\"\n\n# Define the available agents\nagents:\n  tool_provider: \"agents/tool_provider\"\n  tool_user: \"agents/tool_user\"\n\n# Default configuration for all agents\ndefault_config:\n  log_level: INFO\n\n# Default communicator settings\ncommunicator_defaults:\n  type: mock\n  options: {}\n\n# Agent-specific configurations\nagent_configs:\n  # Tool provider config\n  tool_provider:\n    communicator_type: mcp-stdio\n    communicator_options:\n      server_mode: true\n\n  # Tool user config\n  tool_user:\n    communicator_type: mcp-stdio\n    communicator_options:\n      server_mode: false\n    service_urls:\n      # The command to start the tool provider (uses openmas run)\n      tool_provider: \"poetry run openmas run tool_provider --project .\"\n</code></pre></p>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#step-4-create-a-test-script","title":"Step 4: Create a Test Script","text":"<p>Create a test script to verify that the example works:</p> <p>test_example.py: <pre><code>\"\"\"Test script for the MCP STDIO tool call example.\"\"\"\n\nimport asyncio\nimport logging\nimport sys\nfrom typing import Dict, Any\n\nfrom openmas.agent_factory import AgentFactory\nfrom openmas.logging import configure_logging\n\n# Configure logging\nconfigure_logging(logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nasync def run_test():\n    \"\"\"Run the test.\"\"\"\n    logger.info(\"Starting MCP STDIO tool call test\")\n\n    # Create the agent factory\n    factory = AgentFactory()\n\n    # Create the agents\n    tool_user = await factory.create_agent(\"tool_user\")\n\n    try:\n        # Start the user agent - it will start the provider\n        # as a subprocess using the command in service_urls\n        await tool_user.start()\n        logger.info(\"Tool user agent started\")\n\n        # Wait for the user to complete its task\n        await asyncio.sleep(5.0)\n\n        # Verify the result\n        result = getattr(tool_user, \"result\", None)\n        error = getattr(tool_user, \"error\", None)\n\n        if result:\n            logger.info(f\"Test result: {result}\")\n            assert result.get(\"status\") == \"success\", \"Tool call failed\"\n            assert \"processed_text\" in result, \"Missing processed_text in result\"\n            assert \"word_count\" in result, \"Missing word_count in result\"\n            logger.info(\"Test passed! Tool call was successful.\")\n        elif error:\n            logger.error(f\"Test failed with error: {error}\")\n            sys.exit(1)\n        else:\n            logger.error(\"Test failed - no result or error found\")\n            sys.exit(1)\n\n    finally:\n        # Always clean up the agents\n        logger.info(\"Cleaning up agents\")\n        await tool_user.stop()\n        logger.info(\"Agents stopped\")\n\n\nif __name__ == \"__main__\":\n    try:\n        asyncio.run(run_test())\n    except KeyboardInterrupt:\n        logger.info(\"Test interrupted by user\")\n        sys.exit(130)\n    except Exception as e:\n        logger.error(f\"Error running test: {e}\", exc_info=True)\n        sys.exit(1)\n</code></pre></p>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#step-5-run-the-example","title":"Step 5: Run the Example","text":""},{"location":"guides/mcp_stdio_tool_call_tutorial/#method-1-run-each-agent-separately","title":"Method 1: Run Each Agent Separately","text":"<ol> <li>First, start the tool provider:</li> </ol> <pre><code>poetry run openmas run tool_provider\n</code></pre> <ol> <li>Then, in a separate terminal, start the tool user:</li> </ol> <pre><code>poetry run openmas run tool_user\n</code></pre>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#method-2-use-the-test-script","title":"Method 2: Use the Test Script","text":"<pre><code>python test_example.py\n</code></pre>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#key-concepts","title":"Key Concepts","text":""},{"location":"guides/mcp_stdio_tool_call_tutorial/#mcp-stdio-communicator","title":"MCP STDIO Communicator","text":"<p>The <code>McpStdioCommunicator</code> handles communication over standard input/output pipes:</p> <ol> <li>In server mode, it listens for incoming messages on stdin</li> <li>In client mode, it starts the server as a subprocess and connects via pipes</li> <li>All MCP protocol messages are exchanged via these pipes</li> </ol>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#mcp-171-tool-response-format","title":"MCP 1.7.1 Tool Response Format","text":"<p>With MCP 1.7.1, tools must return a list of <code>TextContent</code> objects:</p> <pre><code>from mcp.types import TextContent\nimport json\n\n# Convert a dictionary to a valid MCP 1.7.1 response\nresult_dict = {\"processed_text\": \"HELLO\", \"word_count\": 1, \"status\": \"success\"}\njson_str = json.dumps(result_dict)\nresponse = [TextContent(type=\"text\", text=json_str)]\n</code></pre>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#tool-input-format","title":"Tool Input Format","text":"<p>For maximum compatibility, provide arguments in multiple formats:</p> <pre><code>payload = {\n    \"text\": \"Hello world\",\n    \"content\": [{\"type\": \"text\", \"text\": \"Hello world\"}]\n}\n</code></pre>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#best-practices-for-mcp-171-stdio-communication","title":"Best Practices for MCP 1.7.1 STDIO Communication","text":"<ol> <li>Handle Different Argument Formats: Check for arguments in both direct and content array formats</li> <li>Proper Return Format: Return a list of TextContent objects</li> <li>Structured Responses: Use JSON for structured data exchange</li> <li>Error Handling: Catch and handle errors gracefully</li> <li>Timeouts: Use timeouts to prevent hanging when calling tools</li> </ol>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#troubleshooting","title":"Troubleshooting","text":"<ol> <li>Process Startup Errors: If the provider process fails to start, check:</li> <li>Correct command in service_urls</li> <li>Permission issues</li> <li> <p>Path issues</p> </li> <li> <p>Communication Errors: If tool calls fail:</p> </li> <li>Check that tools are registered with the correct names</li> <li>Verify that arguments are formatted correctly</li> <li> <p>Look for serialization errors in complex data</p> </li> <li> <p>Timeout Issues: If calls timeout:</p> </li> <li>Increase the timeout value</li> <li>Check for performance issues in tool implementation</li> <li>Ensure the provider is not deadlocked</li> </ol>"},{"location":"guides/mcp_stdio_tool_call_tutorial/#comparison-of-stdio-vs-sse","title":"Comparison of STDIO vs SSE","text":"Feature STDIO SSE Communication Process-based (pipes) Network-based (HTTP) Multiple Clients One client per provider Multiple clients per server Deployment Must run on same machine Can run on different machines Setup Simpler (process pipes) More complex (HTTP server) Resilience Process must restart on failure Can reconnect on failure Use Case Local tool execution Distributed systems"},{"location":"guides/mcp_stdio_tool_call_tutorial/#next-steps","title":"Next Steps","text":"<ul> <li>Add more tools to the provider</li> <li>Process more complex data types</li> <li>Implement error handling for edge cases</li> <li>Try the SSE transport for networked communication in MCP SSE Tool Call Tutorial</li> </ul> <p>For more details on MCP integration in OpenMAS, see the MCP Integration Guide and the MCP Developer Guide.</p>"},{"location":"guides/patterns/","title":"Agent Patterns in OpenMAS","text":"<p>OpenMAS provides optional modules and base classes within the <code>openmas.patterns</code> namespace to facilitate the implementation of common Multi-Agent System (MAS) design patterns. This guide highlights the patterns with built-in support and provides conceptual approaches for implementing other common workflows using core features.</p>"},{"location":"guides/patterns/#supported-patterns-with-built-in-helpers","title":"Supported Patterns with Built-in Helpers","text":""},{"location":"guides/patterns/#orchestrator-worker-pattern-openmaspatternsorchestrator","title":"Orchestrator-Worker Pattern (<code>openmas.patterns.orchestrator</code>)","text":"<p>This pattern is useful for coordinating complex workflows where a central agent (Orchestrator) delegates tasks to specialized agents (Workers). OpenMAS provides dedicated base classes for this:</p> <ul> <li><code>BaseOrchestratorAgent</code>: Manages workflow execution (e.g., using <code>orchestrate_workflow</code>), delegates tasks (<code>delegate_task</code>), aggregates results, discovers workers (<code>discover_workers</code>), and handles potential worker failures or timeouts.</li> <li><code>BaseWorkerAgent</code>: Implements specific task logic using the <code>@TaskHandler</code> decorator. Workers typically register themselves with an orchestrator.</li> <li>Communication: Uses standard OpenMAS communication (<code>send_request</code>/<code>send_notification</code>) for task delegation and result reporting.</li> </ul> <p>Benefits:</p> <ul> <li>Clear separation of concerns.</li> <li>Improved scalability and maintainability.</li> <li>Facilitates parallelism and fault tolerance in workflows.</li> </ul> <p>Example Usage:</p> <pre><code>import asyncio\nfrom openmas.patterns.orchestrator import (\n    BaseOrchestratorAgent,\n    BaseWorkerAgent,\n    TaskHandler\n)\nfrom openmas.config import AgentConfig\nfrom openmas.agent import BaseAgent # Needed for main example\nfrom openmas.logging import configure_logging, get_logger\n\nconfigure_logging(log_level=\"INFO\")\nlogger = get_logger(__name__)\n\n# Define a worker agent with task handlers\nclass MathWorker(BaseWorkerAgent):\n    # No __init__ needed unless adding custom state\n\n    @TaskHandler(task_type=\"add\", description=\"Add two numbers\")\n    async def add(self, a: int, b: int) -&gt; dict:\n        logger.info(f\"Worker '{self.name}' adding {a} + {b}\")\n        return {\"result\": a + b}\n\n    @TaskHandler(task_type=\"multiply\", description=\"Multiply two numbers\")\n    async def multiply(self, a: int, b: int) -&gt; dict:\n        logger.info(f\"Worker '{self.name}' multiplying {a} * {b}\")\n        return {\"result\": a * b}\n\n# Define an orchestrator agent\nclass CalculationOrchestrator(BaseOrchestratorAgent):\n    # No __init__ needed unless adding custom state\n\n    async def calculate_expression(self, a: int, b: int, c: int) -&gt; int:\n        \"\"\"Calculates a + (b * c) using worker agents.\"\"\"\n        logger.info(f\"Orchestrator calculating {a} + ({b} * {c})\")\n        # Define a workflow sequence\n        workflow = [\n            {\n                \"task_type\": \"multiply\", # Task handled by MathWorker\n                \"parameters\": {\"a\": b, \"b\": c},\n                \"worker_name\": \"math_worker\" # Specify the target worker\n            },\n            {\n                \"task_type\": \"add\",      # Task handled by MathWorker\n                \"parameters\": {\"a\": a},  # 'b' will come from previous result\n                \"include_previous_results\": {\"b\": \"result\"}, # Map previous 'result' to 'b'\n                \"worker_name\": \"math_worker\",\n                \"abort_on_failure\": True\n            }\n        ]\n\n        # Execute the workflow (sequentially by default)\n        results = await self.orchestrate_workflow(workflow)\n        logger.info(f\"Workflow results: {results}\")\n\n        # Get the final result from the second step (index 1)\n        final_result_dict = results.get(1, {})\n        return final_result_dict.get(\"result\", None)\n\n# --- Main application setup ---\nasync def main():\n    # Create agents using standard BaseAgent initialization\n    # Communicators need to be compatible (e.g., HTTP)\n    http_port_orch = 8000\n    http_port_worker = 8001\n\n    orch_config = AgentConfig(\n        name=\"calc_orchestrator\",\n        communicator_type=\"http\",\n        service_urls={\"math_worker\": f\"http://localhost:{http_port_worker}\"},\n        communicator_options={\"http_port\": http_port_orch}\n    )\n    worker_config = AgentConfig(\n        name=\"math_worker\",\n        communicator_type=\"http\",\n        service_urls={\"calc_orchestrator\": f\"http://localhost:{http_port_orch}\"},\n        communicator_options={\"http_port\": http_port_worker}\n    )\n\n    orchestrator = CalculationOrchestrator(config=orch_config)\n    worker = MathWorker(config=worker_config)\n\n    # Start agents (this runs setup and run methods)\n    await orchestrator.start()\n    await worker.start()\n\n    # Worker needs to register itself with the orchestrator\n    logger.info(\"Registering worker...\")\n    await worker.register_with_orchestrator(orchestrator.name)\n    logger.info(\"Worker registered.\")\n\n    # Give a moment for registration/setup\n    await asyncio.sleep(1)\n\n    # Trigger the calculation on the orchestrator\n    logger.info(\"Triggering calculation...\")\n    final_value = await orchestrator.calculate_expression(a=5, b=2, c=3)\n    logger.info(f\"Final Calculated Result: {final_value}\") # Should be 11\n\n    # Clean up\n    logger.info(\"Stopping agents...\")\n    await worker.stop()\n    await orchestrator.stop()\n    logger.info(\"Agents stopped.\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>(See the API documentation for <code>BaseOrchestratorAgent</code> and <code>BaseWorkerAgent</code> for more details on configuration and methods like <code>discover_workers</code>, <code>delegate_task</code>, <code>orchestrate_workflow</code> options, etc.)</p>"},{"location":"guides/patterns/#implementing-other-workflows-using-core-features","title":"Implementing Other Workflows using Core Features","text":"<p>Many other patterns rely on agents sending messages to each other in specific sequences or based on certain conditions. You can implement these using <code>BaseAgent</code> and <code>send_request</code>.</p>"},{"location":"guides/patterns/#1-prompt-chaining-sequential-processing","title":"1. Prompt Chaining / Sequential Processing","text":"<p>In this pattern, the output of one agent becomes the input for the next agent in a sequence.</p> <p>Concept: Agent A calls Agent B, Agent B processes the data and calls Agent C, and so on. The initial call might return the final result after the whole chain completes, or intermediate agents might just forward requests.</p> <p>Implementation:</p> <ul> <li>Each agent in the chain needs the address of the next agent in its <code>service_urls</code> configuration.</li> <li>An agent's handler receives a request, performs its task, potentially transforms the data, and then uses <code>self.communicator.send_request</code> to call the next agent in the chain, passing the processed data.</li> <li>The final agent in the chain returns the result back up the call stack.</li> </ul> <pre><code># Conceptual Chaining Example\nfrom openmas.agent import BaseAgent\nimport asyncio\n\nclass AgentB(BaseAgent):\n    async def setup(self):\n        await self.communicator.register_handler(\"process_b\", self.handle_process)\n\n    async def handle_process(self, data_from_a: dict) -&gt; dict:\n        # ... process data_from_a ...\n        processed_data = {\"b_result\": data_from_a.get(\"a_result\", \"\") + \"_processed_by_b\"}\n\n        # Assume Agent C's logical name is 'agentC' configured in service_urls\n        # self.config.service_urls[\"agentC\"] would contain the actual address\n        agent_c_service_name = \"agentC\"\n\n        # Call Agent C\n        final_result = await self.communicator.send_request(\n            target_service=agent_c_service_name,\n            method=\"process_c\",\n            params={\"data_from_b\": processed_data}\n        )\n        return final_result # Return result from C\n\nclass AgentC(BaseAgent):\n     async def setup(self):\n        await self.communicator.register_handler(\"process_c\", self.handle_process)\n\n     async def handle_process(self, data_from_b: dict) -&gt; dict:\n         # ... process data_from_b ...\n         final_data = {\"final\": data_from_b.get(\"b_result\", \"\") + \"_processed_by_c\"}\n         return final_data\n\n# Agent A (not shown) would initiate the call to Agent B's \"process_b\" handler.\n# Configuration (e.g., in Agent A and B) would map logical names like \"agentB\"\n# and \"agentC\" to actual addresses (e.g., http://host:port).\n</code></pre>"},{"location":"guides/patterns/#2-routing-conditional-dispatch","title":"2. Routing / Conditional Dispatch","text":"<p>An agent acts as a router, deciding which subsequent agent(s) to call based on the incoming request data or its internal state.</p> <p>Concept: Agent R receives a request, inspects the parameters or context, and forwards the request to Agent X, Agent Y, or maybe both, based on defined rules.</p> <p>Implementation:</p> <ul> <li>The Router Agent (Agent R) needs the addresses of all potential target agents (X, Y, etc.) in its <code>service_urls</code>.</li> <li>The handler in Agent R contains the routing logic (e.g., <code>if/elif/else</code> statements based on request parameters).</li> <li>Based on the logic, Agent R uses <code>self.communicator.send_request</code> to call the appropriate target agent(s) and method(s).</li> <li>The router might aggregate responses or simply return the response from the chosen target.</li> </ul> <pre><code># Conceptual Router Example\nfrom openmas.agent import BaseAgent\nimport asyncio\n\nclass RouterAgent(BaseAgent):\n    async def setup(self):\n        await self.communicator.register_handler(\"route_request\", self.handle_route)\n\n    async def handle_route(self, request_data: dict) -&gt; dict:\n        request_type = request_data.get(\"type\")\n        payload = request_data.get(\"payload\")\n\n        if request_type == \"image\":\n            # Assume logical name 'imageProcessor' is configured in service_urls\n            target_service = \"imageProcessor\"\n            target_method = \"process_image\"\n        elif request_type == \"text\":\n            # Assume logical name 'textAnalyzer' is configured in service_urls\n            target_service = \"textAnalyzer\"\n            target_method = \"analyze_text\"\n        else:\n            return {\"error\": \"Unknown request type\"}\n\n        # Forward the request to the chosen service\n        result = await self.communicator.send_request(\n            target_service=target_service,\n            method=target_method,\n            params=payload # Pass the original payload\n        )\n        return result\n\n# Other agents (imageProcessor, textAnalyzer) would define the respective\n# handlers (process_image, analyze_text).\n# The RouterAgent's config would map these logical names to addresses.\n</code></pre>"},{"location":"guides/patterns/#3-parallel-execution-fan-out","title":"3. Parallel Execution / Fan-Out","text":"<p>An agent sends the same (or similar) request to multiple other agents simultaneously and potentially aggregates the results.</p> <p>Concept: Agent P receives a task, splits it or identifies multiple relevant workers (W1, W2, W3), sends requests to all workers in parallel, waits for all responses, and combines them.</p> <p>Implementation:</p> <ul> <li>The Parallelizer Agent (Agent P) needs the addresses of all potential worker agents (W1, W2, W3) in its <code>service_urls</code>.</li> <li>Agent P creates multiple <code>send_request</code> calls as <code>asyncio</code> tasks.</li> <li>It uses <code>asyncio.gather(*tasks)</code> to run these requests concurrently and wait for all of them to complete.</li> <li>It then processes the list of results returned by <code>asyncio.gather</code>.</li> </ul> <pre><code># Conceptual Parallelizer Example\nfrom openmas.agent import BaseAgent\nimport asyncio\n\nclass ParallelAgent(BaseAgent):\n    async def setup(self):\n        await self.communicator.register_handler(\"process_in_parallel\", self.handle_parallel)\n\n    async def handle_parallel(self, task_data: dict) -&gt; dict:\n        # Assume worker_services list comes from config or discovery\n        # self.config.service_urls should contain mappings for \"worker1\", \"worker2\", etc.\n        worker_services = [\"worker1\", \"worker2\", \"worker3\"] # Logical names\n        tasks = []\n\n        for worker_name in worker_services:\n            task = self.communicator.send_request(\n                target_service=worker_name,\n                method=\"perform_subtask\", # Assume workers implement this\n                params={\"data\": task_data} # Send same data to all\n            )\n            tasks.append(task)\n\n        # Execute all requests concurrently\n        # return_exceptions=True allows processing partial success\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Aggregate results\n        aggregated_results = []\n        errors = []\n        for i, res in enumerate(results):\n            if isinstance(res, Exception):\n                errors.append(f\"Worker {worker_services[i]} failed: {res}\")\n            elif isinstance(res, dict) and res.get(\"error\"): # Handle application errors\n                 errors.append(f\"Worker {worker_services[i]} error: {res['error']}\")\n            else:\n                aggregated_results.append(res)\n\n        return {\n            \"aggregated\": aggregated_results,\n            \"errors\": errors\n        }\n\n# Worker agents (worker1, worker2, etc.) would define the 'perform_subtask' handler.\n# The ParallelAgent's config would map these logical names to addresses.\n</code></pre>"},{"location":"guides/patterns/#other-patterns","title":"Other Patterns","text":"<p>While OpenMAS provides specific helpers for the Orchestrator-Worker pattern, many other MAS patterns can be implemented using the core <code>BaseAgent</code> and appropriate communicators:</p> <ul> <li>Publish/Subscribe: Can be effectively implemented using the <code>MqttCommunicator</code> with an MQTT broker, or by building a custom registry/dispatcher agent using standard communicators.</li> <li>Contract Net Protocol: Involves agents broadcasting task announcements, receiving bids, and awarding contracts. This can be built using <code>send_request</code> and <code>send_notification</code> with custom logic within agents to manage the bidding and awarding process.</li> <li>Service Discovery: A dedicated registry agent can be created where other agents register their services (<code>register_handler</code>) and query for available services (<code>send_request</code>). The <code>BaseOrchestratorAgent</code>'s <code>discover_workers</code> method provides a basic form of discovery for the Orchestrator-Worker pattern.</li> </ul> <p>Building these patterns involves designing the interaction protocols and implementing the corresponding logic within your <code>BaseAgent</code> subclasses.</p>"},{"location":"guides/patterns/#future-enhancements","title":"Future Enhancements","text":"<p>While these patterns are implementable today using core features, dedicated framework helpers or classes for patterns like Chaining or Routing might be added in future OpenMAS versions to further simplify their implementation.</p>"},{"location":"guides/prompt_management/","title":"Prompt Management and Sampling","text":"<p>This guide introduces OpenMAS's prompt management and sampling capabilities, which enable agents to organize, version, reuse prompts, and interact with language models in a standardized way.</p>"},{"location":"guides/prompt_management/#introduction","title":"Introduction","text":"<p>The prompt management and sampling system in OpenMAS provides:</p> <ul> <li>A structured way to define, store, and retrieve prompts</li> <li>Version control and metadata for prompts</li> <li>Template rendering with context variables</li> <li>A sampling abstraction for consistent interaction with language models</li> <li>Integration with MCP (Model Context Protocol)</li> </ul> <p>These features are particularly useful for building agents that need to:</p> <ul> <li>Maintain a library of prompts for different contexts and scenarios</li> <li>Sample from language models with consistent parameters</li> <li>Share prompts between agents or expose them via MCP</li> </ul>"},{"location":"guides/prompt_management/#configuring-prompts-in-project-files","title":"Configuring Prompts in Project Files","text":"<p>The simplest way to configure prompts for an agent is through the <code>openmas_project.yml</code> file. This method is recommended for most applications and provides a clean, declarative way to define prompts.</p>"},{"location":"guides/prompt_management/#prompt-configuration-structure","title":"Prompt Configuration Structure","text":"<p>Prompts are configured using the <code>prompts</code> field in an agent's configuration:</p> <pre><code>agents:\n  analyzer:\n    module: \"agents.analyzer\"\n    class: \"AnalyzerAgent\"\n    prompts_dir: \"prompts\"  # Optional, defaults to \"prompts\"\n    prompts:\n      - name: \"analyze_text\"\n        template_file: \"analysis.txt\"\n        input_variables: [\"text_content\", \"analysis_depth\"]\n      - name: \"summarize\"\n        template: \"Summarize the following text in {{num_sentences}} sentences: {{text}}\"\n        input_variables: [\"text\", \"num_sentences\"]\n</code></pre>"},{"location":"guides/prompt_management/#inline-vs-file-based-templates","title":"Inline vs. File-Based Templates","text":"<p>OpenMAS supports two ways to define prompt templates:</p> <ol> <li>Inline Templates: Defined directly in the YAML configuration using the <code>template</code> field.</li> </ol> <pre><code>prompts:\n  - name: \"greet_user\"\n    template: \"Hello, {{user_name}}! Welcome to {{service_name}}.\"\n    input_variables: [\"user_name\", \"service_name\"]\n</code></pre> <ol> <li>File-Based Templates: Stored in separate files and referenced using the <code>template_file</code> field.</li> </ol> <pre><code>prompts:\n  - name: \"chess_analysis\"\n    template_file: \"chess_analysis.txt\"\n    input_variables: [\"board_state\", \"last_move\"]\n</code></pre> <p>The template file (e.g., <code>prompts/chess_analysis.txt</code>) would contain the full prompt text with variables:</p> <pre><code>You are a chess analysis assistant.\n\nCurrent board state:\n{{board_state}}\n\nLast move played: {{last_move}}\n\nPlease analyze the position and suggest the best move.\n</code></pre>"},{"location":"guides/prompt_management/#using-prompts_dir","title":"Using <code>prompts_dir</code>","text":"<p>The <code>prompts_dir</code> field specifies the directory where template files are stored:</p> <ul> <li>It defaults to <code>prompts</code> if not specified</li> <li>The path is relative to the project root</li> <li>All template files referenced in <code>template_file</code> are looked up in this directory</li> </ul> <p>Custom prompt directories help organize prompts in larger projects:</p> <pre><code>agents:\n  chess_agent:\n    module: \"agents.chess_agent\"\n    class: \"ChessAgent\"\n    prompts_dir: \"agents/chess_agent/prompts\"\n    prompts:\n      - name: \"analyze_position\"\n        template_file: \"position_analysis.txt\"\n        input_variables: [\"fen\", \"move_history\"]\n</code></pre>"},{"location":"guides/prompt_management/#prompt-management","title":"Prompt Management","text":""},{"location":"guides/prompt_management/#core-components","title":"Core Components","text":"<ul> <li>Prompt: A complete prompt definition with metadata and content</li> <li>PromptMetadata: Information about a prompt (name, version, tags, etc.)</li> <li>PromptContent: The actual content of a prompt (system, template, examples)</li> <li>PromptStorage: Abstract storage backend for prompts</li> <li>PromptManager: Main interface for managing prompts</li> </ul>"},{"location":"guides/prompt_management/#basic-usage","title":"Basic Usage","text":"<pre><code>from openmas.prompt import PromptManager, MemoryPromptStorage\n\n# Create a prompt manager with in-memory storage\nprompt_manager = PromptManager(storage=MemoryPromptStorage())\n\n# Create a prompt\nprompt = await prompt_manager.create_prompt(\n    name=\"chess_analysis\",\n    description=\"Analyzes a chess position\",\n    system=\"You are a chess expert that analyzes positions thoroughly.\",\n    template=\"Analyze this chess position: {{position}}\",\n    tags={\"chess\", \"analysis\"},\n    author=\"ChessPal Team\"\n)\n\n# Retrieve a prompt by ID\nretrieved_prompt = await prompt_manager.get_prompt(prompt.id)\n\n# Render a prompt with context\nrendered = await prompt_manager.render_prompt(\n    prompt.id,\n    context={\"position\": \"e4 e5 Nf3 Nc6 Bb5\"}\n)\n\n# Update a prompt\nupdated_prompt = await prompt_manager.update_prompt(\n    prompt.id,\n    system=\"You are a grandmaster-level chess coach providing insightful analysis.\",\n    template=\"Analyze this chess position and provide strategic advice: {{position}}\"\n)\n\n# List all prompts\nprompts = await prompt_manager.list_prompts()\n\n# List prompts with a specific tag\nchess_prompts = await prompt_manager.list_prompts(tag=\"chess\")\n\n# Delete a prompt\nsuccess = await prompt_manager.delete_prompt(prompt.id)\n</code></pre>"},{"location":"guides/prompt_management/#storage-options","title":"Storage Options","text":"<p>OpenMAS provides multiple storage backends for prompts:</p>"},{"location":"guides/prompt_management/#in-memory-storage","title":"In-Memory Storage","text":"<pre><code>from openmas.prompt import PromptManager, MemoryPromptStorage\n\n# Create an in-memory storage (useful for testing or simple applications)\nstorage = MemoryPromptStorage()\nprompt_manager = PromptManager(storage=storage)\n</code></pre>"},{"location":"guides/prompt_management/#file-system-storage","title":"File System Storage","text":"<pre><code>from openmas.prompt import PromptManager, FileSystemPromptStorage\nfrom pathlib import Path\n\n# Create a file system storage (persists prompts as JSON files)\nstorage = FileSystemPromptStorage(path=Path(\"./prompts\"))\nprompt_manager = PromptManager(storage=storage)\n</code></pre>"},{"location":"guides/prompt_management/#sampling-from-language-models","title":"Sampling from Language Models","text":"<p>The sampling module provides a consistent way to interact with language models across different providers.</p>"},{"location":"guides/prompt_management/#core-components_1","title":"Core Components","text":"<ul> <li>SamplingParameters: Controls sampling behavior (temperature, max_tokens, etc.)</li> <li>Message: A message in a conversation (role and content)</li> <li>SamplingContext: Complete context for a sampling operation</li> <li>SamplingResult: Result of a sampling operation</li> <li>Sampler: Base class for samplers</li> </ul>"},{"location":"guides/prompt_management/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from openmas.sampling import SamplingParameters, MessageRole\nfrom openmas.sampling.providers.mcp import McpSampler\nfrom openmas.communication.mcp.sse_communicator import McpSseCommunicator\n\n# Create a communicator\ncommunicator = McpSseCommunicator(\n    agent_name=\"sampler_agent\",\n    service_urls={\"llm_service\": \"http://localhost:8080\"},\n    server_mode=False,\n)\n\n# Create a sampler\nsampler = McpSampler(\n    communicator=communicator,\n    target_service=\"llm_service\",\n    default_model=\"claude-3-opus-20240229\"\n)\n\n# Create a sampling context\ncontext = sampler.create_context(\n    system=\"You are a helpful assistant.\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n    ],\n    parameters={\"temperature\": 0.7, \"max_tokens\": 500}\n)\n\n# Sample from the language model\nresult = await sampler.sample(context)\nprint(result.content)\n</code></pre>"},{"location":"guides/prompt_management/#sampling-from-a-prompt","title":"Sampling from a Prompt","text":"<p>You can also sample directly from a prompt:</p> <pre><code>from openmas.prompt import Prompt, PromptContent, PromptMetadata\nfrom openmas.sampling.providers.mcp import McpSampler\n\n# Create a prompt\nmetadata = PromptMetadata(name=\"chess_commentary\")\ncontent = PromptContent(\n    system=\"You are a chess commentator providing engaging commentary.\",\n    template=\"Provide commentary for this chess move: {{move}}\"\n)\nprompt = Prompt(metadata=metadata, content=content)\n\n# Sample from the prompt\nresult = await sampler.sample_from_prompt(\n    prompt=prompt,\n    context_vars={\"move\": \"e4\"},\n    parameters={\"temperature\": 0.8},\n    model=\"claude-3-sonnet-20240229\"\n)\n\nprint(result.content)\n</code></pre>"},{"location":"guides/prompt_management/#integration-with-mcp","title":"Integration with MCP","text":"<p>OpenMAS provides seamless integration between prompt management and MCP.</p>"},{"location":"guides/prompt_management/#registering-prompts-with-mcp","title":"Registering Prompts with MCP","text":"<pre><code>from openmas.prompt import PromptManager\nfrom openmas.prompt.mcp import McpPromptManager\nfrom openmas.agent.mcp import McpServerAgent\n\n# Create a prompt manager\nprompt_manager = PromptManager()\n\n# Create some prompts\nchess_analysis = await prompt_manager.create_prompt(\n    name=\"chess_analysis\",\n    system=\"You are a chess expert.\",\n    template=\"Analyze this position: {{position}}\",\n)\n\nchess_commentary = await prompt_manager.create_prompt(\n    name=\"chess_commentary\",\n    system=\"You are a chess commentator.\",\n    template=\"Provide commentary for this move: {{move}}\",\n)\n\n# Create an MCP prompt manager\nmcp_prompt_manager = McpPromptManager(prompt_manager)\n\n# Create an MCP server agent\nserver_agent = McpServerAgent(name=\"chess_server\")\nawait server_agent.setup()\n\n# Register prompts with the server\nawait mcp_prompt_manager.register_prompt_with_server(\n    prompt_id=chess_analysis.id,\n    server=server_agent.communicator\n)\n\n# Or register all prompts at once\nregistered_prompts = await mcp_prompt_manager.register_all_prompts_with_server(\n    server=server_agent.communicator\n)\n</code></pre>"},{"location":"guides/prompt_management/#enhanced-mcp-agent-with-prompt-management","title":"Enhanced MCP Agent with Prompt Management","text":"<p>OpenMAS provides an enhanced MCP agent with built-in prompt management and sampling capabilities:</p> <pre><code>from openmas.agent import PromptMcpAgent\n\n# Create an agent with prompt management and sampling\nagent = PromptMcpAgent(\n    name=\"chess_agent\",\n    llm_service=\"llm_service\",\n    default_model=\"claude-3-opus-20240229\"\n)\n\n# Setup the agent\nawait agent.setup()\n\n# Create prompts\nanalysis_prompt = await agent.create_prompt(\n    name=\"analysis\",\n    system=\"You are a chess analyst.\",\n    template=\"Analyze this position: {{position}}\"\n)\n\n# Sample from a prompt\nanalysis = await agent.sample(\n    prompt_id=analysis_prompt.id,\n    context={\"position\": \"e4 e5 Nf3 Nc6\"},\n    parameters={\"temperature\": 0.7}\n)\n\n# Sample directly from text\nresponse = await agent.sample_text(\n    system=\"You are a helpful assistant.\",\n    prompt=\"What opening begins with e4 e5 Nf3 Nc6?\",\n)\n\n# Use the chat interface\nresult = await agent.chat(\n    system=\"You are a chess tutor.\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the best response to e4?\"}\n    ],\n    parameters={\"temperature\": 0.8}\n)\n</code></pre>"},{"location":"guides/prompt_management/#example-chesspal-ai-integration","title":"Example: ChessPal AI Integration","text":"<p>Here's a complete example of using prompt management and sampling in a chess agent:</p> <pre><code>import asyncio\nfrom openmas.agent import PromptMcpAgent\n\nclass ChessPalAgent(PromptMcpAgent):\n    \"\"\"Chess assistant agent with prompt management and LLM capabilities.\"\"\"\n\n    async def setup(self):\n        \"\"\"Set up the agent with prompts and communication.\"\"\"\n        await super().setup()\n\n        # Create a set of chess-related prompts\n        self.prompts = {}\n\n        # Analysis prompt\n        self.prompts[\"analysis\"] = await self.create_prompt(\n            name=\"chess_analysis\",\n            description=\"Analyzes a chess position in detail\",\n            system=\"You are a chess analysis engine that evaluates positions objectively. \"\n                   \"Provide clear, concise analysis focusing on material, position, and tactics.\",\n            template=\"Analyze this chess position (FEN notation): {{fen}}\\n\\n\"\n                    \"Current player to move: {{player_to_move}}\\n\\n\"\n                    \"Recent moves: {{recent_moves}}\",\n            tags={\"chess\", \"analysis\"}\n        )\n\n        # Commentary prompt\n        self.prompts[\"commentary\"] = await self.create_prompt(\n            name=\"chess_commentary\",\n            description=\"Provides engaging commentary on chess moves\",\n            system=\"You are an engaging chess commentator like those at major tournaments. \"\n                   \"Your commentary is insightful, slightly dramatic, and helps viewers \"\n                   \"understand the significance of moves.\",\n            template=\"The position is: {{fen}}\\n\\n\"\n                    \"The move just played was: {{last_move}}\\n\\n\"\n                    \"Provide engaging commentary on this move.\",\n            tags={\"chess\", \"commentary\"}\n        )\n\n        # Teaching prompt\n        self.prompts[\"teaching\"] = await self.create_prompt(\n            name=\"chess_teaching\",\n            description=\"Explains chess concepts in an educational way\",\n            system=\"You are a patient chess coach who explains concepts clearly to students. \"\n                   \"You adapt your explanations to be appropriate for the student's rating.\",\n            template=\"Student rating: {{student_rating}}\\n\\n\"\n                    \"Explain this chess concept: {{concept}}\\n\\n\"\n                    \"If relevant, reference the current position: {{fen}}\",\n            tags={\"chess\", \"teaching\"}\n        )\n\n        # Register prompts with MCP if in server mode\n        if self._server_mode:\n            await self.register_prompts_with_server()\n\n    async def analyze_position(self, fen, player_to_move, recent_moves):\n        \"\"\"Analyze a chess position using LLM.\"\"\"\n        return await self.sample(\n            prompt_id=self.prompts[\"analysis\"].id,\n            context={\n                \"fen\": fen,\n                \"player_to_move\": player_to_move,\n                \"recent_moves\": recent_moves\n            },\n            parameters={\"temperature\": 0.3, \"max_tokens\": 800}\n        )\n\n    async def provide_commentary(self, fen, last_move):\n        \"\"\"Provide commentary for a chess move.\"\"\"\n        return await self.sample(\n            prompt_id=self.prompts[\"commentary\"].id,\n            context={\n                \"fen\": fen,\n                \"last_move\": last_move\n            },\n            parameters={\"temperature\": 0.7, \"max_tokens\": 300}\n        )\n\n    async def explain_concept(self, concept, student_rating, fen=None):\n        \"\"\"Explain a chess concept to a student.\"\"\"\n        return await self.sample(\n            prompt_id=self.prompts[\"teaching\"].id,\n            context={\n                \"concept\": concept,\n                \"student_rating\": student_rating,\n                \"fen\": fen or \"Not applicable\"\n            },\n            parameters={\"temperature\": 0.5, \"max_tokens\": 1000}\n        )\n\n# Example usage\nasync def main():\n    agent = ChessPalAgent(\n        name=\"chesspal\",\n        llm_service=\"claude\",\n        default_model=\"claude-3-sonnet-20240229\"\n    )\n    await agent.setup()\n\n    # Analyze a position\n    analysis = await agent.analyze_position(\n        fen=\"r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3\",\n        player_to_move=\"white\",\n        recent_moves=\"1. e4 e5 2. Nf3 Nc6\"\n    )\n    print(\"Analysis:\", analysis.content)\n\n    # Provide commentary on a move\n    commentary = await agent.provide_commentary(\n        fen=\"r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNBQKB1R w KQkq - 2 3\",\n        last_move=\"Nc6\"\n    )\n    print(\"Commentary:\", commentary.content)\n\n    # Explain a concept\n    explanation = await agent.explain_concept(\n        concept=\"The Italian Game opening\",\n        student_rating=1200\n    )\n    print(\"Explanation:\", explanation.content)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"guides/prompt_management/#best-practices","title":"Best Practices","text":"<ol> <li>Organize Prompts by Tags: Use tags to categorize prompts by domain, purpose, or agent type.</li> <li>Version Control: Update the version field when making significant changes to prompts.</li> <li>Storage Selection: Choose the appropriate storage backend based on your needs:</li> <li><code>MemoryPromptStorage</code> for testing or simple applications</li> <li><code>FileSystemPromptStorage</code> for persistence between runs</li> <li>Template Design: Keep templates focused and use variables consistently.</li> <li>Sampling Parameters: Tune temperature, max_tokens, and other parameters based on the task:</li> <li>Lower temperature (0.1-0.3) for factual, analytical tasks</li> <li>Medium temperature (0.4-0.7) for balanced creativity and accuracy</li> <li>Higher temperature (0.7-1.0) for creative, diverse outputs</li> <li>Error Handling: Always handle potential errors in sampling operations.</li> </ol>"},{"location":"guides/prompt_management/#api-reference","title":"API Reference","text":"<p>For complete API documentation, see: - Prompt Management API Reference - Sampling API Reference</p>"},{"location":"guides/reasoning_integration/","title":"Reasoning Integration in OpenMAS","text":"<p>OpenMAS focuses on providing a robust structure and communication layer for multi-agent systems, but it's designed to be extensible and integrate with various reasoning frameworks. This document explains how to integrate external reasoning engines, particularly Belief-Desire-Intention (BDI) frameworks, with OpenMAS agents.</p>"},{"location":"guides/reasoning_integration/#bdi-architecture-overview","title":"BDI Architecture Overview","text":"<p>The Belief-Desire-Intention (BDI) model is a framework for designing intelligent agents with three key components:</p> <ol> <li>Beliefs: The agent's knowledge about the world, itself, and other agents</li> <li>Desires: The agent's goals or objectives that it wants to achieve</li> <li>Intentions: The agent's committed plans to achieve its goals</li> </ol> <p>The BDI reasoning cycle typically involves:</p> <ol> <li>Perception: Updating beliefs based on sensory input</li> <li>Deliberation: Selecting which desires to pursue based on current beliefs</li> <li>Planning: Creating intentions (plans) to achieve selected desires</li> <li>Execution: Carrying out intentions</li> </ol>"},{"location":"guides/reasoning_integration/#bdi-integration-in-openmas","title":"BDI Integration in OpenMAS","text":"<p>OpenMAS provides a <code>BdiAgent</code> base class that extends <code>BaseAgent</code> with hooks for BDI integration. This class provides:</p> <ol> <li>Basic belief, desire, and intention management</li> <li>A structured BDI reasoning cycle</li> <li>Hooks for integrating external BDI frameworks</li> </ol>"},{"location":"guides/reasoning_integration/#bdiagent-architecture","title":"BdiAgent Architecture","text":"<p>The <code>BdiAgent</code> class has the following key components:</p> <ol> <li>Belief Management: Methods to add, update, and query beliefs</li> <li>Desire Management: Methods to add and remove desires</li> <li>Intention Management: Methods to manage intentions (plans)</li> <li>BDI Lifecycle Hooks: Overridable methods for belief update, deliberation, planning, and execution</li> <li>Event Hooks: Methods called when beliefs, desires, or intentions change</li> </ol> <p>The BDI reasoning cycle is implemented in the <code>_run_bdi_cycle</code> method, which runs continuously while the agent is active.</p>"},{"location":"guides/reasoning_integration/#integration-with-baseagent-lifecycle","title":"Integration with BaseAgent Lifecycle","text":"<p>The <code>BdiAgent</code> integrates with the <code>BaseAgent</code> lifecycle as follows:</p> <ol> <li>setup: Called when the agent starts, can be used to initialize resources</li> <li>run: Starts the BDI reasoning cycle and waits until the agent is stopped</li> <li>shutdown: Stops the BDI reasoning cycle and cleans up resources</li> </ol>"},{"location":"guides/reasoning_integration/#using-bdiagent","title":"Using BdiAgent","text":""},{"location":"guides/reasoning_integration/#basic-usage","title":"Basic Usage","text":"<p>To create a simple BDI agent, subclass <code>BdiAgent</code> and override the necessary methods:</p> <pre><code>from openmas.agent import BdiAgent\n\nclass MyBdiAgent(BdiAgent):\n    async def setup(self) -&gt; None:\n        # Initialize resources, register handlers\n        self.add_belief(\"location\", \"home\")\n        self.add_desire(\"go_to_work\")\n\n    async def update_beliefs(self) -&gt; None:\n        # Update beliefs based on perception\n        # For example, get current location from a sensor\n        current_location = await self.get_location_from_sensor()\n        self.add_belief(\"location\", current_location)\n\n    async def deliberate(self) -&gt; None:\n        # Select desires based on beliefs\n        if self.get_belief(\"location\") == \"home\" and self.get_belief(\"time\") &gt; \"08:00\":\n            self.add_desire(\"go_to_work\")\n\n    async def plan(self) -&gt; None:\n        # Create intentions to achieve desires\n        if \"go_to_work\" in self.get_all_desires():\n            self.add_intention({\n                \"id\": \"travel_to_work\",\n                \"steps\": [\"get_ready\", \"take_bus\", \"arrive_at_office\"]\n            })\n\n    async def execute_intentions(self) -&gt; None:\n        # Execute intentions\n        for intention in self.get_all_intentions():\n            if intention[\"id\"] == \"travel_to_work\":\n                await self.execute_travel_plan(intention[\"steps\"])\n</code></pre>"},{"location":"guides/reasoning_integration/#integrating-external-bdi-frameworks","title":"Integrating External BDI Frameworks","text":"<p>OpenMAS can integrate with external BDI frameworks by:</p> <ol> <li>Subclassing <code>BdiAgent</code></li> <li>Overriding the BDI lifecycle methods to integrate with the external framework</li> <li>Synchronizing the agent's state between OpenMAS and the external framework</li> </ol>"},{"location":"guides/reasoning_integration/#example-spade-bdi-integration","title":"Example: SPADE-BDI Integration","text":"<p>OpenMAS includes an example integration with the SPADE-BDI framework. The <code>SpadeBdiAgent</code> class demonstrates how to:</p> <ol> <li>Initialize a SPADE-BDI agent</li> <li>Synchronize beliefs between OpenMAS and SPADE-BDI</li> <li>Map the SPADE-BDI lifecycle to the OpenMAS BDI lifecycle</li> </ol> <pre><code>from openmas.agent import SpadeBdiAgent\n\n# Create a SPADE-BDI agent with an AgentSpeak (ASL) file\nagent = SpadeBdiAgent(name=\"my-agent\", asl_file_path=\"my_plans.asl\")\nawait agent.start()\n\n# Add a belief (will be synchronized to SPADE-BDI)\nagent.add_belief(\"location\", \"home\")\n\n# The ASL file defines plans that react to belief changes\n# For example, when the \"location\" belief changes, a plan might be triggered\n</code></pre>"},{"location":"guides/reasoning_integration/#customizing-bdi-integration","title":"Customizing BDI Integration","text":""},{"location":"guides/reasoning_integration/#creating-a-custom-bdi-integration","title":"Creating a Custom BDI Integration","text":"<p>To integrate with another BDI framework:</p> <ol> <li>Subclass <code>BdiAgent</code></li> <li>Override the BDI lifecycle methods to integrate with the external framework</li> <li>Synchronize the agent's state between OpenMAS and the external framework</li> </ol> <p>Example:</p> <pre><code>from openmas.agent import BdiAgent\nfrom external_bdi_framework import ExternalBdiEngine\n\nclass CustomBdiAgent(BdiAgent):\n    async def setup(self) -&gt; None:\n        await super().setup()\n\n        # Initialize the external BDI engine\n        self._external_bdi = ExternalBdiEngine()\n        self._external_bdi.start()\n\n    async def update_beliefs(self) -&gt; None:\n        # Synchronize beliefs from external perception to OpenMAS\n        external_beliefs = self._external_bdi.get_beliefs()\n        for belief_name, belief_value in external_beliefs.items():\n            self.add_belief(belief_name, belief_value)\n\n    async def deliberate(self) -&gt; None:\n        # Use the external BDI engine for deliberation\n        selected_desires = self._external_bdi.deliberate(self._beliefs)\n\n        # Synchronize desires to OpenMAS\n        for desire in selected_desires:\n            self.add_desire(desire)\n\n    async def plan(self) -&gt; None:\n        # Use the external BDI engine for planning\n        plans = self._external_bdi.plan(self._beliefs, self._desires)\n\n        # Synchronize plans to OpenMAS as intentions\n        for plan in plans:\n            self.add_intention(plan)\n\n    async def execute_intentions(self) -&gt; None:\n        # Execute intentions using the external BDI engine\n        for intention in self.get_all_intentions():\n            self._external_bdi.execute(intention)\n\n    async def shutdown(self) -&gt; None:\n        # Clean up the external BDI engine\n        self._external_bdi.stop()\n        await super().shutdown()\n</code></pre>"},{"location":"guides/reasoning_integration/#communication-in-bdi-agents","title":"Communication in BDI Agents","text":"<p>BDI agents can use the OpenMAS <code>Communicator</code> to interact with other agents:</p> <pre><code>class CommunicativeBdiAgent(BdiAgent):\n    async def setup(self) -&gt; None:\n        await super().setup()\n\n        # Register a handler for receiving messages\n        await self.communicator.register_handler(\"receive_message\", self.handle_message)\n\n    async def handle_message(self, message: Dict[str, Any]) -&gt; Dict[str, Any]:\n        # Update beliefs based on received message\n        self.add_belief(\"message_received\", message)\n        return {\"status\": \"message_processed\"}\n\n    async def execute_intentions(self) -&gt; None:\n        # Example: Send a message to another agent as part of intention execution\n        for intention in self.get_all_intentions():\n            if intention[\"id\"] == \"inform_agent\":\n                await self.communicator.send_request(\n                    target_service=intention[\"target\"],\n                    method=\"receive_message\",\n                    params={\"content\": intention[\"content\"]}\n                )\n</code></pre>"},{"location":"guides/reasoning_integration/#best-practices","title":"Best Practices","text":"<ol> <li>Modular Design: Keep the BDI reasoning separate from agent-specific functionality</li> <li>State Synchronization: Ensure consistent state between OpenMAS and external frameworks</li> <li>Error Handling: Handle exceptions in the BDI reasoning cycle</li> <li>Efficient Communication: Use the OpenMAS communicator for agent interaction</li> <li>Performance Considerations: Adjust the deliberation cycle interval for your use case</li> </ol>"},{"location":"guides/reasoning_integration/#references","title":"References","text":"<ul> <li>RAO (1995) BDI Agents: From Theory to Practice</li> <li>SPADE-BDI Documentation</li> <li>AgentSpeak Language</li> </ul>"},{"location":"guides/sampling_configuration/","title":"Sampling Configuration","text":"<p>This guide explains how to configure and use OpenMAS's sampling capabilities, which provide a consistent interface for generating text from language models.</p>"},{"location":"guides/sampling_configuration/#introduction","title":"Introduction","text":"<p>Sampling refers to the process of generating text from language models. OpenMAS provides a flexible sampling system that:</p> <ul> <li>Offers a consistent API across different language model providers</li> <li>Supports configuring sampling parameters in project files</li> <li>Integrates with MCP (Model Context Protocol) for enhanced functionality</li> <li>Enables testing with mock samplers</li> </ul>"},{"location":"guides/sampling_configuration/#sampling-parameters","title":"Sampling Parameters","text":"<p>Sampling parameters control how text is generated from language models. The following parameters are supported:</p> Parameter Description Default Range <code>provider</code> The sampling provider to use (e.g., \"mcp\", \"mock\") None - <code>model</code> The model to use for sampling None Provider-specific <code>temperature</code> Controls randomness - higher values produce more diverse outputs 0.7 0.0-1.0 <code>max_tokens</code> Maximum number of tokens to generate None Positive integer <code>top_p</code> Nucleus sampling parameter - limits token selection to a cumulative probability None 0.0-1.0 <code>top_k</code> Limits token selection to top k options None Positive integer <code>stop_sequences</code> List of strings that stop generation when encountered None List of strings <code>frequency_penalty</code> Penalizes repeated tokens None Provider-specific <code>presence_penalty</code> Penalizes repeated topics None Provider-specific <code>seed</code> Random seed for reproducible outputs None Integer <p>Note that not all parameters are supported by all providers, and some providers may have additional parameters not listed here.</p>"},{"location":"guides/sampling_configuration/#configuring-sampling-in-project-files","title":"Configuring Sampling in Project Files","text":"<p>The simplest way to configure sampling is through the <code>openmas_project.yml</code> file:</p> <pre><code>agents:\n  llm_agent:\n    module: \"agents.llm_agent\"\n    class: \"LlmAgent\"\n    sampling:\n      provider: \"mcp\"\n      model: \"claude-3-opus-20240229\"\n      temperature: 0.5\n      max_tokens: 2000\n      top_p: 0.9\n</code></pre> <p>This configuration creates a sampler that: - Uses the MCP provider - Uses the Claude 3 Opus model - Has a temperature of 0.5 (more deterministic than the default) - Generates at most 2000 tokens - Uses nucleus sampling with top_p of 0.9</p>"},{"location":"guides/sampling_configuration/#sampling-providers","title":"Sampling Providers","text":"<p>OpenMAS supports multiple sampling providers:</p>"},{"location":"guides/sampling_configuration/#mcp-provider","title":"MCP Provider","text":"<p>The MCP provider uses the Model Context Protocol to interact with language models:</p> <pre><code>sampling:\n  provider: \"mcp\"\n  model: \"claude-3-opus-20240229\"\n  temperature: 0.7\n</code></pre> <p>When using the MCP provider, your agent must use an MCP-compatible communicator:</p> <pre><code>communicator_type: \"mcp_sse\"  # or \"mcp_stdio\"\ncommunicator_options:\n  server_mode: false\n</code></pre>"},{"location":"guides/sampling_configuration/#mock-provider","title":"Mock Provider","text":"<p>For testing and development, you can use the mock provider:</p> <pre><code>sampling:\n  provider: \"mock\"\n  model: \"test-model\"\n</code></pre> <p>The mock provider logs sampling requests but returns a fixed response without calling an actual language model.</p>"},{"location":"guides/sampling_configuration/#using-a-sampler-in-code","title":"Using a Sampler in Code","text":""},{"location":"guides/sampling_configuration/#accessing-the-sampler-in-an-agent","title":"Accessing the Sampler in an Agent","text":"<p>If you configure sampling in your project file, the agent will automatically create a sampler for you:</p> <pre><code>from openmas.agent import BaseAgent\nfrom openmas.sampling import SamplingParameters\n\nclass MyAgent(BaseAgent):\n    async def setup(self):\n        # Setup is called automatically when the agent starts\n        # No need to create a sampler manually if configured in project file\n        if self.config.sampling:\n            # Access the sampler parameters from config\n            params = SamplingParameters(**self.config.sampling.model_dump(exclude_none=True))\n            self.sampler = get_sampler(params=params)\n        else:\n            # Create a default sampler if not configured\n            self.sampler = get_sampler(SamplingParameters())\n</code></pre>"},{"location":"guides/sampling_configuration/#sampling-from-the-sampler","title":"Sampling from the Sampler","text":"<p>To sample from a language model:</p> <pre><code>async def process_message(self, message):\n    # Create a sampling context\n    context = self.sampler.create_context(\n        system=\"You are a helpful assistant.\",\n        messages=[\n            {\"role\": \"user\", \"content\": message}\n        ],\n        parameters={\n            \"temperature\": 0.5,\n            \"max_tokens\": 1000\n        }\n    )\n\n    # Sample from the language model\n    result = await self.sampler.sample(context)\n\n    # Use the result\n    return result.content\n</code></pre>"},{"location":"guides/sampling_configuration/#using-sampling-with-prompts","title":"Using Sampling with Prompts","text":"<p>You can also sample directly from a prompt:</p> <pre><code># Get a prompt from the prompt manager\nprompt = await self.prompt_manager.get_prompt(\"analyze_text\")\n\n# Sample from the prompt\nresult = await self.sampler.sample_from_prompt(\n    prompt=prompt,\n    context_vars={\"text\": input_text, \"analysis_depth\": \"deep\"},\n    parameters={\"temperature\": 0.3}  # Override default parameters\n)\n</code></pre>"},{"location":"guides/sampling_configuration/#working-with-mcp-samplers","title":"Working with MCP Samplers","text":"<p>The MCP sampler integrates with the MCP protocol to provide enhanced functionality.</p>"},{"location":"guides/sampling_configuration/#mcp-specific-configuration","title":"MCP-Specific Configuration","text":"<p>When using the MCP provider, you need to:</p> <ol> <li>Configure your agent to use an MCP communicator</li> <li>Specify the target service for language model requests</li> </ol> <pre><code>agents:\n  mcp_agent:\n    module: \"agents.mcp_agent\"\n    class: \"McpAgent\"\n    communicator_type: \"mcp_sse\"\n    communicator_options:\n      server_mode: false\n    service_urls:\n      llm_service: \"http://localhost:8080/v1\"\n    sampling:\n      provider: \"mcp\"\n      model: \"claude-3-opus-20240229\"\n</code></pre>"},{"location":"guides/sampling_configuration/#using-the-promptmcpagent","title":"Using the <code>PromptMcpAgent</code>","text":"<p>For convenience, OpenMAS provides a <code>PromptMcpAgent</code> class that combines prompt management and sampling capabilities:</p> <pre><code>from openmas.agent import PromptMcpAgent\n\n# Create the agent\nagent = PromptMcpAgent(\n    name=\"analyzer\",\n    llm_service=\"llm_service\",  # Service name defined in service_urls\n    default_model=\"claude-3-opus-20240229\"\n)\n\n# Setup the agent\nawait agent.setup()\n\n# Create a prompt\nprompt_id = await agent.create_prompt(\n    name=\"analyze\",\n    system=\"You are an analytical assistant.\",\n    template=\"Please analyze the following text: {{text}}\"\n)\n\n# Sample using the prompt\nresult = await agent.sample(\n    prompt_id=prompt_id,\n    context={\"text\": input_text},\n    parameters={\"temperature\": 0.5}\n)\n</code></pre>"},{"location":"guides/sampling_configuration/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Define Sampling Parameters in Project Files: This makes it easy to adjust parameters without changing code.</p> </li> <li> <p>Use Different Temperatures for Different Tasks:</p> </li> <li>Lower temperatures (0.0-0.5) for factual or structured output</li> <li>Medium temperatures (0.5-0.8) for creative but controlled text</li> <li> <p>Higher temperatures (0.8-1.0) for more creative or exploratory outputs</p> </li> <li> <p>Set Appropriate Max Tokens: Estimate the maximum length of the expected response and add a safety margin.</p> </li> <li> <p>Use Stop Sequences Wisely: Define stop sequences to prevent the model from continuing beyond the needed response.</p> </li> <li> <p>Consider Using Seeds for Reproducibility: When testing or when deterministic outputs are required, set a seed value.</p> </li> <li> <p>Mock for Testing: Use the mock provider during testing to avoid calling actual language models.</p> </li> </ol>"},{"location":"guides/testing-utilities/","title":"Testing Your OpenMAS Applications","text":"<p>OpenMAS provides utilities to help you write robust unit and integration tests for your own multi-agent systems. This guide focuses on how to use these tools: <code>MockCommunicator</code> and <code>AgentTestHarness</code>.</p> <p>These utilities allow you to test your agent's logic and interactions in isolation, without needing to run real dependent services or manage complex network setups during testing.</p>"},{"location":"guides/testing-utilities/#important-testing-concepts-to-understand-first","title":"Important Testing Concepts to Understand First","text":"<p>Before diving into the specifics of OpenMAS testing utilities, it's important to understand the core testing approach:</p>"},{"location":"guides/testing-utilities/#1-expectation-based-testing-not-direct-communication","title":"1. Expectation-Based Testing (NOT Direct Communication)","text":"<p>When using <code>MockCommunicator</code> for testing, you're not establishing real communication between agents. Instead, you're:</p> <ul> <li>Setting up expectations for what messages should be sent</li> <li>Having your agent code execute and attempt to send those messages</li> <li>Verifying that the expected messages were sent with the correct parameters</li> </ul> <p>This pattern is different from trying to simulate real message passing between agents. The mock is primarily a validation tool.</p>"},{"location":"guides/testing-utilities/#2-required-agent-implementation","title":"2. Required Agent Implementation","text":"<p>All agent classes in OpenMAS must implement specific abstract methods from <code>BaseAgent</code>:</p> <ul> <li><code>setup()</code>: Initialize the agent</li> <li><code>run()</code>: The main agent logic</li> <li><code>shutdown()</code>: Clean up resources</li> </ul> <p>If you don't implement these methods in your agent classes, you'll receive errors when trying to use them with the testing harness.</p>"},{"location":"guides/testing-utilities/#3-test-harness-vs-direct-agent-creation","title":"3. Test Harness vs. Direct Agent Creation","text":"<p>There are two main approaches to testing: - Using <code>AgentTestHarness</code> to manage agent lifecycle and provide mocked communicators - Creating agents directly and manually configuring mocked communicators</p> <p>The examples below will show both approaches.</p>"},{"location":"guides/testing-utilities/#using-mockcommunicator","title":"Using <code>MockCommunicator</code>","text":"<p>The <code>MockCommunicator</code> (<code>openmas.testing.MockCommunicator</code>) is a powerful tool for testing individual agents. It acts as a stand-in for a real communicator (like <code>HttpCommunicator</code> or <code>McpSseCommunicator</code>), allowing you to:</p> <ul> <li>Define expected outgoing requests or notifications your agent should send.</li> <li>Simulate incoming responses or errors for those requests.</li> <li>Verify that your agent sent the expected messages.</li> <li>Register mock handlers and trigger them to test your agent's response logic.</li> </ul>"},{"location":"guides/testing-utilities/#basic-setup-using-pytest-fixtures","title":"Basic Setup (using <code>pytest</code> fixtures)","text":"<p>A common pattern is to create a <code>pytest</code> fixture for your mock communicator:</p> <pre><code>import pytest\nfrom openmas.testing import MockCommunicator\n\n@pytest.fixture\ndef mock_communicator():\n    \"\"\"Provides a MockCommunicator instance for tests.\"\"\"\n    # Initialize with the name your agent would typically use\n    comm = MockCommunicator(agent_name=\"my-test-agent\")\n    yield comm\n    # Optional: Automatically verify all expectations are met at the end of the test\n    comm.verify()\n</code></pre> <p>You can then inject this fixture into your test functions.</p>"},{"location":"guides/testing-utilities/#setting-expectations-and-verifying-requests","title":"Setting Expectations and Verifying Requests","text":"<p>You can tell the <code>MockCommunicator</code> what <code>send_request</code> calls to expect from your agent and what response to return.</p> <pre><code>from my_project.agents import DataProcessingAgent # Your agent class\n\n@pytest.mark.asyncio\nasync def test_agent_fetches_user_data(mock_communicator):\n    # Instantiate your agent, passing the mock communicator\n    # You might need to adapt this based on how your agent gets its communicator\n    agent = DataProcessingAgent(name=\"test-processor\", communicator=mock_communicator)\n\n    # 1. Expect the agent to call send_request to 'data-service'\n    mock_communicator.expect_request(\n        target_service=\"data-service\",\n        method=\"get_user\",\n        params={\"user_id\": \"123\"},\n        # Define the response the mock should return\n        response={\"name\": \"Test User\", \"email\": \"test@example.com\"}\n    )\n\n    # 2. Run the part of your agent's logic that makes the request\n    user_data = await agent.process_user(\"123\") # Assume this method calls send_request\n\n    # 3. Assert based on the mocked response\n    assert user_data[\"name\"] == \"Test User\"\n    assert user_data[\"email\"] == \"test@example.com\"\n\n    # 4. Verify expectations (if not done in the fixture)\n    # mock_communicator.verify()\n</code></pre>"},{"location":"guides/testing-utilities/#advanced-parameter-matching","title":"Advanced Parameter Matching","text":"<p>When setting expectations, you don't always need to match parameters exactly. <code>MockCommunicator</code> supports flexible matching:</p> <ul> <li>Any Parameters: Set <code>params=None</code> in <code>expect_request</code> to match any parameters for that service/method call.</li> <li>Regex Matching: Provide a compiled regex object (<code>re.compile(...)</code>) as a value in the <code>params</code> dictionary to match string parameters against a pattern.</li> <li>Custom Matcher Functions: Provide a function as a value in the <code>params</code> dictionary. This function will receive the actual parameter value and should return <code>True</code> if it matches, <code>False</code> otherwise.</li> <li>Subset Dictionary Matching: Provide a dictionary for <code>params</code>. The actual parameters must contain at least these key-value pairs (extra keys in the actual parameters are ignored).</li> </ul> <pre><code>import re\nfrom openmas.testing import MockCommunicator\n\n@pytest.mark.asyncio\nasync def test_advanced_matching(mock_communicator):\n    # Expect a call to 'process' method with any parameters\n    mock_communicator.expect_request(\n        target_service=\"worker-service\", method=\"process\", params=None, response={}\n    )\n\n    # Expect a call where 'item_id' matches a pattern\n    mock_communicator.expect_request(\n        target_service=\"inventory\", method=\"get_item\",\n        params={\"item_id\": re.compile(r\"ITEM-\\d{4}\")}, response={}\n    )\n\n    # Expect a call where 'quantity' is positive\n    def is_positive(val): return isinstance(val, int) and val &gt; 0\n    mock_communicator.expect_request(\n        target_service=\"orders\", method=\"place_order\",\n        params={\"item_id\": \"ABC\", \"quantity\": is_positive}, response={}\n    )\n\n    # Expect a call with a nested structure (only checks 'profile.id')\n    mock_communicator.expect_request(\n        target_service=\"users\", method=\"update_user\",\n        params={\"user\": {\"profile\": {\"id\": 123}}}, response={}\n    )\n\n    # --- Code that triggers the agent to make these calls ---\n    # await agent.do_work_any()\n    # await agent.fetch_item(\"ITEM-1234\")\n    # await agent.create_order(\"ABC\", 5)\n    # await agent.save_user_profile(123, {\"name\": \"Test\", \"extra\": \"data\"})\n\n    mock_communicator.verify()\n</code></pre>"},{"location":"guides/testing-utilities/#testing-notifications-send_notification","title":"Testing Notifications (<code>send_notification</code>)","text":"<p>Testing outgoing notifications is similar to requests, but you don't expect a response.</p> <pre><code>@pytest.mark.asyncio\nasync def test_agent_sends_event_notification(mock_communicator, agent):\n    # Expect the agent to send a notification\n    mock_communicator.expect_notification(\n        target_service=\"logging-service\",\n        method=\"log_event\",\n        params={\"level\": \"info\", \"message\": \"Processing complete for user X\"}\n    )\n\n    # Run agent logic that triggers the notification\n    await agent.finish_processing(\"user X\")\n\n    # Verify\n    mock_communicator.verify()\n</code></pre>"},{"location":"guides/testing-utilities/#testing-handlers-register_handler","title":"Testing Handlers (<code>register_handler</code>)","text":"<p>You can test if your agent correctly registers handlers and how those handlers behave when triggered.</p> <pre><code>@pytest.mark.asyncio\nasync def test_agent_registers_and_handles_greet(mock_communicator, agent):\n    # 1. Run the agent's setup logic (which should call register_handler)\n    await agent.setup()\n\n    # 2. Check if the handler was registered\n    assert \"greet\" in mock_communicator._handlers  # Access internal _handlers dict\n\n    # 3. Trigger the registered handler with test data\n    # This simulates an incoming request to the agent's 'greet' method\n    response = await mock_communicator.trigger_handler(\n        method=\"greet\",\n        params={\"name\": \"Tester\"}\n    )\n\n    # 4. Assert the response returned by the agent's handler\n    assert response == {\"message\": \"Hello, Tester!\"}\n\n    # No verify needed here unless other expectations were set\n</code></pre>"},{"location":"guides/testing-utilities/#testing-error-conditions","title":"Testing Error Conditions","text":"<p>You can configure the <code>MockCommunicator</code> to simulate errors when your agent makes requests.</p> <pre><code>import pytest\nfrom openmas.exceptions import ServiceNotFoundError, CommunicationError\n\n@pytest.mark.asyncio\nasync def test_agent_handles_service_not_found(mock_communicator, agent):\n    # Expect a request, but configure it to raise an exception\n    mock_communicator.expect_request_exception(\n        target_service=\"nonexistent-service\",\n        method=\"get_info\",\n        params={},\n        exception=ServiceNotFoundError(\"Service 'nonexistent-service' not found\")\n    )\n\n    # Use pytest.raises to assert that the agent's call triggers the expected exception\n    with pytest.raises(ServiceNotFoundError):\n        await agent.fetch_info_from_nonexistent_service()\n\n    mock_communicator.verify()\n</code></pre>"},{"location":"guides/testing-utilities/#using-agenttestharness","title":"Using <code>AgentTestHarness</code>","text":"<p>The <code>AgentTestHarness</code> (<code>openmas.testing.AgentTestHarness</code>) builds upon <code>MockCommunicator</code> to provide a higher-level way to manage and test agents within your tests.</p> <p>Key Benefits:</p> <ul> <li>Lifecycle Management: Easily create, start (<code>setup</code>, <code>run</code>), and stop (<code>shutdown</code>) agents within tests.</li> <li>Automatic Mocking: Automatically creates and injects <code>MockCommunicator</code> instances into the agents it manages.</li> <li>Multi-Agent Testing: Manages multiple agents and their mock communicators, simplifying the testing of interactions.</li> </ul>"},{"location":"guides/testing-utilities/#important-notes-about-agenttestharness","title":"Important Notes About AgentTestHarness","text":"<ol> <li> <p>Agent Class Requirements: <code>AgentTestHarness</code> requires you to pass the agent class, not an instance. The harness will create instances for you. Your agent class must implement all abstract methods from <code>BaseAgent</code> (<code>setup</code>, <code>run</code>, <code>shutdown</code>).</p> </li> <li> <p>No Automatic Agent Linking: The harness doesn't automatically establish communication between agents. You must set up appropriate expectations for each agent's communicator.</p> </li> <li> <p>Using Expectations Not Direct Communication: Remember that you're testing with expectations rather than real communication. This means setting up what messages you expect agents to send, not trying to make them talk to each other directly.</p> </li> </ol>"},{"location":"guides/testing-utilities/#basic-single-agent-testing","title":"Basic Single Agent Testing","text":"<pre><code>import pytest\nfrom openmas.testing import AgentTestHarness\nfrom my_project.agents import MyAgent # Your agent class\n\n@pytest.mark.asyncio\nasync def test_my_agent_behavior():\n    # Create a harness for the agent class\n    harness = AgentTestHarness(MyAgent)\n\n    # Create an agent instance (with a mock communicator)\n    agent = await harness.create_agent(name=\"test-agent\")\n\n    # Set up expectations for messages the agent will send\n    agent.communicator.expect_request(\n        target_service=\"data-service\",\n        method=\"get_data\",\n        params={\"id\": \"12345\"},\n        response={\"data\": \"test result\"}\n    )\n\n    # Use the running_agent context manager to manage lifecycle\n    async with harness.running_agent(agent):\n        # The agent is now set up and running\n\n        # Trigger some behavior that causes the agent to send a request\n        await agent.process_item(\"12345\")\n\n        # Verify that the expected communication happened\n        agent.communicator.verify()\n\n        # Make assertions about the agent's state\n        assert agent.processed_items == [\"12345\"]\n</code></pre>"},{"location":"guides/testing-utilities/#simplified-multi-agent-testing-helpers","title":"Simplified Multi-Agent Testing Helpers","text":"<p>OpenMAS provides several helper utilities to make multi-agent testing easier and more concise. These utilities are particularly useful for common testing patterns like testing communication between a sender and receiver agent.</p>"},{"location":"guides/testing-utilities/#setting-up-sender-receiver-tests","title":"Setting Up Sender-Receiver Tests","text":"<p>The <code>setup_sender_receiver_test</code> function simplifies creating a pair of connected test agents:</p> <pre><code>import pytest\nfrom openmas.testing import setup_sender_receiver_test, expect_sender_request, multi_running_agents\n\n@pytest.mark.asyncio\nasync def test_sender_receiver_communication():\n    # Create both agents with a single call\n    sender_harness, receiver_harness, sender, receiver = await setup_sender_receiver_test(\n        SenderAgent, ReceiverAgent\n    )\n\n    # Set up expectations for the sender's communication\n    expect_sender_request(\n        sender,\n        \"receiver\",  # target agent name\n        \"process_data\",  # method to call\n        {\"message\": \"hello\"},  # expected parameters\n        {\"status\": \"ok\", \"processed\": True}  # response to return\n    )\n\n    # Run both agents in a single context manager\n    async with multi_running_agents(sender_harness, sender, receiver_harness, receiver):\n        # Trigger the sender's logic\n        await sender.send_message(\"hello\")\n\n        # Verify expectations were met\n        sender.communicator.verify()\n</code></pre>"},{"location":"guides/testing-utilities/#setting-message-expectations","title":"Setting Message Expectations","text":"<p>Instead of directly calling <code>agent.communicator.expect_request()</code>, you can use these more intuitive helper functions:</p> <pre><code>from openmas.testing import expect_sender_request, expect_notification\n\n# Set up a request expectation\nexpect_sender_request(\n    agent,  # the agent that will send the request\n    \"target-service\",  # name of the target service/agent\n    \"method-name\",  # method to call\n    {\"param1\": \"value1\"},  # expected parameters\n    {\"result\": \"success\"}  # response to return\n)\n\n# Set up a notification expectation\nexpect_notification(\n    agent,  # the agent that will send the notification\n    \"logger-service\",  # target service\n    \"log_event\",  # notification method\n    {\"level\": \"info\", \"message\": \"test\"}  # expected parameters\n)\n</code></pre>"},{"location":"guides/testing-utilities/#running-multiple-agents","title":"Running Multiple Agents","text":"<p>The <code>multi_running_agents</code> function provides a single context manager for running multiple agents:</p> <pre><code>from openmas.testing import multi_running_agents\n\n# Instead of nested context managers:\n# async with harness1.running_agent(agent1):\n#     async with harness2.running_agent(agent2):\n#         # test code here\n\n# Use the simpler multi_running_agents:\nasync with multi_running_agents(harness1, agent1, harness2, agent2, harness3, agent3):\n    # All agents are now running\n\n    # Trigger agent behavior\n    await agent1.do_something()\n\n    # Verify expectations\n    agent1.communicator.verify()\n    agent2.communicator.verify()\n    agent3.communicator.verify()\n</code></pre>"},{"location":"guides/testing-utilities/#complete-multi-agent-test-example","title":"Complete Multi-Agent Test Example","text":"<p>Here's a complete example showing how the helpers simplify multi-agent testing:</p> <pre><code>import pytest\nfrom openmas.testing import (\n    setup_sender_receiver_test,\n    expect_sender_request,\n    multi_running_agents\n)\nfrom my_project.agents import DataSenderAgent, DataProcessorAgent\n\n@pytest.mark.asyncio\nasync def test_data_processing_flow():\n    # Set up sender and receiver agents\n    sender_harness, processor_harness, sender, processor = await setup_sender_receiver_test(\n        DataSenderAgent, DataProcessorAgent,\n        sender_name=\"data-sender\",\n        receiver_name=\"data-processor\"\n    )\n\n    # Set up expectations for the communication\n    expect_sender_request(\n        sender,\n        \"data-processor\",\n        \"process_data\",\n        {\"data\": {\"id\": \"123\", \"value\": \"test\"}},\n        {\"status\": \"processed\", \"result\": \"SUCCESS\"}\n    )\n\n    # Run both agents\n    async with multi_running_agents(sender_harness, sender, processor_harness, processor):\n        # Trigger the sender to send data\n        await sender.send_data_item(\"123\", \"test\")\n\n        # Verify the communication happened as expected\n        sender.communicator.verify()\n\n        # Check agent state if needed\n        assert sender.sent_items == [\"123\"]\n        assert processor.processed_items == [\"123\"]\n</code></pre>"},{"location":"guides/testing-utilities/#best-practices-for-testing-multi-agent-systems","title":"Best Practices for Testing Multi-Agent Systems","text":"<p>When testing OpenMAS multi-agent systems, especially with mocked communicators, consider these best practices:</p> <ol> <li> <p>Keep Tests Focused: Test one specific interaction or behavior in each test case.</p> </li> <li> <p>Separate Unit vs. Integration Tests: Use <code>MockCommunicator</code> for unit tests of individual agents, and real communicators (or a mix of real and mock) for integration tests.</p> </li> <li> <p>Use Helper Functions: Leverage the helper functions (<code>setup_sender_receiver_test</code>, <code>expect_sender_request</code>, etc.) for cleaner, more maintainable test code.</p> </li> <li> <p>Prefer Clear Expectations: Set specific expectations rather than using <code>params=None</code> when possible, to catch bugs in parameter handling.</p> </li> <li> <p>Verify All Communicators: Remember to call <code>verify()</code> on every mock communicator to ensure all expected communications happened.</p> </li> <li> <p>Test Error Handling: Use <code>expect_request_exception</code> to verify your agents handle errors gracefully.</p> </li> <li> <p>Lifecycle Management: Use <code>running_agents</code> (or <code>harness.running_agent</code>) to properly manage agent lifecycle, ensuring <code>setup</code>, <code>run</code>, and <code>shutdown</code> methods are called.</p> </li> <li> <p>Check for Clear Error Messages: If you expect a test to fail, assert on the specific error message rather than just the error type. This helps maintain helpful error reporting.</p> </li> </ol> <p>By following these patterns, you can build robust tests for your OpenMAS agents that are easier to maintain and provide better verification of your system's behavior.</p>"},{"location":"guides/testing-utilities/#choosing-the-right-testing-approach","title":"Choosing the Right Testing Approach","text":"<p>OpenMAS provides different levels of testing utilities, from low-level mocks to high-level helpers. Here's how to choose which approach is right for your needs:</p>"},{"location":"guides/testing-utilities/#helper-functions-highest-level","title":"Helper Functions (Highest Level)","text":"<p>Examples: <code>setup_sender_receiver_test</code>, <code>expect_sender_request</code>, <code>multi_running_agents</code></p> <p>Best for: - Quick setup of standard sender-receiver test scenarios - Minimal boilerplate code - Clear, readable tests - Most common testing patterns</p> <pre><code># Example using helper functions\nsender_harness, receiver_harness, sender, receiver = await setup_sender_receiver_test(\n    SenderAgent, ReceiverAgent\n)\nexpect_sender_request(sender, \"receiver\", \"process\", params, response)\nasync with multi_running_agents(sender_harness, sender, receiver_harness, receiver):\n    await sender.run()\n</code></pre>"},{"location":"guides/testing-utilities/#agenttestharness-middle-level","title":"AgentTestHarness (Middle Level)","text":"<p>Best for: - Custom agent configurations - Non-standard test scenarios - When you need more control over agent lifecycle - Testing agents individually</p> <pre><code># Example using AgentTestHarness directly\nharness = AgentTestHarness(MyAgent)\nagent = await harness.create_agent(name=\"test-agent\", config={\"custom\": True})\n# Set up expectations manually\nagent.communicator.expect_request(...)\nasync with harness.running_agent(agent):\n    await agent.custom_method()\n</code></pre>"},{"location":"guides/testing-utilities/#mockcommunicator-low-level","title":"MockCommunicator (Low Level)","text":"<p>Best for: - Complex mocking scenarios - Custom parameter matching - Testing handler behavior directly - When you need maximum control over mocking</p> <pre><code># Example using MockCommunicator directly\ncommunicator = MockCommunicator(agent_name=\"test\")\n# Attach to an agent manually\nagent.communicator = communicator\n# Advanced expectation setup\ncommunicator.expect_request(\n    target_service=\"service\",\n    method=\"operation\",\n    params={\"id\": re.compile(r\"\\d+\")},  # Regex matching\n    response={\"result\": \"data\"}\n)\n</code></pre>"},{"location":"guides/testing-utilities/#decision-table","title":"Decision Table","text":"If you need to... Use this approach Test a simple sender-receiver pattern Helper functions (<code>setup_sender_receiver_test</code>, etc.) Run multiple agents in a test <code>multi_running_agents</code> Configure agents with custom settings Direct <code>AgentTestHarness</code> Test complex parameter matching Direct <code>MockCommunicator</code> Assert agent state changes Direct <code>AgentTestHarness</code> Trigger handlers directly Direct <code>MockCommunicator.trigger_handler()</code>"},{"location":"guides/testing-utilities/#testing-mcp-agents","title":"Testing MCP Agents","text":""},{"location":"guides/testing-utilities/#testing-mcp-stdio-tools","title":"Testing MCP stdio Tools","text":"<p>Testing agents that use the <code>McpStdioCommunicator</code> requires some special considerations, as it involves process management and stdin/stdout communication. Here are the recommended approaches:</p>"},{"location":"guides/testing-utilities/#unit-testing-with-mock-communicator","title":"Unit Testing with Mock Communicator","text":"<p>For unit tests, you can mock the <code>McpStdioCommunicator</code> to avoid spawning real processes:</p> <pre><code>import pytest\nfrom unittest import mock\nfrom openmas.agent import BaseAgent\nfrom openmas.communication.mcp import McpStdioCommunicator\n\nclass ToolUserAgent(BaseAgent):\n    # Agent implementation...\n    pass\n\n@pytest.fixture\ndef mock_stdio_communicator():\n    \"\"\"Create a mocked stdio communicator.\"\"\"\n    communicator = mock.AsyncMock(spec=McpStdioCommunicator)\n\n    # Mock the call_tool method to return a predefined result\n    async def mock_call_tool(target_service, tool_name, arguments):\n        if tool_name == \"process_data\" and \"text\" in arguments:\n            text = arguments[\"text\"]\n            return {\n                \"processed_text\": text.upper(),\n                \"word_count\": len(text.split()),\n                \"status\": \"success\"\n            }\n        return {\"status\": \"error\", \"error\": \"Unknown tool or invalid arguments\"}\n\n    communicator.call_tool.side_effect = mock_call_tool\n    return communicator\n\n@pytest.mark.asyncio\nasync def test_tool_user_with_mock_communicator(mock_stdio_communicator):\n    \"\"\"Test the tool user agent with a mock communicator.\"\"\"\n    agent = ToolUserAgent(name=\"test-agent\")\n    agent.set_communicator(mock_stdio_communicator)\n\n    await agent.setup()\n    await agent.run()\n\n    # Verify the tool was called with expected arguments\n    mock_stdio_communicator.call_tool.assert_called_once()\n    call_args = mock_stdio_communicator.call_tool.call_args[1]\n    assert call_args[\"tool_name\"] == \"process_data\"\n    assert \"text\" in call_args[\"arguments\"]\n</code></pre>"},{"location":"guides/testing-utilities/#integration-testing-with-standalone-scripts","title":"Integration Testing with Standalone Scripts","text":"<p>For integration testing, create a standalone MCP server script that implements the tool functionality:</p> <pre><code>import asyncio\nimport json\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nfrom mcp.server.fastmcp import Context, FastMCP\n\ndef create_tool_server_script() -&gt; str:\n    \"\"\"Create a standalone MCP server script for testing.\"\"\"\n    return \"\"\"\n#!/usr/bin/env python\n\nimport asyncio\nimport json\nimport sys\nfrom mcp.server.fastmcp import Context, FastMCP\n\n# Create the server\nserver = FastMCP(\"TestToolServer\")\n\n@server.tool(\"process_data\", description=\"Process incoming data\")\nasync def process_data(context: Context, text: str = \"\") -&gt; str:\n    # Process the data\n    if text:\n        processed_text = text.upper()\n        word_count = len(text.split())\n\n        result = {\n            \"processed_text\": processed_text,\n            \"word_count\": word_count,\n            \"status\": \"success\"\n        }\n    else:\n        result = {\n            \"error\": \"No text provided\",\n            \"status\": \"error\"\n        }\n\n    # Return JSON string\n    return json.dumps(result)\n\n# Run the server\nasyncio.run(server.run_stdio_async())\n\"\"\"\n\n@pytest.mark.asyncio\n@pytest.mark.integration\nasync def test_real_mcp_stdio_tool_call():\n    \"\"\"Test real MCP stdio tool calls with a standalone server script.\"\"\"\n    # Create the server script\n    script_content = create_tool_server_script()\n\n    # Write the script to a temp file\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as tmp:\n        tmp.write(script_content)\n        script_path = tmp.name\n\n    # Make it executable\n    os.chmod(script_path, 0o755)\n\n    # Process handle for cleanup\n    process = None\n\n    try:\n        from openmas.agent import BaseAgent\n        from openmas.communication.mcp import McpStdioCommunicator\n\n        # Create a tool user agent\n        agent = BaseAgent(name=\"test-tool-user\")\n\n        # Configure the communicator to use the script\n        communicator = McpStdioCommunicator(\n            agent_name=agent.name,\n            server_mode=False,\n            service_urls={\n                \"test_tool_server\": f\"stdio:{sys.executable} {script_path}\"\n            }\n        )\n        agent.set_communicator(communicator)\n\n        # Call the tool\n        await agent.setup()\n\n        # Test the tool call\n        result = await communicator.call_tool(\n            target_service=\"test_tool_server\",\n            tool_name=\"process_data\",\n            arguments={\"text\": \"Hello, test!\"}\n        )\n\n        # Verify the result\n        assert result[\"status\"] == \"success\"\n        assert result[\"processed_text\"] == \"HELLO, TEST!\"\n        assert result[\"word_count\"] == 2\n\n    finally:\n        # Clean up\n        if process and process.returncode is None:\n            try:\n                process.terminate()\n                await asyncio.sleep(0.5)\n                if process.returncode is None:\n                    process.kill()\n            except Exception:\n                pass\n\n        # Clean up the temp file\n        try:\n            os.unlink(script_path)\n        except Exception:\n            pass\n</code></pre>"},{"location":"guides/testing-utilities/#testing-timeout-handling","title":"Testing Timeout Handling","text":"<p>Properly testing timeout handling is important for robust MCP stdio communication:</p> <pre><code>@pytest.mark.asyncio\n@pytest.mark.integration\nasync def test_timeout_handling():\n    \"\"\"Test timeout handling with MCP stdio tool calls.\"\"\"\n    # Create a script that implements a slow tool\n    slow_tool_script = \"\"\"\n#!/usr/bin/env python\n\nimport asyncio\nimport json\nimport sys\nfrom mcp.server.fastmcp import Context, FastMCP\n\nserver = FastMCP(\"SlowToolServer\")\n\n@server.tool(\"slow_process\", description=\"A tool that takes a long time\")\nasync def slow_process(context: Context, text: str = \"\") -&gt; str:\n    # Simulate a slow operation\n    await asyncio.sleep(10.0)  # Sleep for 10 seconds\n\n    result = {\n        \"processed_text\": text.upper(),\n        \"status\": \"success\"\n    }\n    return json.dumps(result)\n\nasyncio.run(server.run_stdio_async())\n\"\"\"\n\n    # Write the script to a temp file\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as tmp:\n        tmp.write(slow_tool_script)\n        script_path = tmp.name\n\n    # Make it executable\n    os.chmod(script_path, 0o755)\n\n    try:\n        from openmas.agent import BaseAgent\n        from openmas.communication.mcp import McpStdioCommunicator\n\n        # Create a tool user agent\n        agent = BaseAgent(name=\"test-timeout-user\")\n\n        # Configure the communicator\n        communicator = McpStdioCommunicator(\n            agent_name=agent.name,\n            server_mode=False,\n            service_urls={\n                \"slow_tool_server\": f\"stdio:{sys.executable} {script_path}\"\n            }\n        )\n        agent.set_communicator(communicator)\n\n        # Set up the agent\n        await agent.setup()\n\n        # Call the slow tool with a short timeout\n        with pytest.raises(asyncio.TimeoutError):\n            await asyncio.wait_for(\n                communicator.call_tool(\n                    target_service=\"slow_tool_server\",\n                    tool_name=\"slow_process\",\n                    arguments={\"text\": \"This should time out\"}\n                ),\n                timeout=2.0  # 2-second timeout (shorter than the 10-second sleep)\n            )\n\n    finally:\n        # Clean up the temp file\n        try:\n            os.unlink(script_path)\n        except Exception:\n            pass\n</code></pre>"},{"location":"guides/testing-utilities/#best-practices-for-testing-mcp-stdio","title":"Best Practices for Testing MCP stdio","text":"<ol> <li>Use temporary files for server scripts to avoid leaving artifacts</li> <li>Clean up processes explicitly to avoid orphaned processes</li> <li>Implement proper timeout handling in both tests and production code</li> <li>Capture stderr output from subprocesses for better debugging</li> <li>Test both success and error cases to ensure robust error handling</li> <li>Use mocks for unit tests and real processes for integration tests</li> <li>Include process management edge cases in your test suite</li> </ol>"},{"location":"guides/communication/","title":"Communication in OpenMAS","text":"<p>This document provides an overview of the communication protocols in OpenMAS, explaining when and how to use each one.</p>"},{"location":"guides/communication/#communication-overview","title":"Communication Overview","text":"<p>OpenMAS provides a flexible communication layer that abstracts away the complexity of different communication protocols. The core of this system is the <code>BaseCommunicator</code> abstract base class, which defines the standard interface for sending requests (<code>send_request</code>), sending notifications (<code>send_notification</code>), and registering handlers for incoming messages (<code>register_handler</code>). All specific protocol implementations (like <code>HttpCommunicator</code>, <code>McpSseCommunicator</code>, etc.) inherit from <code>BaseCommunicator</code>.</p> <p>An agent's communicator is typically instantiated automatically by <code>BaseAgent</code> based on the <code>communicator_type</code> and <code>communicator_options</code> specified in the agent's configuration.</p>"},{"location":"guides/communication/#lazy-loading-of-communicators","title":"Lazy Loading of Communicators","text":"<p>A key design principle in OpenMAS is lazy loading for optional components, especially communicators that require extra dependencies.</p> <ul> <li>Core vs. Optional: The <code>HttpCommunicator</code> (using <code>httpx</code>) might be considered core or have minimal dependencies. Communicators for MCP (<code>mcp</code>), gRPC (<code>grpcio</code>), and MQTT (<code>paho-mqtt</code>) require specific third-party libraries.</li> <li>Mechanism: OpenMAS does not require you to install all possible communication libraries just to use the core framework. When <code>BaseAgent</code> initializes, it looks at the configured <code>communicator_type</code>. If it's a non-core type (e.g., \"grpc\", \"mcp_sse\", \"mqtt\"), the framework attempts to dynamically import the necessary communicator class (<code>GrpcCommunicator</code>, <code>McpSseCommunicator</code>, etc.) using <code>importlib</code>.</li> <li>Dependency Management: If the import fails because the required underlying library (e.g., <code>grpcio</code> for <code>GrpcCommunicator</code>) is not installed in your environment, OpenMAS will raise an <code>ImportError</code> or a specific <code>ConfigurationError</code> guiding you to install the necessary optional dependency.</li> <li>Installation: You install support for optional communicators using pip extras:     <pre><code># Install core openmas\npip install openmas\n\n# Install support for gRPC\npip install 'openmas[grpc]'\n\n# Install support for MCP (includes mcp-sdk)\npip install 'openmas[mcp]'\n\n# Install support for MQTT\npip install 'openmas[mqtt]'\n\n# Install multiple extras\npip install 'openmas[grpc,mcp]'\n\n# Install all optional communicators and features\npip install 'openmas[all]'\n</code></pre>     (Use <code>poetry add 'openmas[extra]'</code> if using Poetry).</li> </ul> <p>This approach keeps the core <code>openmas</code> package lightweight and ensures users only install what they need.</p>"},{"location":"guides/communication/#available-protocols-communicators","title":"Available Protocols &amp; Communicators","text":"<p>OpenMAS provides multiple communication protocols to suit different needs:</p>"},{"location":"guides/communication/#http-httpcommunicator","title":"HTTP (<code>HttpCommunicator</code>)","text":"<ul> <li>Protocol: Standard HTTP/1.1 (using <code>httpx</code>).</li> <li>Best For: RESTful API interactions, web service integration, general-purpose request/response communication between agents/services across processes or machines.</li> <li>Dependencies: <code>httpx</code> (likely a core dependency).</li> <li>Configuration: <code>communicator_type: http</code>. Options like <code>http_port</code> (server mode), <code>timeout</code>, <code>retries</code> can be set in <code>communicator_options</code>.</li> </ul>"},{"location":"guides/communication/#model-context-protocol-mcp","title":"Model Context Protocol (MCP)","text":"<p>MCP is designed for interacting with AI models and tools, particularly from Anthropic. OpenMAS provides two communicators for MCP. Requires <code>openmas[mcp]</code>.</p> <ol> <li> <p><code>McpSseCommunicator</code></p> <ul> <li>Protocol: MCP over HTTP Server-Sent Events (SSE).</li> <li>Best For: Networked MCP communication. Running an agent as an HTTP-based MCP server (e.g., for a UI to connect to) or connecting to remote HTTP-based MCP services.</li> <li>Dependencies: <code>mcp</code> SDK, <code>fastapi</code>, <code>uvicorn</code>, <code>httpx</code>.</li> <li>Configuration: <code>communicator_type: mcp_sse</code>. Options: <code>server_mode</code> (bool), <code>http_port</code> (server mode).</li> </ul> </li> <li> <p><code>McpStdioCommunicator</code></p> <ul> <li>Protocol: MCP over standard input/output.</li> <li>Best For: Running an agent as an MCP service interacted with via stdin/stdout (e.g., as a CLI tool or managed subprocess). Connecting to external tools/engines that expose an MCP interface via stdio (like Stockfish configured for MCP).</li> <li>Dependencies: <code>mcp</code> SDK.</li> <li>Configuration: <code>communicator_type: mcp_stdio</code>. Options: <code>server_mode</code> (bool).</li> </ul> </li> </ol>"},{"location":"guides/communication/#grpc-grpccommunicator","title":"gRPC (<code>GrpcCommunicator</code>)","text":"<p>Experimental Feature</p> <p>Please note that the <code>GrpcCommunicator</code> is considered experimental in OpenMAS v0.1.0. While providing basic gRPC functionality, it has undergone limited testing compared to the core HTTP and MCP communicators and may have an unstable API subject to change in future releases. It may lack comprehensive error handling or support for advanced gRPC features like streaming patterns. It is not recommended for use in production environments at this stage. Feedback and contributions to improve gRPC integration are welcome.</p> <ul> <li>Protocol: gRPC (using <code>grpcio</code>).</li> <li>Best For: High-performance, low-latency RPC between services, potentially across different languages. Streaming scenarios. Microservice architectures where gRPC is standard. Requires <code>openmas[grpc]</code>.</li> <li>Dependencies: <code>grpcio</code>, <code>grpcio-tools</code>.</li> <li>Configuration: <code>communicator_type: grpc</code>. Options: <code>server_mode</code> (bool), <code>grpc_port</code> (server mode).</li> <li>Note: The default implementation uses a generic dictionary format. For type-safe communication using Protobuf definitions, customization might be needed.</li> </ul>"},{"location":"guides/communication/#mqtt-mqttcommunicator","title":"MQTT (<code>MqttCommunicator</code>)","text":"<p>Experimental Feature</p> <p>Please note that the <code>MqttCommunicator</code> is considered experimental in OpenMAS v0.1.0. While providing basic MQTT connectivity, it has undergone limited testing compared to the core HTTP and MCP communicators and may have an unstable API subject to change in future releases. Known limitations might include incomplete support for all MQTT QoS levels or specific broker configurations. It is not recommended for use in production environments at this stage. Feedback and contributions to enhance MQTT support are welcome.</p> <ul> <li>Protocol: MQTT (using <code>paho-mqtt</code>).</li> <li>Best For: Publish/subscribe messaging patterns, event-driven architectures, decoupled communication, IoT applications. Requires an external MQTT broker. Requires <code>openmas[mqtt]</code>.</li> <li>Dependencies: <code>paho-mqtt</code>.</li> <li>Configuration: <code>communicator_type: mqtt</code>. Options: <code>broker_host</code>, <code>broker_port</code>, <code>username</code>, <code>password</code>, <code>client_id</code>, TLS settings.</li> </ul>"},{"location":"guides/communication/#choosing-the-right-protocol","title":"Choosing the Right Protocol","text":"Scenario Recommended Communicator(s) Why? General Request/Response between Agents/Services <code>HttpCommunicator</code> Standard, widely supported, good for RESTful patterns. Interacting with Anthropic Models/MCP Services <code>McpSseCommunicator</code> Native MCP support over standard web protocols. Exposing Agent as HTTP-based MCP Server <code>McpSseCommunicator</code> Allows web clients/other services to interact via MCP over HTTP/SSE. Agent as CLI Tool using MCP <code>McpStdioCommunicator</code> Uses stdin/stdout for MCP interaction. Connecting to MCP Tool via Subprocess (e.g. Stockfish) <code>McpStdioCommunicator</code> Manages subprocess communication via MCP over stdio. High-Performance RPC <code>GrpcCommunicator</code> Efficient binary protocol, good for low-latency internal comms. Publish/Subscribe, Event-Driven Systems <code>MqttCommunicator</code> Decoupled messaging via a broker, suitable for event notifications. Agents in the Same Process (Testing/Simple) <code>MockCommunicator</code> (testing) or potentially a future <code>InMemoryCommunicator</code> Lowest latency, avoids network overhead."},{"location":"guides/communication/#communicator-configuration-options","title":"Communicator Configuration Options","text":"<p>Refer to the specific communicator class documentation (or source code) and the Configuration Guide for detailed options applicable to each communicator type (e.g., <code>http_port</code>, <code>grpc_port</code>, <code>broker_host</code>, <code>server_mode</code>, <code>timeout</code>). These are typically set within the <code>communicator_options</code> dictionary in your configuration.</p>"},{"location":"guides/communication/#mcp-method-mapping-client-perspective","title":"MCP Method Mapping (Client Perspective)","text":"<p>When an OpenMAS agent uses an MCP communicator (<code>McpSseCommunicator</code> or <code>McpStdioCommunicator</code>) in client mode to interact with a remote MCP server, the standard OpenMAS communicator methods (<code>send_request</code>, <code>send_notification</code>) are mapped to the underlying MCP protocol actions on the remote server:</p> Your Agent's Call (<code>self.communicator.&lt;method&gt;</code>) Remote MCP Action Triggered Description <code>send_request(target_service=\"svc\", method=\"tool/list\")</code> <code>list_tools()</code> Lists tools on the remote MCP server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"tool/call\", params={\"name\": \"calc\", \"arguments\": {\"a\":1}})</code> <code>call_tool(\"calc\", {\"a\":1})</code> Calls the tool named \"calc\" on the remote server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"prompt/list\")</code> <code>list_prompts()</code> Lists prompts on the remote server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"prompt/get\", params={\"name\": \"qa\", \"arguments\": {\"q\":\"Hi\"}})</code> <code>get_prompt(\"qa\", {\"q\":\"Hi\"})</code> Gets the prompt named \"qa\" from the remote server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"resource/list\")</code> <code>list_resources()</code> Lists resources on the remote server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"resource/read\", params={\"uri\": \"/data.json\"})</code> <code>read_resource(\"/data.json\")</code> Reads the resource at the specified URI from server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"some_custom_name\", params={...})</code> <code>call_tool(\"some_custom_name\", {...})</code> By convention, non-prefixed methods often map to <code>call_tool</code> on the server. <code>send_notification(target_service=\"svc\", method=\"log_event\", params={...})</code> Async <code>call_tool(\"log_event\", {...})</code> Sends a notification, often mapped to an asynchronous tool call on the server <code>svc</code> where no response is expected by the caller. <p>Note: This mapping applies when your OpenMAS agent is acting as an MCP client. When your agent acts as an MCP server (using <code>MCPServerAgent</code> or a communicator in <code>server_mode=True</code>), incoming MCP requests trigger the methods decorated with <code>@mcp_tool</code>, <code>@mcp_prompt</code>, or <code>@mcp_resource</code> within your agent. See the MCP Integration Guide.</p>"},{"location":"guides/communication/#extending-with-custom-protocols","title":"Extending with Custom Protocols","text":"<p>OpenMAS allows you to create custom protocol implementations by extending the <code>BaseCommunicator</code> class and potentially leveraging the communicator extension system (see <code>communicator_extensions.md</code>).</p>"},{"location":"guides/communication/#communication-in-openmas-old","title":"Communication in OpenMAS (OLD)","text":"<p>This document provides an overview of the communication protocols in OpenMAS, explaining when and how to use each one.</p>"},{"location":"guides/communication/#communication-overview_1","title":"Communication Overview","text":"<p>OpenMAS provides a flexible communication layer that abstracts away the complexity of different communication protocols. The core of this system is the <code>BaseCommunicator</code> interface, which all protocol implementations extend.</p>"},{"location":"guides/communication/#available-protocols","title":"Available Protocols","text":""},{"location":"guides/communication/#http-communication","title":"HTTP Communication","text":"<p>The HTTP protocol implementation uses standard HTTP requests for communication between agents and services. It's suitable for: - RESTful API interactions - Web-based service integration - Scenarios where agents run in different processes or machines</p> <p>Configuration Example: <pre><code>from openmas.communication import HTTPCommunicator\n\ncommunicator = HTTPCommunicator(\n    agent_name=\"agent1\",\n    service_urls={\n        \"service1\": \"http://localhost:8000/service1\",\n        \"service2\": \"http://localhost:8001/service2\"\n    }\n)\n</code></pre></p>"},{"location":"guides/communication/#message-channel-protocol-mcp","title":"Message Channel Protocol (MCP)","text":"<p>The Message Channel Protocol is optimized for high-performance, in-memory communication. It's ideal for: - Agents running in the same process - High-frequency message passing - Testing and development - Integration with AI models and tools via Anthropic's MCP</p> <p>OpenMAS provides specialized MCP communicator implementations:</p>"},{"location":"guides/communication/#mcp-stdio-communicator","title":"MCP Stdio Communicator","text":"<p>Specifically designed for MCP communication over standard input/output. Can operate in both client and server roles.</p> <p>Client Mode Example - Connecting to an External MCP Server: <pre><code>from openmas.communication.mcp import McpStdioCommunicator\n\ncommunicator = McpStdioCommunicator(\n    agent_name=\"agent1\",\n    service_urls={\n        \"local_service\": \"python -m service_script.py\",  # Command to run a local MCP service\n        \"external_service\": \"stdio:/path/to/external/executable\"  # Connection to external executable\n    }\n)\n</code></pre></p> <p>Server Mode Example: <pre><code>from openmas.communication.mcp import McpStdioCommunicator\n\ncommunicator = McpStdioCommunicator(\n    agent_name=\"agent1\",\n    service_urls={},  # Not used in server mode\n    server_mode=True,\n    server_instructions=\"This agent provides analysis tools.\"\n)\n</code></pre></p>"},{"location":"guides/communication/#mcp-sse-communicator","title":"MCP SSE Communicator","text":"<p>Uses HTTP with Server-Sent Events for MCP communication. Can operate in both client and server roles.</p> <p>Client Mode Example - Connecting to External MCP Servers: <pre><code>from openmas.communication.mcp import McpSseCommunicator\n\ncommunicator = McpSseCommunicator(\n    agent_name=\"agent1\",\n    service_urls={\n        \"local_service\": \"http://localhost:8000/mcp\",  # Local MCP service\n        \"external_service\": \"http://external-server.example.com:8080\"  # External MCP server\n    }\n)\n</code></pre></p> <p>Server Mode Example: <pre><code>from fastapi import FastAPI\nfrom openmas.communication.mcp import McpSseCommunicator\n\n# Optional: Create a FastAPI app (will create one if not provided)\napp = FastAPI(title=\"MCP Agent\")\n\ncommunicator = McpSseCommunicator(\n    agent_name=\"agent1\",\n    service_urls={},  # Not used in server mode\n    server_mode=True,\n    http_port=8000,\n    server_instructions=\"This agent provides analysis tools.\",\n    app=app  # Optional\n)\n</code></pre></p>"},{"location":"guides/communication/#when-to-use-each-protocol","title":"When to Use Each Protocol","text":"Protocol Best For Limitations HTTP Cross-process/cross-machine communication Higher latency, network dependency MCP Stdio MCP with subprocess or CLI Requires subprocess management MCP SSE MCP with web services Requires HTTP infrastructure"},{"location":"guides/communication/#when-to-use-each-mcp-communicator","title":"When to Use Each MCP Communicator","text":"Communicator Client Mode Server Mode Best For McpStdioCommunicator Spawn and connect to subprocess MCP services or external executables Run as MCP server via stdin/stdout CLI tools, subprocess integration, connecting to existing MCP tools like Stockfish McpSseCommunicator Connect to HTTP-based MCP services (local or external) Run as HTTP/SSE MCP server Web services, UI integration, API gateway patterns, connecting to cloud-based MCP services"},{"location":"guides/communication/#connecting-to-external-mcp-servers","title":"Connecting to External MCP Servers","text":"<p>OpenMAS supports connecting to external MCP servers in both stdio and SSE modes:</p>"},{"location":"guides/communication/#stdio-connection-format","title":"Stdio Connection Format","text":"<p>For stdio connections to external executables, use the <code>stdio:</code> protocol prefix:</p> <pre><code>service_urls = {\n    \"stockfish\": \"stdio:/usr/local/bin/stockfish\",  # Path to Stockfish executable\n    \"custom_tool\": \"stdio:/path/to/custom/tool\"     # Path to any MCP-compatible executable\n}\n</code></pre> <p>When using the stdio protocol prefix, OpenMAS will execute the specified binary and communicate with it via stdin/stdout.</p>"},{"location":"guides/communication/#sse-connection-format","title":"SSE Connection Format","text":"<p>For SSE connections to external HTTP-based MCP servers, use standard HTTP URLs:</p> <pre><code>service_urls = {\n    \"local_service\": \"http://localhost:8000\",              # Local MCP server\n    \"cloud_service\": \"https://api.example.com/mcp-server\"  # External cloud MCP server\n}\n</code></pre>"},{"location":"guides/communication/#mcp-method-mapping","title":"MCP Method Mapping","text":"<p>When an OpenMAS agent uses an MCP communicator (<code>McpSseCommunicator</code> or <code>McpStdioCommunicator</code>) in client mode to interact with a remote MCP server, the standard OpenMAS communicator methods (<code>send_request</code>, <code>send_notification</code>) are mapped to the underlying MCP protocol actions on the remote server:</p> Your Agent's Call (<code>self.communicator.&lt;method&gt;</code>) Remote MCP Action Triggered Description <code>send_request(target_service=\"svc\", method=\"tool/list\")</code> <code>list_tools()</code> Lists tools on the remote MCP server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"tool/call\", params={\"name\": \"calc\", \"arguments\": {\"a\":1}})</code> <code>call_tool(\"calc\", {\"a\":1})</code> Calls the tool named \"calc\" on the remote server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"prompt/list\")</code> <code>list_prompts()</code> Lists prompts on the remote server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"prompt/get\", params={\"name\": \"qa\", \"arguments\": {\"q\":\"Hi\"}})</code> <code>get_prompt(\"qa\", {\"q\":\"Hi\"})</code> Gets the prompt named \"qa\" from the remote server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"resource/list\")</code> <code>list_resources()</code> Lists resources on the remote server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"resource/read\", params={\"uri\": \"/data.json\"})</code> <code>read_resource(\"/data.json\")</code> Reads the resource at the specified URI from server <code>svc</code>. <code>send_request(target_service=\"svc\", method=\"some_custom_name\", params={...})</code> <code>call_tool(\"some_custom_name\", {...})</code> By convention, non-prefixed methods often map to <code>call_tool</code> on the server. <code>send_notification(target_service=\"svc\", method=\"log_event\", params={...})</code> Async <code>call_tool(\"log_event\", {...})</code> Sends a notification, often mapped to an asynchronous tool call on the server <code>svc</code> where no response is expected by the caller. <p>Note: This mapping applies when your OpenMAS agent is acting as an MCP client. When your agent acts as an MCP server (using <code>MCPServerAgent</code> or a communicator in <code>server_mode=True</code>), incoming MCP requests trigger the methods decorated with <code>@mcp_tool</code>, <code>@mcp_prompt</code>, or <code>@mcp_resource</code> within your agent.</p>"},{"location":"guides/communication/#extending-with-custom-protocols_1","title":"Extending with Custom Protocols","text":"<p>OpenMAS allows you to create custom protocol implementations by extending the <code>BaseCommunicator</code> class. See the developer documentation for details on implementing your own communicator.</p>"},{"location":"guides/communication/#communicator-extension-system","title":"Communicator Extension System","text":"<p>OpenMAS includes an extension system that allows developers to create and register their own communicator implementations. This system enables easy extension of OpenMAS with custom communication protocols.</p>"},{"location":"guides/communication/#using-the-extension-system","title":"Using the Extension System","text":"<p>The communicator extension system allows users to specify a communicator type in their agent configuration:</p> <pre><code>from openmas.agent import BaseAgent\nfrom openmas.config import AgentConfig\n\n# Configure through environment variables\n# COMMUNICATOR_TYPE=mcp_stdio\n# COMMUNICATOR_OPTION_SERVER_MODE=true\n\n# Or through direct initialization with config\nagent = BaseAgent(\n    name=\"my-agent\",\n    config=AgentConfig(\n        name=\"my-agent\",\n        communicator_type=\"http\",  # or \"mcp_stdio\", \"mcp_sse\", etc.\n        communicator_options={\n            \"server_mode\": True,\n            \"http_port\": 8000\n        }\n    )\n)\n\n# Or just override the communicator class directly\nfrom openmas.communication import HttpCommunicator\nagent = BaseAgent(\n    name=\"my-agent\",\n    communicator_class=HttpCommunicator\n)\n</code></pre>"},{"location":"guides/communication/#available-configuration-options","title":"Available Configuration Options","text":""},{"location":"guides/communication/#http-communicator","title":"HTTP Communicator","text":"Option Default Description None currently"},{"location":"guides/communication/#mcp-stdio-communicator_1","title":"MCP Stdio Communicator","text":"Option Default Description <code>server_mode</code> <code>False</code> Whether to run in server mode <code>server_instructions</code> <code>None</code> Instructions for the server"},{"location":"guides/communication/#mcp-sse-communicator_1","title":"MCP SSE Communicator","text":"Option Default Description <code>server_mode</code> <code>False</code> Whether to run in server mode <code>http_port</code> <code>8000</code> Port for the HTTP server (server mode only) <code>server_instructions</code> <code>None</code> Instructions for the server"},{"location":"guides/communication/#grpc-communicator","title":"gRPC Communicator","text":"Option Default Description <code>server_mode</code> <code>False</code> Whether to run in server mode <code>server_address</code> <code>[::]:50051</code> Address to bind the server to (server mode only) <code>max_workers</code> <code>10</code> Maximum number of server worker threads <code>channel_options</code> <code>{}</code> Additional gRPC channel options"},{"location":"guides/communication/#grpc-communication","title":"gRPC Communication","text":"<p>The gRPC communicator provides efficient, high-performance communication using Google's gRPC framework. It requires the <code>openmas[grpc]</code> extra to be installed.</p> <p>It's suitable for:</p> <ul> <li>High-performance, type-safe communication (if using Protobuf definitions)</li> <li>Cross-language interoperability</li> <li>Streaming scenarios</li> <li>Microservice architectures where gRPC is already in use</li> </ul> <p>Configuration Example (Client Mode):</p> <pre><code># In config (e.g., YAML or environment variables)\n# COMMUNICATOR_TYPE=grpc\n# SERVICE_URL_MY_GRPC_SERVICE=localhost:50051\n\nfrom openmas.communication.grpc import GrpcCommunicator\n\n# Or instantiated directly:\ncommunicator = GrpcCommunicator(\n    agent_name=\"my-grpc-client\",\n    service_urls={\n        \"my_grpc_service\": \"localhost:50051\" # Address of the target gRPC server\n    },\n    # server_mode=False # Default\n)\n</code></pre> <p>Configuration Example (Server Mode):</p> <pre><code># In config:\n# COMMUNICATOR_TYPE=grpc\n# COMMUNICATOR_OPTION_SERVER_MODE=true\n# COMMUNICATOR_OPTION_GRPC_PORT=50052\n\nfrom openmas.communication.grpc import GrpcCommunicator\n\n# Or instantiated directly:\ncommunicator = GrpcCommunicator(\n    agent_name=\"my-grpc-server\",\n    service_urls={}, # Not needed for server\n    server_mode=True,\n    grpc_port=50052 # Port for this agent's gRPC server to listen on\n)\n</code></pre> <p>Note: The current <code>GrpcCommunicator</code> uses a generic dictionary-based request/response format over gRPC. For type safety using Protobuf definitions, you would typically implement a custom communicator or extend the existing one.</p>"},{"location":"guides/communication/#mqtt-communication","title":"MQTT Communication","text":"<p>The MQTT communicator uses the MQTT protocol for publish/subscribe messaging, typically via an MQTT broker. It requires the <code>openmas[mqtt]</code> extra.</p> <p>It's suitable for:</p> <ul> <li>Event-driven architectures</li> <li>Decoupled communication where agents publish or subscribe to topics</li> <li>IoT scenarios</li> <li>Situations where a message broker is preferred</li> </ul> <p>Configuration Example:</p> <pre><code># In config:\n# COMMUNICATOR_TYPE=mqtt\n# COMMUNICATOR_OPTION_BROKER_HOST=mqtt.eclipseprojects.io\n# COMMUNICATOR_OPTION_BROKER_PORT=1883\n# SERVICE_URLS={} # Often not used directly, communication is via pub/sub\n\nfrom openmas.communication.mqtt import MqttCommunicator\n\n# Or instantiated directly:\ncommunicator = MqttCommunicator(\n    agent_name=\"my-mqtt-agent\",\n    service_urls={}, # Agents typically discover each other via topics\n    broker_host=\"mqtt.eclipseprojects.io\", # Address of the MQTT broker\n    broker_port=1883,\n    # Optional: username=\"user\", password=\"pass\", client_id=\"custom_id\"\n)\n</code></pre> <p>Note: With MQTT, agents usually communicate via topics rather than direct service names in <code>service_urls</code>. The <code>send_request</code> and <code>send_notification</code> methods in the <code>MqttCommunicator</code> likely map <code>target_service</code> and <code>method</code> to specific MQTT topics based on internal conventions.</p>"},{"location":"guides/communication/#mqtt-communicator","title":"MQTT Communicator","text":"Option Default Description <code>broker_host</code> <code>\"localhost\"</code> Hostname or IP address of the MQTT broker. <code>broker_port</code> <code>1883</code> Port of the MQTT broker. <code>username</code> <code>None</code> Username for MQTT broker authentication. <code>password</code> <code>None</code> Password for MQTT broker authentication. <code>client_id</code> Auto-generated MQTT client ID. If empty, one is generated. <code>keepalive</code> <code>60</code> MQTT keepalive interval in seconds. <code>tls_enabled</code> <code>False</code> Enable TLS/SSL encryption. <code>tls_ca_certs</code> <code>None</code> Path to CA certificate file for TLS. <code>tls_certfile</code> <code>None</code> Path to client certificate file for TLS. <code>tls_keyfile</code> <code>None</code> Path to client private key file for TLS."},{"location":"use_cases/chesspal_ai/","title":"Use Case: Chesspal.ai Refactoring","text":"<p>This document outlines the target architecture for refactoring the <code>chesspal.ai</code> application into a Multi-Agent System (MAS) using OpenMAS. This use case served as a primary driver for early versions of the framework, particularly highlighting the need for robust Model Context Protocol (MCP) integration.</p> <p>(Based on Appendix B of the OpenMAS Design Document v0.2.3)</p>"},{"location":"use_cases/chesspal_ai/#background","title":"Background","text":"<p><code>chesspal.ai</code> involves detecting chess board states from images, managing game logic, interacting with a chess engine (Stockfish), and generating commentary. Refactoring this into an MAS aims to improve modularity, scalability, and maintainability.</p>"},{"location":"use_cases/chesspal_ai/#target-mas-architecture","title":"Target MAS Architecture","text":"<p>The proposed MAS consists of the following agents, primarily communicating via MCP:</p>"},{"location":"use_cases/chesspal_ai/#1-orchestrator-agent","title":"1. Orchestrator Agent","text":"<ul> <li>Role: Central coordinator of the system. Manages the overall game flow, maintains the current game state, and orchestrates interactions between other agents and potentially a user interface (GUI).</li> <li>Key Responsibilities:<ul> <li>Game state management (e.g., current board position, move history, whose turn).</li> <li>Persisting game state (e.g., using SQLite for development, PostgreSQL for production).</li> <li>Handling input (e.g., moves submitted from a GUI, requests for game state).</li> <li>Delegating tasks to other agents (requesting commentary, requesting move analysis).</li> <li>Receiving results from other agents and updating the game state.</li> </ul> </li> <li>Communication (MCP):<ul> <li>MCP Server: Runs an MCP Server (using <code>McpServerAgent</code> or <code>McpSseCommunicator</code> in server mode) to expose an interface for external clients (like a GUI) to connect. This interface would allow clients to:<ul> <li>Get the current game state (e.g., via an MCP Resource or Tool).</li> <li>Submit player moves (e.g., via an MCP Tool call).</li> <li>Receive game updates (potentially via streaming or notifications).</li> </ul> </li> <li>MCP Client: Acts as an MCP Client (using <code>BaseAgent</code> with <code>McpSseCommunicator</code> or <code>McpStdioCommunicator</code> in client mode) to interact with the Commentary and Stockfish agents. It would use <code>send_request</code> mapped to MCP actions like:<ul> <li><code>call_tool</code> on the Commentary Agent to generate commentary for a move.</li> <li><code>call_tool</code> on the Stockfish Agent to get move analysis or the best move.</li> </ul> </li> </ul> </li> <li>Dependencies &amp; OpenMAS Requirements:<ul> <li>Robust OpenMAS wrappers for MCP server (<code>FastMCP</code>) and client (<code>ClientSession</code>) functionality via the official <code>mcp</code> SDK (v1.6+).</li> <li><code>BaseAgent</code> must support standard <code>asyncio</code> patterns for database interactions (e.g., using <code>asyncpg</code> or <code>aiosqlite</code>).</li> <li>Easy configuration of service URLs to connect to the other agents.</li> </ul> </li> </ul>"},{"location":"use_cases/chesspal_ai/#2-commentary-agent","title":"2. Commentary Agent","text":"<ul> <li>Role: Generates natural language commentary about the chess game state or recent moves.</li> <li>Key Responsibilities:<ul> <li>Receiving requests from the Orchestrator containing game context (e.g., current FEN, last move).</li> <li>Interacting with a Large Language Model (LLM), such as Google's Gemma or Anthropic's Claude, to generate commentary text based on the provided context.</li> <li>Returning the generated commentary to the Orchestrator.</li> </ul> </li> <li>Communication (MCP):<ul> <li>MCP Server: Runs an MCP Server (using <code>McpServerAgent</code> or similar). It exposes its functionality, likely as an MCP Tool (e.g., <code>generate_commentary</code>) that the Orchestrator can call via <code>send_request</code> (mapping to <code>call_tool</code>). The tool would accept game context as input and return the commentary string.</li> </ul> </li> <li>Dependencies &amp; OpenMAS Requirements:<ul> <li>OpenMAS MCP server capabilities (<code>McpServerAgent</code> or <code>McpSseCommunicator</code>/<code>McpStdioCommunicator</code> in server mode).</li> <li>Compatibility with LLM integration libraries (e.g., <code>google-generativeai</code>, <code>anthropic</code>) within the <code>BaseAgent</code>'s async environment. See LLM Integration Guide.</li> <li>Ability to load LLM API keys and model names via the OpenMAS configuration system.</li> </ul> </li> <li>Enhanced Implementation with Prompt Management:<ul> <li>Uses <code>PromptMcpAgent</code> to maintain a library of commentary prompts for different game scenarios</li> <li>Leverages template rendering to insert game state into prompts</li> <li>Uses the sampling system to control output parameters like temperature and length</li> </ul> </li> </ul>"},{"location":"use_cases/chesspal_ai/#3-stockfish-agent","title":"3. Stockfish Agent","text":"<ul> <li>Role: Provides chess engine capabilities using the Stockfish engine. Performs move validation, calculates the best move, and provides board analysis.</li> <li>Key Responsibilities:<ul> <li>Managing an underlying Stockfish engine process.</li> <li>Receiving requests from the Orchestrator (e.g., \"validate move\", \"get best move for FEN\", \"analyze position\").</li> <li>Interacting with the Stockfish process (likely via UCI protocol).</li> <li>Returning the results (e.g., best move in UCI notation, evaluation score) to the Orchestrator.</li> </ul> </li> <li>Communication (MCP):<ul> <li>MCP Server: Runs an MCP Server (using <code>McpServerAgent</code> or similar). It exposes its functionality as one or more MCP Tools (e.g., <code>get_best_move</code>, <code>validate_move</code>, <code>analyze_position</code>) that the Orchestrator can call.</li> </ul> </li> <li>Dependencies &amp; OpenMAS Requirements:<ul> <li>OpenMAS MCP server capabilities.</li> <li><code>BaseAgent</code> must support managing external subprocesses asynchronously (e.g., using <code>asyncio.create_subprocess_exec</code> to run and communicate with Stockfish).</li> <li>Ability to configure the path to the Stockfish executable.</li> </ul> </li> </ul>"},{"location":"use_cases/chesspal_ai/#extended-architecture-with-prompt-management-and-sampling","title":"Extended Architecture with Prompt Management and Sampling","text":"<p>The ChessPal use case can be significantly enhanced with OpenMAS's new prompt management and sampling capabilities. This section outlines how these features can be integrated into the system.</p>"},{"location":"use_cases/chesspal_ai/#commentary-agent-with-prompt-management","title":"Commentary Agent with Prompt Management","text":"<p>The Commentary Agent can be refactored to leverage the <code>PromptMcpAgent</code> class, which provides built-in prompt management and sampling capabilities:</p> <pre><code>from openmas.agent import PromptMcpAgent\nfrom typing import Dict, Any, Optional\n\nclass ChessCommentaryAgent(PromptMcpAgent):\n    \"\"\"Chess commentary agent that provides natural language commentary on chess games.\"\"\"\n\n    async def setup(self):\n        \"\"\"Set up the agent with prompts and communication.\"\"\"\n        await super().setup()\n\n        # Initialize prompt library with different commentary styles and purposes\n        self.prompts = {}\n\n        # Basic move commentary\n        self.prompts[\"move_commentary\"] = await self.create_prompt(\n            name=\"move_commentary\",\n            description=\"Provides commentary for a chess move\",\n            system=\"You are an enthusiastic chess commentator who explains moves clearly.\",\n            template=(\n                \"Current board position (FEN notation): {{fen}}\\n\"\n                \"Last move played: {{last_move}}\\n\"\n                \"Player who moved: {{player}}\\n\\n\"\n                \"Provide engaging commentary about this move in 2-3 sentences.\"\n            ),\n            tags={\"chess\", \"commentary\", \"moves\"}\n        )\n\n        # Game situation analysis\n        self.prompts[\"game_analysis\"] = await self.create_prompt(\n            name=\"game_analysis\",\n            description=\"Analyzes the current game situation\",\n            system=\"You are a chess grandmaster providing insightful analysis.\",\n            template=(\n                \"Current board position (FEN notation): {{fen}}\\n\"\n                \"Move history: {{move_history}}\\n\"\n                \"Current player to move: {{player_to_move}}\\n\\n\"\n                \"Analyze the current game situation. Comment on piece development, \"\n                \"board control, and potential strategies for both players.\"\n            ),\n            tags={\"chess\", \"analysis\", \"strategy\"}\n        )\n\n        # Opening identification\n        self.prompts[\"opening_commentary\"] = await self.create_prompt(\n            name=\"opening_commentary\",\n            description=\"Identifies and comments on chess openings\",\n            system=\"You are a chess opening expert who can identify openings from move sequences.\",\n            template=(\n                \"Current move sequence: {{move_sequence}}\\n\\n\"\n                \"Identify the chess opening being played, if recognizable. \"\n                \"Explain the key ideas behind this opening and potential variations.\"\n            ),\n            tags={\"chess\", \"commentary\", \"openings\"}\n        )\n\n        # Beginner-friendly commentary\n        self.prompts[\"beginner_commentary\"] = await self.create_prompt(\n            name=\"beginner_commentary\",\n            description=\"Chess commentary tailored for beginners\",\n            system=(\n                \"You are a patient chess teacher who explains concepts in simple terms. \"\n                \"Avoid using advanced terminology without explanation. Focus on basic \"\n                \"principles and learning opportunities.\"\n            ),\n            template=(\n                \"Current board position (FEN notation): {{fen}}\\n\"\n                \"Last move played: {{last_move}}\\n\"\n                \"Player level: Beginner\\n\\n\"\n                \"Explain this chess position and the last move in terms a beginner can understand. \"\n                \"Highlight any basic principles that apply and learning opportunities.\"\n            ),\n            tags={\"chess\", \"commentary\", \"beginner\"}\n        )\n\n        # Register prompts with MCP server (if running in server mode)\n        if self._server_mode:\n            await self.register_prompts_with_server()\n\n        # Set up tool handlers\n        self.add_tool_handler(\"generate_commentary\", self.handle_commentary_request)\n        self.add_tool_handler(\"analyze_position\", self.handle_analysis_request)\n        self.add_tool_handler(\"identify_opening\", self.handle_opening_request)\n\n    async def handle_commentary_request(self, payload: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle a request for move commentary.\"\"\"\n        fen = payload.get(\"fen\", \"\")\n        last_move = payload.get(\"last_move\", \"\")\n        player = payload.get(\"player\", \"\")\n        style = payload.get(\"style\", \"standard\")\n\n        # Select the appropriate prompt based on style\n        prompt_id = self.prompts[\"move_commentary\"].id\n        if style == \"beginner\":\n            prompt_id = self.prompts[\"beginner_commentary\"].id\n\n        # Sample from the selected prompt\n        result = await self.sample(\n            prompt_id=prompt_id,\n            context={\n                \"fen\": fen,\n                \"last_move\": last_move,\n                \"player\": player\n            },\n            parameters={\n                \"temperature\": 0.7,\n                \"max_tokens\": 200\n            }\n        )\n\n        return {\"commentary\": result.content}\n\n    async def handle_analysis_request(self, payload: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle a request for game analysis.\"\"\"\n        fen = payload.get(\"fen\", \"\")\n        move_history = payload.get(\"move_history\", \"\")\n        player_to_move = payload.get(\"player_to_move\", \"\")\n\n        result = await self.sample(\n            prompt_id=self.prompts[\"game_analysis\"].id,\n            context={\n                \"fen\": fen,\n                \"move_history\": move_history,\n                \"player_to_move\": player_to_move\n            },\n            parameters={\n                \"temperature\": 0.3,  # Lower temperature for more focused analysis\n                \"max_tokens\": 500\n            }\n        )\n\n        return {\"analysis\": result.content}\n\n    async def handle_opening_request(self, payload: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle a request to identify a chess opening.\"\"\"\n        move_sequence = payload.get(\"move_sequence\", \"\")\n\n        result = await self.sample(\n            prompt_id=self.prompts[\"opening_commentary\"].id,\n            context={\n                \"move_sequence\": move_sequence\n            },\n            parameters={\n                \"temperature\": 0.2,  # Low temperature for factual accuracy\n                \"max_tokens\": 300\n            }\n        )\n\n        return {\"opening_analysis\": result.content}\n</code></pre> <p>Key benefits of this implementation:</p> <ol> <li>Structured Prompt Management: Different prompts for different commentary needs (move commentary, analysis, opening identification)</li> <li>Dynamic Templating: Game state is inserted into prompts via template variables</li> <li>Parameter Control: Control over sampling parameters like temperature and max_tokens</li> <li>MCP Integration: Prompts can be registered as MCP resources automatically</li> <li>Versioning &amp; Metadata: Prompts include version information, tags, and metadata</li> <li>Extensibility: Easy to add new commentary styles or specialized prompts</li> </ol>"},{"location":"use_cases/chesspal_ai/#orchestrator-agent-with-sampling-interface","title":"Orchestrator Agent with Sampling Interface","text":"<p>The Orchestrator Agent can leverage the sampling interface to generate personalized responses for players:</p> <pre><code>from openmas.agent import PromptMcpAgent\nfrom typing import Dict, Any, Optional\n\nclass ChessOrchestratorAgent(PromptMcpAgent):\n    \"\"\"Orchestrator agent that manages the chess game and coordinates other agents.\"\"\"\n\n    async def setup(self):\n        \"\"\"Set up the agent.\"\"\"\n        await super().setup()\n\n        # Initialize player interaction prompts\n        self.prompts = {}\n\n        # Welcome message prompt\n        self.prompts[\"welcome\"] = await self.create_prompt(\n            name=\"welcome_message\",\n            description=\"Generates a welcome message for players\",\n            system=\"You are ChessPal, a friendly chess assistant.\",\n            template=(\n                \"Player name: {{player_name}}\\n\"\n                \"Player rating: {{player_rating}}\\n\"\n                \"Time of day: {{time_of_day}}\\n\\n\"\n                \"Generate a friendly, personalized welcome message for this chess player.\"\n            ),\n            tags={\"interaction\", \"welcome\"}\n        )\n\n        # Game advice prompt\n        self.prompts[\"advice\"] = await self.create_prompt(\n            name=\"game_advice\",\n            description=\"Provides personalized advice for a player during a game\",\n            system=\"You are ChessPal, a helpful chess coach.\",\n            template=(\n                \"Player name: {{player_name}}\\n\"\n                \"Player rating: {{player_rating}}\\n\"\n                \"Current position (FEN): {{fen}}\\n\"\n                \"Player color: {{player_color}}\\n\"\n                \"Move history: {{move_history}}\\n\\n\"\n                \"Provide brief, helpful advice for this player based on the current game situation.\"\n            ),\n            tags={\"interaction\", \"advice\"}\n        )\n\n        # Initialize communicators to other agents\n        # ... (code to set up communication with other agents)\n\n    async def generate_welcome_message(self, player_name: str, player_rating: int) -&gt; str:\n        \"\"\"Generate a personalized welcome message for a player.\"\"\"\n        # Get the current time of day\n        import datetime\n        hour = datetime.datetime.now().hour\n        time_of_day = \"morning\" if 5 &lt;= hour &lt; 12 else \"afternoon\" if 12 &lt;= hour &lt; 18 else \"evening\"\n\n        # Sample from the welcome prompt\n        result = await self.sample(\n            prompt_id=self.prompts[\"welcome\"].id,\n            context={\n                \"player_name\": player_name,\n                \"player_rating\": player_rating,\n                \"time_of_day\": time_of_day\n            },\n            parameters={\n                \"temperature\": 0.8,  # Higher temperature for more varied, creative messages\n                \"max_tokens\": 100\n            }\n        )\n\n        return result.content\n\n    async def generate_advice(self, player_name: str, player_rating: int,\n                             fen: str, player_color: str, move_history: str) -&gt; str:\n        \"\"\"Generate personalized advice for a player during a game.\"\"\"\n        result = await self.sample(\n            prompt_id=self.prompts[\"advice\"].id,\n            context={\n                \"player_name\": player_name,\n                \"player_rating\": player_rating,\n                \"fen\": fen,\n                \"player_color\": player_color,\n                \"move_history\": move_history\n            },\n            parameters={\n                \"temperature\": 0.5,\n                \"max_tokens\": 150\n            }\n        )\n\n        return result.content\n\n    async def handle_player_move(self, payload: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Handle a move submitted by a player.\"\"\"\n        # ... (code to validate and process the move)\n\n        # Get commentary from the commentary agent\n        commentary_result = await self.send_request(\n            target=\"commentary_agent\",\n            action=\"call_tool\",\n            tool_name=\"generate_commentary\",\n            arguments={\n                \"fen\": current_fen,\n                \"last_move\": move,\n                \"player\": player_name,\n                \"style\": \"standard\"  # or \"beginner\" based on player preference\n            }\n        )\n\n        # ... (code to update game state)\n\n        return {\n            \"success\": True,\n            \"commentary\": commentary_result.get(\"commentary\", \"\"),\n            \"board_state\": current_fen,\n            # ... other response fields\n        }\n</code></pre>"},{"location":"use_cases/chesspal_ai/#summary-of-framework-requirements-derived","title":"Summary of Framework Requirements Derived","text":"<p>This use case highlights the need for OpenMAS to provide:</p> <ol> <li>Robust MCP Integration: Stable, easy-to-use, and correct wrappers/abstractions around the official <code>mcp</code> Python SDK (v1.6+) for both client (<code>ClientSession</code> via <code>send_request</code>) and server (<code>FastMCP</code> via <code>McpServerAgent</code> or communicators in server mode) roles.</li> <li>Async Compatibility: The <code>BaseAgent</code> structure must seamlessly support standard asynchronous operations required by the agents, including database access, external API calls (LLMs), and managing subprocesses, without blocking the event loop.</li> <li>Configuration: Flexible configuration system to manage agent names, communication settings (ports, types), service URLs for inter-agent communication, API keys, and external tool paths.</li> <li>Integration: Facilitate the integration of external libraries/SDKs (LLM clients, DB drivers, subprocess management) within the agent's lifecycle methods (<code>setup</code>, <code>run</code>).</li> <li>Prompt Management: Structured system for organizing, versioning, and retrieving prompts for different purposes within agents.</li> <li>Sampling Interface: Consistent interface for interacting with language models across different providers, with control over parameters.</li> <li>MCP Prompt Integration: Ability to expose prompts as MCP resources that can be accessed by other agents.</li> </ol>"},{"location":"use_cases/chesspal_ai/#benefits-of-prompt-management-for-chesspal","title":"Benefits of Prompt Management for ChessPal","text":"<p>The integration of prompt management and sampling features provides several key benefits for the ChessPal system:</p> <ol> <li>Improved Modularity: Prompts are separated from code, making them easier to manage and update</li> <li>Versioning and Tracking: Changes to prompt content can be tracked and versioned</li> <li>Personalization: Templates allow for dynamic insertion of game state and player information</li> <li>Parameter Tuning: Fine control over sampling parameters for different use cases</li> <li>MCP Integration: Prompts can be exposed as MCP resources for consumption by other agents</li> <li>Role-Specific Content: Different prompts for different roles (commentator, coach, analyst)</li> <li>Consistent Interface: Standard interface regardless of the underlying LLM provider</li> </ol> <p>This approach demonstrates how OpenMAS's prompt management and sampling features enable more sophisticated agent behaviors while maintaining clean separation of concerns and modular design.</p>"}]}